<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯, Rickyã®æ°´æœæ‘Š">
    <meta name="description" content="Rickyã®ä¸ªäººåšå®¢">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯ | Rickyã®æ°´æœæ‘Š</title>
    <link rel="icon" type="image/png" href="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <script src="/libs/jquery/jquery.min.js"></script>

    <link rel="stylesheet" type="text/css" href="/css/loading.css">

<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Rickyã®æ°´æœæ‘Š" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/598673.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    
    <div id="loading-box">
      <div class="loading-left-bg"></div>
      <div class="loading-right-bg"></div>
      <div class="spinner-box">
        <div class="configure-border-1">
          <div class="configure-core"></div>
        </div>
        <div class="configure-border-2">
          <div class="configure-core"></div>
        </div>
        <div class="loading-word">åŠ è½½ä¸­...</div>
      </div>
    </div>
    <!-- é¡µé¢åŠ è½½åŠ¨ç”» -->
    <script>
      $(document).ready(function () {
        document.body.style.overflow = 'auto';
        document.getElementById('loading-box').classList.add("loaded")
      })
    </script>
  

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Rickyã®æ°´æœæ‘Š</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>åšå®¢</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/tags">
          
          <i class="fas fa-tags" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>åšå®¢æ ‡ç­¾å¤¹</span>
        </a>
      </li>
      
      <li>
        <a href="/categories">
          
          <i class="fas fa-bookmark" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>åšå®¢åˆ†ç±»å›¾</span>
        </a>
      </li>
      
      <li>
        <a href="/archives">
          
          <i class="fas fa-archive" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>åˆ›ä½œæ—¶å…‰è½´</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>å…³äº</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>ä¸ªäººä¸»é¡µ</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fas fa-file" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>ä¸ªäººç®€å†</span>
        </a>
      </li>
      
      <li>
        <a href="/self-journey">
          
          <i class="fas fa-train" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>ä¸ªäººæ—…é€”</span>
        </a>
      </li>
      
      <li>
        <a href="/self-awareness">
          
          <i class="fas fa-lightbulb" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>è‡ªæˆ‘è®¤çŸ¥</span>
        </a>
      </li>
      
      <li>
        <a href="/self-growth">
          
          <i class="fas fa-chart-line" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>ä¸ªäººæˆé•¿</span>
        </a>
      </li>
      
      <li>
        <a href="/anilist">
          
          <i class="fas fa-tv" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>è¿½ç•ªåˆ—è¡¨</span>
        </a>
      </li>
      
      <li>
        <a href="/world-exploration">
          
          <i class="fas fa-globe" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>ä¸–ç•Œæ¢ç´¢</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-language" style="zoom: 0.6;"></i>
      
      <span>å¤–è¯­</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/EngTOEFL">
          
          <span>ENï½œTOEFLç»éªŒ</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicEnglish">
          
          <span>ENï½œå­¦æœ¯è‹±è¯­</span>
        </a>
      </li>
      
      <li>
        <a href="/EngGrammar">
          
          <span>ENï½œè‹±è¯­è¯­æ³•</span>
        </a>
      </li>
      
      <li>
        <a href="/JpBasic">
          
          <span>JPï½œäº”åéŸ³å›¾</span>
        </a>
      </li>
      
      <li>
        <a href="/JpVocab">
          
          <span>JPï½œåŸºç¡€è¯æ±‡</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-code" style="zoom: 0.6;"></i>
      
      <span>ç§‘ç ”</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/AcademicFoundation">
          
          <span>ç§‘ç ”åŸºç¡€æŠ€èƒ½</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicEnglish">
          
          <span>å­¦æœ¯è‹±è¯­</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicDL">
          
          <span>æ·±åº¦å­¦ä¹ </span>
        </a>
      </li>
      
      <li>
        <a href="/Pytorch">
          
          <span>Pytorch</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-keyboard" style="zoom: 0.6;"></i>
      
      <span>AI</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/AI-basics">
          
          <span>AI-å¤§æ¨¡å‹</span>
        </a>
      </li>
      
      <li>
        <a href="/">
          
          <span>AI-ç›¸å…³ç†è®º</span>
        </a>
      </li>
      
      <li>
        <a href="/AI-tools">
          
          <span>AI-å®ç”¨å·¥å…·</span>
        </a>
      </li>
      
      <li>
        <a href="/AI-news">
          
          <span>AI-å¥½æ–‡æ”¶å½•</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-keyboard" style="zoom: 0.6;"></i>
      
      <span>OI</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%9F%A5%E8%AF%86%E7%82%B9/">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œçŸ¥è¯†ç‚¹</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E5%8D%95/">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œé¢˜å•</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E8%A7%A3/">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œé¢˜è§£</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E5%A4%8D%E7%9B%98/">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œå¤ç›˜</span>
        </a>
      </li>
      
      <li>
        <a href="/tags/%E6%9C%AF%E8%AF%AD/">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œæœ¯è¯­</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œè®­ç»ƒ</span>
        </a>
      </li>
      
      <li>
        <a href="/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%BB%8F%E9%AA%8C%E5%B8%96">
          
          <span>ä¿¡æ¯å¥¥èµ›ï½œç»éªŒå¸–</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/Codeforces%E9%A2%98%E8%A7%A3/">
          
          <span>Codeforcesé¢˜è§£</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/AtCoder%E9%A2%98%E8%A7%A3/">
          
          <span>AtCoderé¢˜è§£</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/AtCoder%E5%A4%8D%E7%9B%98/">
          
          <span>AtCoderå¤ç›˜</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-door-open" style="zoom: 0.6;"></i>
      
      <span>æ”¶è—é¦†</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/music-live">
          
          <span>éŸ³ä¹ï½œLiveç°åœº</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-travel">
          
          <span>é£æ™¯ï½œäº‘æ¸¸ä¸–ç•Œ</span>
        </a>
      </li>
      
      <li>
        <a href="/co-study">
          
          <span>æ•ˆç‡ï½œé™ªä¼´å­¦ä¹ </span>
        </a>
      </li>
      
      <li>
        <a href="/advice">
          
          <span>æå‡ï½œç»éªŒåˆ†äº«</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-role-model">
          
          <span>è®¿è°ˆï½œæ¦œæ ·å‰è¾ˆ</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-sentences">
          
          <span>æ–‡å­¦ï½œé‡‘å¥æ‘˜å½•</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Rickyã®æ°´æœæ‘Š</div>
        <div class="logo-desc">
            
            Rickyã®ä¸ªäººåšå®¢
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-tags"></i>
			
			åšå®¢
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/tags " style="margin-left:75px">
				  
				   <i class="fa fas fa-tags" style="position: absolute;left:50px" ></i>
			      
		          <span>åšå®¢æ ‡ç­¾å¤¹</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories " style="margin-left:75px">
				  
				   <i class="fa fas fa-bookmark" style="position: absolute;left:50px" ></i>
			      
		          <span>åšå®¢åˆ†ç±»å›¾</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archives " style="margin-left:75px">
				  
				   <i class="fa fas fa-archive" style="position: absolute;left:50px" ></i>
			      
		          <span>åˆ›ä½œæ—¶å…‰è½´</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			å…³äº
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>ä¸ªäººä¸»é¡µ</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fas fa-file" style="position: absolute;left:50px" ></i>
			      
		          <span>ä¸ªäººç®€å†</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-journey " style="margin-left:75px">
				  
				   <i class="fa fas fa-train" style="position: absolute;left:50px" ></i>
			      
		          <span>ä¸ªäººæ—…é€”</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-awareness " style="margin-left:75px">
				  
				   <i class="fa fas fa-lightbulb" style="position: absolute;left:50px" ></i>
			      
		          <span>è‡ªæˆ‘è®¤çŸ¥</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-growth " style="margin-left:75px">
				  
				   <i class="fa fas fa-chart-line" style="position: absolute;left:50px" ></i>
			      
		          <span>ä¸ªäººæˆé•¿</span>
                  </a>
                </li>
              
                <li>

                  <a href="/anilist " style="margin-left:75px">
				  
				   <i class="fa fas fa-tv" style="position: absolute;left:50px" ></i>
			      
		          <span>è¿½ç•ªåˆ—è¡¨</span>
                  </a>
                </li>
              
                <li>

                  <a href="/world-exploration " style="margin-left:75px">
				  
				   <i class="fa fas fa-globe" style="position: absolute;left:50px" ></i>
			      
		          <span>ä¸–ç•Œæ¢ç´¢</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-language"></i>
			
			å¤–è¯­
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/EngTOEFL " style="margin-left:75px">
				  
		          <span>ENï½œTOEFLç»éªŒ</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicEnglish " style="margin-left:75px">
				  
		          <span>ENï½œå­¦æœ¯è‹±è¯­</span>
                  </a>
                </li>
              
                <li>

                  <a href="/EngGrammar " style="margin-left:75px">
				  
		          <span>ENï½œè‹±è¯­è¯­æ³•</span>
                  </a>
                </li>
              
                <li>

                  <a href="/JpBasic " style="margin-left:75px">
				  
		          <span>JPï½œäº”åéŸ³å›¾</span>
                  </a>
                </li>
              
                <li>

                  <a href="/JpVocab " style="margin-left:75px">
				  
		          <span>JPï½œåŸºç¡€è¯æ±‡</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-code"></i>
			
			ç§‘ç ”
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/AcademicFoundation " style="margin-left:75px">
				  
		          <span>ç§‘ç ”åŸºç¡€æŠ€èƒ½</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicEnglish " style="margin-left:75px">
				  
		          <span>å­¦æœ¯è‹±è¯­</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicDL " style="margin-left:75px">
				  
		          <span>æ·±åº¦å­¦ä¹ </span>
                  </a>
                </li>
              
                <li>

                  <a href="/Pytorch " style="margin-left:75px">
				  
		          <span>Pytorch</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-keyboard"></i>
			
			AI
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/AI-basics " style="margin-left:75px">
				  
		          <span>AI-å¤§æ¨¡å‹</span>
                  </a>
                </li>
              
                <li>

                  <a href="/ " style="margin-left:75px">
				  
		          <span>AI-ç›¸å…³ç†è®º</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AI-tools " style="margin-left:75px">
				  
		          <span>AI-å®ç”¨å·¥å…·</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AI-news " style="margin-left:75px">
				  
		          <span>AI-å¥½æ–‡æ”¶å½•</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-keyboard"></i>
			
			OI
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%9F%A5%E8%AF%86%E7%82%B9/ " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œçŸ¥è¯†ç‚¹</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E5%8D%95/ " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œé¢˜å•</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œé¢˜è§£</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E5%A4%8D%E7%9B%98/ " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œå¤ç›˜</span>
                  </a>
                </li>
              
                <li>

                  <a href="/tags/%E6%9C%AF%E8%AF%AD/ " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œæœ¯è¯­</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œè®­ç»ƒ</span>
                  </a>
                </li>
              
                <li>

                  <a href="/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%BB%8F%E9%AA%8C%E5%B8%96 " style="margin-left:75px">
				  
		          <span>ä¿¡æ¯å¥¥èµ›ï½œç»éªŒå¸–</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/Codeforces%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>Codeforcesé¢˜è§£</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/AtCoder%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>AtCoderé¢˜è§£</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/AtCoder%E5%A4%8D%E7%9B%98/ " style="margin-left:75px">
				  
		          <span>AtCoderå¤ç›˜</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-door-open"></i>
			
			æ”¶è—é¦†
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/music-live " style="margin-left:75px">
				  
		          <span>éŸ³ä¹ï½œLiveç°åœº</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-travel " style="margin-left:75px">
				  
		          <span>é£æ™¯ï½œäº‘æ¸¸ä¸–ç•Œ</span>
                  </a>
                </li>
              
                <li>

                  <a href="/co-study " style="margin-left:75px">
				  
		          <span>æ•ˆç‡ï½œé™ªä¼´å­¦ä¹ </span>
                  </a>
                </li>
              
                <li>

                  <a href="/advice " style="margin-left:75px">
				  
		          <span>æå‡ï½œç»éªŒåˆ†äº«</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-role-model " style="margin-left:75px">
				  
		          <span>è®¿è°ˆï½œæ¦œæ ·å‰è¾ˆ</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-sentences " style="margin-left:75px">
				  
		          <span>æ–‡å­¦ï½œé‡‘å¥æ‘˜å½•</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Ricky2333" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Ricky2333" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>


    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('è¯·è¾“å…¥è®¿é—®æœ¬æ–‡ç« çš„å¯†ç ')).toString(CryptoJS.enc.Hex)) {
                alert('å¯†ç é”™è¯¯ï¼Œå°†è¿”å›ä¸»é¡µï¼');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/18.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
        background-color: rgb(255, 255, 255,0.7);
        border-radius: 10px;
        box-shadow: 0 10px 35px 2px rgba(0, 0, 0, .15), 0 5px 15px rgba(0, 0, 0, .07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        /* color: #42b983; */
        color: #20BDFF;
        font-weight: 700;
        /* text-decoration: underline; */
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
        /* color: #20BDFF; */
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">æ— æ ‡ç­¾</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    33 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- æ˜¯å¦åŠ è½½ä½¿ç”¨è‡ªå¸¦çš„ prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Ricky-ã®-å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯"><a href="#Ricky-ã®-å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯" class="headerlink" title="Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯"></a>Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯</h1><h2 id="åŸºç¡€æ¦‚å¿µ"><a href="#åŸºç¡€æ¦‚å¿µ" class="headerlink" title="åŸºç¡€æ¦‚å¿µ"></a>åŸºç¡€æ¦‚å¿µ</h2><h4 id="Tokens-ä¸-Embeddings"><a href="#Tokens-ä¸-Embeddings" class="headerlink" title="Tokens ä¸ Embeddings"></a>Tokens ä¸ Embeddings</h4><p>Tokens ä¸ Embeddings çš„åŒºåˆ«</p>
<table>
<thead>
<tr>
<th align="center">Concept</th>
<th align="center">Tokens</th>
<th align="center"><strong>Embeddings</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>What is it?</strong></td>
<td align="center">A <strong>textual unit</strong> (like a word or subword)</td>
<td align="center">A <strong>numerical vector</strong> that represents a tokenâ€™s meaning</td>
</tr>
<tr>
<td align="center"><strong>Data type</strong></td>
<td align="center">Discrete integers (IDs)</td>
<td align="center">Dense floating-point tensors</td>
</tr>
<tr>
<td align="center"><strong>Example</strong></td>
<td align="center"><code>"insulin"</code> â†’ <code>2345</code> (token ID)</td>
<td align="center"><code>[-0.01, 0.32, ..., 1.25]</code> (vector of 1024 floats)</td>
</tr>
<tr>
<td align="center"><strong>Used for</strong></td>
<td align="center">Input to the model (after tokenization)</td>
<td align="center">Internal representation in the model</td>
</tr>
<tr>
<td align="center"><strong>Reversible?</strong></td>
<td align="center">âœ… Can convert back to text via tokenizer</td>
<td align="center">âŒ Cannot easily recover original text from embedding</td>
</tr>
</tbody></table>
<p>Text â†’ Tokens â†’ Embeddings çš„å¯è§†åŒ–</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ <span class="token string">"What condition is characterized by..."</span>      â”‚  â†’ text
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                   Tokenization
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  <span class="token string">"What"</span>    â”‚ <span class="token string">"condition"</span>â”‚    <span class="token string">"is"</span>    â”‚   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>      â”‚  â†’ tokens
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           <span class="token punctuation">[</span><span class="token number">1023</span><span class="token punctuation">,</span> <span class="token number">5678</span><span class="token punctuation">,</span> <span class="token number">2345</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>  â†’ token IDs
                        â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Language Model     â”‚   â†’   Language Model
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚      last_hidden_state <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>      â”‚ â†’ token embeddings
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
             Mean across tokens <span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
                        â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Sentence Embedding <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span> â”‚  â†’ sentence embeddings
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="å¾®è°ƒ"><a href="#å¾®è°ƒ" class="headerlink" title="å¾®è°ƒ"></a>å¾®è°ƒ</h3><h4 id="å¾®è°ƒæ¦‚å¿µæ¸…å•"><a href="#å¾®è°ƒæ¦‚å¿µæ¸…å•" class="headerlink" title="å¾®è°ƒæ¦‚å¿µæ¸…å•"></a>å¾®è°ƒæ¦‚å¿µæ¸…å•</h4><ul>
<li>ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒ ï¼Ÿâœ…ï¼ˆ2025.3.11ï¼‰</li>
<li>å¾®è°ƒçš„æ¦‚å¿µ âœ… ï¼ˆ2025.3.11ï¼‰</li>
<li>å¾®è°ƒçš„æ­¥éª¤ âœ… ï¼ˆ2025.3.11ï¼‰</li>
<li>å¾®è°ƒçš„ç­–ç•¥åˆ†ç±» âœ… ï¼ˆ2025.3.11ï¼‰</li>
<li>å¾®è°ƒçš„æ¡†æ¶</li>
<li>å…·ä½“çš„å¾®è°ƒæ¡†æ¶</li>
<li>å¾®è°ƒçš„æŒ‘æˆ˜ âœ… ï¼ˆ2025.3.11ï¼‰</li>
<li>å¾®è°ƒçš„ç›¸å…³æœ¯è¯­</li>
</ul>
<h4 id="ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒï¼Ÿ"></a>ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒï¼Ÿ</h4><p>è™½ç„¶é¢„è®­ç»ƒçš„ LLMï¼ˆå¦‚ GPT-4ã€LLaMAï¼‰å·²ç»å­¦åˆ°äº†å¤§é‡çŸ¥è¯†ï¼Œä½†åœ¨å…·ä½“åº”ç”¨ä¸­ï¼Œå¯èƒ½ä»ç„¶æœ‰ä»¥ä¸‹é—®é¢˜ï¼š</p>
<ul>
<li><strong>é¢†åŸŸé€‚åº”æ€§ä¸è¶³</strong>ï¼šå¦‚åŒ»ç–—ã€æ³•å¾‹ã€é‡‘èç­‰ä¸“ä¸šé¢†åŸŸçš„è¯­è¨€å’Œè¡¨è¾¾æ–¹å¼ã€‚</li>
<li><strong>ä»»åŠ¡é’ˆå¯¹æ€§ä¸å¼º</strong>ï¼šå¦‚æƒ…æ„Ÿåˆ†æã€æ‘˜è¦ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ç‰¹å®šä»»åŠ¡ã€‚</li>
<li><strong>æœªæŒæ¡ç‰¹å®šé£æ ¼</strong>ï¼šæ¯”å¦‚è®© ChatGPT è¯´è¯æ›´åƒæŸä¸ªå“ç‰Œï¼Œæˆ–è€…é€‚åº”æŸç§è¯­æ°”ã€‚</li>
</ul>
<h4 id="å¾®è°ƒçš„æ¦‚å¿µ"><a href="#å¾®è°ƒçš„æ¦‚å¿µ" class="headerlink" title="å¾®è°ƒçš„æ¦‚å¿µ"></a>å¾®è°ƒçš„æ¦‚å¿µ</h4><p>å¤§æ¨¡å‹å¾®è°ƒæ˜¯æŒ‡åœ¨é¢„è®­ç»ƒå¤§æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡ç‰¹å®šä»»åŠ¡çš„æ•°æ®å¯¹å¤§æ¨¡å‹è¿›ä¸€æ­¥è®­ç»ƒï¼ˆä¿®æ”¹å¤§æ¨¡å‹çš„éƒ¨åˆ†å‚æ•°ã€è°ƒæ•´å¤§æ¨¡å‹çš„ç»“æ„ç­‰ï¼‰ï¼Œä»¥æå‡å¤§æ¨¡å‹åœ¨è¯¥ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</p>
<h4 id="å¾®è°ƒçš„æ­¥éª¤"><a href="#å¾®è°ƒçš„æ­¥éª¤" class="headerlink" title="å¾®è°ƒçš„æ­¥éª¤"></a>å¾®è°ƒçš„æ­¥éª¤</h4><ul>
<li>å‡†å¤‡å¾®è°ƒæ•°æ®é›†</li>
<li>å‡†å¤‡é¢„è®­ç»ƒæ¨¡å‹</li>
<li>è°ƒæ•´æ¨¡å‹ç»“æ„ï¼ˆè°ƒæ•´æ¨¡å‹çš„è¾“å‡ºå±‚ï¼‰</li>
<li>ä½¿ç”¨å¾®è°ƒæŠ€æœ¯è¿›è¡Œè®­ç»ƒ</li>
<li>éªŒè¯ä¸æµ‹è¯•</li>
</ul>
<h4 id="å¾®è°ƒçš„ç­–ç•¥åˆ†ç±»"><a href="#å¾®è°ƒçš„ç­–ç•¥åˆ†ç±»" class="headerlink" title="å¾®è°ƒçš„ç­–ç•¥åˆ†ç±»"></a>å¾®è°ƒçš„ç­–ç•¥åˆ†ç±»</h4><ul>
<li><strong>å…¨æ¨¡å‹å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰</strong><ul>
<li>å¾®è°ƒæ‰€æœ‰å‚æ•°ï¼Œé€‚åˆæ•°æ®å……è¶³çš„æƒ…å†µã€‚</li>
</ul>
</li>
<li><strong>å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFT, Parameter Efficient Fine-Tuningï¼‰</strong><ul>
<li>åªæ›´æ–°æ¨¡å‹çš„ä¸€éƒ¨åˆ†å‚æ•°ï¼Œè€Œå†»ç»“å¤§éƒ¨åˆ†å‚æ•°ï¼Œå‡å°‘è®¡ç®—é‡ã€‚</li>
<li><strong>ä½ç§©é€‚åº”å¾®è°ƒï¼ˆLoRAï¼ŒLow-Rank Adaptationï¼‰</strong><ul>
<li>åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡çŸ©é˜µä¸Šæ·»åŠ ä½ç§©çŸ©é˜µï¼Œåªè®­ç»ƒè¿™äº›ä½ç§©çŸ©é˜µï¼Œä»è€Œå¤§å¹…å‡å°‘éœ€è¦è®­ç»ƒçš„å‚æ•°æ•°é‡ã€‚</li>
</ul>
</li>
<li><strong>é€‚é…å™¨å¾®è°ƒï¼ˆAdapter Fine-Tuningï¼‰</strong><ul>
<li>åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸­æ’å…¥å°çš„é€‚é…å™¨æ¨¡å—ï¼Œåªè®­ç»ƒè¿™äº›é€‚é…å™¨æ¨¡å—ï¼Œè€Œä¿æŒé¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ä¸å˜ã€‚é€‚é…å™¨æ¨¡å—é€šå¸¸æ˜¯ä¸€ä¸ªå°çš„ç¥ç»ç½‘ç»œå±‚ã€‚</li>
</ul>
</li>
</ul>
</li>
<li><strong>æç¤ºå¾®è°ƒï¼ˆPrompt Tuningï¼ŒP-tuningï¼‰</strong><ul>
<li>æç¤ºå¾®è°ƒæ˜¯ä¸€ç§æ–°å…´çš„å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡åœ¨è¾“å…¥ä¸­æ·»åŠ ç‰¹å®šçš„æç¤ºï¼Œå¼•å¯¼æ¨¡å‹ç”ŸæˆæœŸæœ›çš„è¾“å‡ºï¼Œè€Œä¸éœ€è¦å¤§é‡ä¿®æ”¹æ¨¡å‹å‚æ•°ã€‚</li>
</ul>
</li>
<li><strong>çŸ¥è¯†è’¸é¦å¾®è°ƒï¼ˆKnowledge Distillation Fine-Tuningï¼‰</strong><ul>
<li>çŸ¥è¯†è’¸é¦å¾®è°ƒæ˜¯æŒ‡ä½¿ç”¨ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆæ¨¡å‹ï¼‰æ¥æŒ‡å¯¼ä¸€ä¸ªå°æ¨¡å‹ï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰çš„è®­ç»ƒã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå­¦ç”Ÿæ¨¡å‹å¯ä»¥å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ï¼Œä»è€Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½ã€‚</li>
</ul>
</li>
</ul>
<h4 id="å¾®è°ƒçš„æŒ‘æˆ˜"><a href="#å¾®è°ƒçš„æŒ‘æˆ˜" class="headerlink" title="å¾®è°ƒçš„æŒ‘æˆ˜"></a>å¾®è°ƒçš„æŒ‘æˆ˜</h4><ul>
<li><strong>æ•°æ®éœ€æ±‚</strong>ï¼šå¾®è°ƒéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œæ•°æ®ä¸è¶³æ—¶æ•ˆæœå—é™ã€‚</li>
<li><strong>è®¡ç®—èµ„æº</strong>ï¼šå¤§æ¨¡å‹å¾®è°ƒéœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼Œå°¤å…¶æ˜¯å…¨æ¨¡å‹å¾®è°ƒã€‚</li>
</ul>
<h4 id="å¾®è°ƒï¼ˆFine-tuningï¼‰ç›¸å…³æœ¯è¯­æ€»ç»“è¡¨"><a href="#å¾®è°ƒï¼ˆFine-tuningï¼‰ç›¸å…³æœ¯è¯­æ€»ç»“è¡¨" class="headerlink" title="å¾®è°ƒï¼ˆFine-tuningï¼‰ç›¸å…³æœ¯è¯­æ€»ç»“è¡¨"></a>å¾®è°ƒï¼ˆFine-tuningï¼‰ç›¸å…³æœ¯è¯­æ€»ç»“è¡¨</h4><table>
<thead>
<tr>
<th align="center"><strong>ä¸­æ–‡æœ¯è¯­</strong></th>
<th align="center"><strong>è‹±æ–‡æœ¯è¯­</strong></th>
<th><strong>æœ¯è¯­è§£é‡Š</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">é¢„è®­ç»ƒ</td>
<td align="center">Pre-training</td>
<td>åœ¨å¤§è§„æ¨¡æ— ç›‘ç£æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶å­¦ä¹ é€šç”¨è¯­è¨€ç‰¹å¾ã€‚</td>
</tr>
<tr>
<td align="center">å¾®è°ƒ</td>
<td align="center">Fine-tuning</td>
<td>åœ¨ç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡æ•°æ®ä¸Šè¿›ä¸€æ­¥è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥æå‡å…¶æ€§èƒ½ã€‚</td>
</tr>
<tr>
<td align="center">ç›‘ç£å¾®è°ƒ</td>
<td align="center">Supervised Fine-tuning</td>
<td>ä½¿ç”¨å¸¦æœ‰æ ‡ç­¾çš„æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œè®©æ¨¡å‹å­¦ä¹ ä»»åŠ¡çš„æ­£ç¡®è¾“å‡ºã€‚</td>
</tr>
<tr>
<td align="center">ä½ç§©é€‚é…</td>
<td align="center">LoRA (Low-Rank Adaptation)</td>
<td>ä¸€ç§é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡å¯¹æƒé‡çŸ©é˜µæ·»åŠ ä½ç§©é€‚é…å±‚æ¥å‡å°‘è®¡ç®—æˆæœ¬ã€‚</td>
</tr>
<tr>
<td align="center">å‚æ•°é«˜æ•ˆå¾®è°ƒ</td>
<td align="center">PEFT (Parameter Efficient Fine-tuning)</td>
<td>åªè°ƒæ•´éƒ¨åˆ†å‚æ•°ï¼ˆå¦‚ LoRAã€Adapterï¼‰ï¼Œè€Œéæ•´ä¸ªæ¨¡å‹ï¼Œä»¥å‡å°‘è®¡ç®—éœ€æ±‚ã€‚</td>
</tr>
<tr>
<td align="center">é€‚é…å™¨</td>
<td align="center">Adapter</td>
<td>åœ¨ Transformer å±‚ä¹‹é—´æ’å…¥çš„å°å‹ç½‘ç»œæ¨¡å—ï¼Œç”¨äºé«˜æ•ˆå¾®è°ƒã€‚</td>
</tr>
<tr>
<td align="center">å…¨å‚æ•°å¾®è°ƒ</td>
<td align="center">Full Fine-tuning</td>
<td>è°ƒæ•´æ•´ä¸ªæ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œé€šå¸¸éœ€è¦æ›´é«˜çš„è®¡ç®—èµ„æºã€‚</td>
</tr>
<tr>
<td align="center">æŒ‡ä»¤å¾®è°ƒ</td>
<td align="center">Instruction Fine-tuning</td>
<td>é€šè¿‡æä¾›ä¸åŒçš„æŒ‡ä»¤æ•°æ®ï¼Œä½¿æ¨¡å‹æ›´æ“…é•¿éµå¾ªæŒ‡ä»¤ã€‚</td>
</tr>
<tr>
<td align="center">å¼ºåŒ–å­¦ä¹ å¾®è°ƒ</td>
<td align="center">RLHF (Reinforcement Learning from Human Feedback)</td>
<td>ç»“åˆäººç±»åé¦ˆè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿æ¨¡å‹çš„å›ç­”æ›´ç¬¦åˆäººç±»æœŸæœ›ã€‚</td>
</tr>
<tr>
<td align="center">æ•°æ®é›†</td>
<td align="center">Dataset</td>
<td>ç”¨äºå¾®è°ƒçš„æ–‡æœ¬æˆ–ä»»åŠ¡æ•°æ®ï¼Œé€šå¸¸åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚</td>
</tr>
<tr>
<td align="center">è¿ç§»å­¦ä¹ </td>
<td align="center">Transfer Learning</td>
<td>åœ¨ä¸€ä¸ªä»»åŠ¡ä¸Šè®­ç»ƒçš„æ¨¡å‹æƒé‡ç”¨äºå¦ä¸€ä¸ªä»»åŠ¡ï¼Œä»¥å‡å°‘è®­ç»ƒæˆæœ¬ã€‚</td>
</tr>
<tr>
<td align="center">æ¸©åº¦å‚æ•°</td>
<td align="center">Temperature</td>
<td>æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œè¾ƒé«˜æ¸©åº¦å¢åŠ åˆ›é€ æ€§ï¼Œè¾ƒä½æ¸©åº¦å¢åŠ ç¡®å®šæ€§ã€‚</td>
</tr>
<tr>
<td align="center">Token é™åˆ¶</td>
<td align="center">Token Limit</td>
<td>LLM å¤„ç†çš„æœ€å¤§ token æ•°ï¼Œå½±å“è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</td>
</tr>
<tr>
<td align="center">è®­ç»ƒæŸå¤±</td>
<td align="center">Training Loss</td>
<td>è¡¡é‡æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„è¯¯å·®ï¼Œå¸¸è§æŸå¤±å‡½æ•°æœ‰äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰ã€‚</td>
</tr>
<tr>
<td align="center">éªŒè¯æŸå¤±</td>
<td align="center">Validation Loss</td>
<td>è¡¡é‡æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°ï¼Œç”¨äºé¿å…è¿‡æ‹Ÿåˆã€‚</td>
</tr>
<tr>
<td align="center">è¿‡æ‹Ÿåˆ</td>
<td align="center">Overfitting</td>
<td>æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šæ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚</td>
</tr>
<tr>
<td align="center">æ¢¯åº¦ç´¯ç§¯</td>
<td align="center">Gradient Accumulation</td>
<td>é€šè¿‡å¤šæ¬¡ç´¯ç§¯å°æ‰¹é‡æ¢¯åº¦æ¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡ï¼Œé™ä½æ˜¾å­˜éœ€æ±‚ã€‚</td>
</tr>
<tr>
<td align="center">æ¢¯åº¦è£å‰ª</td>
<td align="center">Gradient Clipping</td>
<td>é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸çš„æŠ€æœ¯ï¼Œé™åˆ¶æ¢¯åº¦çš„æœ€å¤§å€¼ã€‚</td>
</tr>
<tr>
<td align="center">å­¦ä¹ ç‡</td>
<td align="center">Learning Rate</td>
<td>æ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°æ­¥ä¼çš„è¶…å‚æ•°ï¼Œå½±å“æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚</td>
</tr>
<tr>
<td align="center">é¢„è®­ç»ƒæƒé‡</td>
<td align="center">Pretrained Weights</td>
<td>ç»è¿‡å¤§è§„æ¨¡æ•°æ®è®­ç»ƒçš„æ¨¡å‹å‚æ•°ï¼Œå¯ä»¥åœ¨å¾®è°ƒæ—¶è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚</td>
</tr>
<tr>
<td align="center">AdamW ä¼˜åŒ–å™¨</td>
<td align="center">AdamW Optimizer</td>
<td>ä¸€ç§æ”¹è¿›çš„ Adam ä¼˜åŒ–å™¨ï¼Œå¹¿æ³›ç”¨äº LLM å¾®è°ƒã€‚</td>
</tr>
<tr>
<td align="center">è®­ç»ƒæ­¥æ•°</td>
<td align="center">Training Steps</td>
<td>è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œå‚æ•°æ›´æ–°çš„æ¬¡æ•°ï¼Œå½±å“æ¨¡å‹çš„æ”¶æ•›æƒ…å†µã€‚</td>
</tr>
<tr>
<td align="center">Batch Size</td>
<td align="center">æ‰¹æ¬¡å¤§å°</td>
<td>è®­ç»ƒæ—¶ä¸€æ¬¡å¤„ç†çš„æ•°æ®æ ·æœ¬æ•°é‡ï¼Œå½±å“è®¡ç®—å¼€é”€å’Œæ”¶æ•›é€Ÿåº¦ã€‚</td>
</tr>
<tr>
<td align="center">Prompt å·¥ç¨‹</td>
<td align="center">Prompt Engineering</td>
<td>é€šè¿‡è®¾è®¡è¾“å…¥æç¤ºè¯æ¥å¼•å¯¼ LLM ç”ŸæˆæœŸæœ›çš„è¾“å‡ºã€‚</td>
</tr>
<tr>
<td align="center">æŒ‡ä»¤æ•°æ®</td>
<td align="center">Instruction Data</td>
<td>è®­ç»ƒæ¨¡å‹éµå¾ªæŒ‡ä»¤æ ¼å¼çš„æ•°æ®ï¼Œå¦‚ â€œè¯·æ€»ç»“è¿™ç¯‡æ–‡ç« â€ã€‚</td>
</tr>
<tr>
<td align="center">å¢é‡å¾®è°ƒ</td>
<td align="center">Incremental Fine-tuning</td>
<td>åœ¨å·²æœ‰çš„å¾®è°ƒæ¨¡å‹ä¸Šè¿›ä¸€æ­¥è®­ç»ƒï¼Œè€Œä¸æ˜¯ä»åŸºç¡€æ¨¡å‹å¼€å§‹ã€‚</td>
</tr>
<tr>
<td align="center">æ··åˆç²¾åº¦è®­ç»ƒ</td>
<td align="center">Mixed Precision Training</td>
<td>ç»“åˆ FP16 å’Œ FP32 è¿›è¡Œè®­ç»ƒï¼Œä»¥å‡å°‘æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿè®¡ç®—ã€‚</td>
</tr>
<tr>
<td align="center">é›¶æ ·æœ¬å­¦ä¹ </td>
<td align="center">Zero-shot Learning</td>
<td>æ¨¡å‹åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚</td>
</tr>
<tr>
<td align="center">å°‘æ ·æœ¬å­¦ä¹ </td>
<td align="center">Few-shot Learning</td>
<td>é€šè¿‡å°‘é‡ç¤ºä¾‹è®©æ¨¡å‹é€‚åº”æ–°ä»»åŠ¡ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</td>
</tr>
<tr>
<td align="center">å…¨ç²¾åº¦è®­ç»ƒ</td>
<td align="center">Full Precision Training</td>
<td>ä½¿ç”¨ FP32 è¿›è¡Œè®­ç»ƒï¼Œè®¡ç®—ç²¾åº¦é«˜ä½†æ˜¾å­˜å ç”¨å¤§ã€‚</td>
</tr>
</tbody></table>
<hr>
<h2 id="Hugging-Face-å®æˆ˜"><a href="#Hugging-Face-å®æˆ˜" class="headerlink" title="Hugging Face å®æˆ˜"></a>Hugging Face å®æˆ˜</h2><h3 id="å¹³å°ç®€ä»‹"><a href="#å¹³å°ç®€ä»‹" class="headerlink" title="å¹³å°ç®€ä»‹"></a>å¹³å°ç®€ä»‹</h3><p><strong>Hugging Face</strong> æ˜¯ä¸€å®¶ä¸“æ³¨äº <strong>è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰</strong> å’Œ <strong>äººå·¥æ™ºèƒ½æ¨¡å‹å¼€æºä¸éƒ¨ç½²</strong> çš„å…¬å¸ã€‚</p>
<p>å®ƒæä¾›äº†ï¼š</p>
<ul>
<li>âœ… å¤§é‡é¢„è®­ç»ƒæ¨¡å‹ï¼ˆBERTã€GPTã€T5 ç­‰ï¼‰</li>
<li>âœ… ä¸€ä¸ªç»Ÿä¸€çš„ Python åº“ï¼ˆ<code>transformers</code>ï¼‰</li>
<li>âœ… è®­ç»ƒã€å¾®è°ƒã€éƒ¨ç½²ã€åˆ†äº«æ¨¡å‹çš„ä¸€æ•´å¥—å·¥å…·</li>
</ul>
<p>Hugging Face çš„ <strong>æ ¸å¿ƒäº§å“</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>åç§°</th>
<th>åŠŸèƒ½è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ğŸ¤— transformers</strong></td>
<td>ä¸€ä¸ªå¼ºå¤§æ˜“ç”¨çš„ Python åº“ï¼Œæ”¯æŒåŠ è½½ã€ä½¿ç”¨ã€è®­ç»ƒå„ç§é¢„è®­ç»ƒ transformer æ¨¡å‹</td>
</tr>
<tr>
<td><strong>ğŸ¤— Datasets</strong></td>
<td>æä¾›ä¸Šåƒä¸ªæ ‡å‡†æ•°æ®é›†ï¼ˆå¦‚ SQuADã€SST-2ã€CoQAï¼‰</td>
</tr>
<tr>
<td><strong>ğŸ¤— Hub</strong></td>
<td>ä¸€ä¸ªæ¨¡å‹ç¤¾åŒºå¹³å°ï¼Œä½ å¯ä»¥ä¸Šä¼ ã€ä¸‹è½½åˆ«äººè®­ç»ƒå¥½çš„æ¨¡å‹</td>
</tr>
<tr>
<td><strong>ğŸ¤— Spaces</strong></td>
<td>å…è´¹æ‰˜ç®¡å’Œå±•ç¤ºä½ çš„ AI é¡¹ç›®ï¼ˆæ”¯æŒ Gradioã€Streamlit ç­‰ï¼‰</td>
</tr>
<tr>
<td><strong>ğŸ¤— Auto Classes</strong></td>
<td>æä¾›ç»Ÿä¸€çš„æ¨¡å‹åŠ è½½æ¥å£ï¼ˆå¦‚ <code>AutoTokenizer</code>, <code>AutoModel</code>ï¼‰ç®€åŒ–ä½¿ç”¨æµç¨‹</td>
</tr>
</tbody></table>
<hr>
<h3 id="æ¨¡å‹ä¸‹è½½"><a href="#æ¨¡å‹ä¸‹è½½" class="headerlink" title="æ¨¡å‹ä¸‹è½½"></a>æ¨¡å‹ä¸‹è½½</h3><p><strong><u>æ¨¡å‹åç§°ç»“æ„è§£æ</u></strong></p>
<table>
<thead>
<tr>
<th>éƒ¨åˆ†</th>
<th>ç¤ºä¾‹</th>
<th>å«ä¹‰</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ç»„ç»‡å/ä½œè€…</strong></td>
<td><code>bert-base-uncased</code>ï¼ˆæ— ç»„ç»‡ï¼‰<br> <code>facebook/bart-large</code></td>
<td>æ¨¡å‹å‘å¸ƒè€…ï¼Œé€šå¸¸æ˜¯ä½œè€…ã€ç ”ç©¶æœºæ„ã€å…¬å¸ç­‰</td>
</tr>
<tr>
<td><strong>æ¨¡å‹æ¶æ„</strong></td>
<td><code>bert</code>, <code>roberta</code>, <code>gpt2</code>, <code>t5</code>, <code>llama</code>, <code>distilbert</code></td>
<td>è¯´æ˜ä½¿ç”¨çš„ Transformer æ¶æ„ç±»å‹</td>
</tr>
<tr>
<td><strong>å¤§å°</strong></td>
<td><code>base</code>, <code>large</code>, <code>small</code></td>
<td>æ§åˆ¶å‚æ•°é‡å’Œæ¨¡å‹è§„æ¨¡</td>
</tr>
<tr>
<td><strong>å¤§å°å†™</strong></td>
<td><code>cased</code> / <code>uncased</code></td>
<td>è‹±æ–‡æ˜¯å¦åŒºåˆ†å¤§å°å†™ï¼ˆå¦‚ Apple â‰  appleï¼‰</td>
</tr>
<tr>
<td><strong>è¯­è¨€</strong></td>
<td><code>english</code>, <code>chinese</code>, <code>multilingual</code></td>
<td>æ”¯æŒçš„è¯­è¨€</td>
</tr>
<tr>
<td><strong>è®­ç»ƒä»»åŠ¡ / æ•°æ®é›†</strong></td>
<td><code>finetuned-sst-2</code>, <code>squad</code>, <code>cnn-dailymail</code></td>
<td>è¯´æ˜æ˜¯å¦åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¾®è°ƒè¿‡</td>
</tr>
<tr>
<td><strong>ç‰¹æ®Šè®­ç»ƒæ–¹æ³•</strong></td>
<td><code>wwm</code>, <code>whole-word-masking</code>, <code>ext</code>, <code>dapt</code>, <code>adapter</code></td>
<td>ç‰¹æ®ŠæŠ€æœ¯å¦‚å…¨è¯æ©ç ã€æ‰©å±•è®­ç»ƒã€é€‚é…å™¨ç­‰</td>
</tr>
</tbody></table>
<p><strong><u>å¸¸è§å‘½åå®ä¾‹è§£æ</u></strong></p>
<table>
<thead>
<tr>
<th>æ¨¡å‹å</th>
<th>å«ä¹‰</th>
</tr>
</thead>
<tbody><tr>
<td><code>bert-base-uncased</code></td>
<td>Google çš„åŸºç¡€ç‰ˆ BERTï¼Œä¸åŒºåˆ†å¤§å°å†™ï¼Œæœªå¾®è°ƒ</td>
</tr>
<tr>
<td><code>google-bert/bert-large-cased-whole-word-masking</code></td>
<td>æ›´å¤§ã€åŒºåˆ†å¤§å°å†™ã€ä½¿ç”¨å…¨è¯æ©ç çš„ BERT</td>
</tr>
<tr>
<td><code>distilbert-base-uncased-finetuned-sst-2-english</code></td>
<td>DistilBERT æ¨¡å‹ï¼ŒSST-2 ä¸Šè®­ç»ƒçš„è‹±æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹</td>
</tr>
<tr>
<td><code>facebook/bart-large-cnn</code></td>
<td>Facebook çš„ BART æ¨¡å‹ï¼Œå¾®è°ƒåœ¨ CNN æ–°é—»æ‘˜è¦ä»»åŠ¡ä¸Š</td>
</tr>
<tr>
<td><code>google/flan-t5-xl</code></td>
<td>Google çš„ FLAN T5 æ¨¡å‹ï¼Œè¶…å¤§ç‰ˆï¼Œé€‚åˆ zero-shot å¤šä»»åŠ¡</td>
</tr>
<tr>
<td><code>microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</code></td>
<td>å¾®è½¯è®­ç»ƒçš„ç”¨äºç”Ÿç‰©åŒ»å­¦çš„ PubMed-BERTï¼Œä¸“é—¨å¤„ç†è®ºæ–‡æ‘˜è¦</td>
</tr>
</tbody></table>
<p>å½“æ‰‹åŠ¨ä¸‹è½½ Hugging Face ä¸Šçš„ä¸€ä¸ªæ¨¡å‹ï¼ˆæ¯”å¦‚ <code>bert-base-uncased</code>ï¼‰ï¼Œ<strong>æœ€é‡è¦çš„æ–‡ä»¶</strong>æœ‰è¿™å‡ ç±»ï¼š</p>
<table>
<thead>
<tr>
<th>æ–‡ä»¶å</th>
<th>ä½œç”¨</th>
<th>æ˜¯å¦å¿…é¡»</th>
</tr>
</thead>
<tbody><tr>
<td><code>config.json</code></td>
<td>æ¨¡å‹ç»“æ„é…ç½®ï¼ˆå±‚æ•°ã€éšè—ç»´åº¦ã€åˆ†ç±»å¤´ç­‰ï¼‰</td>
<td>âœ…</td>
</tr>
<tr>
<td><code>pytorch_model.bin</code></td>
<td>æ¨¡å‹çš„æƒé‡ï¼ˆPyTorch æ ¼å¼ï¼‰</td>
<td>âœ…</td>
</tr>
<tr>
<td><code>tokenizer_config.json</code></td>
<td>åˆ†è¯å™¨çš„é…ç½®</td>
<td>âœ…</td>
</tr>
<tr>
<td><code>vocab.txt</code> æˆ– <code>merges.txt</code> + <code>vocab.json</code></td>
<td>è¯è¡¨ï¼ˆä¸åŒæ¨¡å‹æ ¼å¼ä¸åŒï¼‰</td>
<td>âœ…</td>
</tr>
<tr>
<td><code>special_tokens_map.json</code></td>
<td>ç‰¹æ®Š tokenï¼ˆå¦‚ <code>[CLS]</code>, <code>[SEP]</code>, <code>[MASK]</code>ï¼‰çš„å®šä¹‰</td>
<td>âš ï¸ æ¨è</td>
</tr>
<tr>
<td><code>tokenizer.json</code></td>
<td>åˆ†è¯å™¨çš„ fast version æ–‡ä»¶</td>
<td>âš ï¸ æ¨è</td>
</tr>
<tr>
<td><code>README.md</code></td>
<td>æ¨¡å‹è¯´æ˜æ–‡æ¡£</td>
<td>âŒ å¯é€‰</td>
</tr>
</tbody></table>
<hr>
<h3 id="ä»£ç åŸºç¡€"><a href="#ä»£ç åŸºç¡€" class="headerlink" title="ä»£ç åŸºç¡€"></a>ä»£ç åŸºç¡€</h3><h4 id="transformeråº“"><a href="#transformeråº“" class="headerlink" title="transformeråº“"></a>transformeråº“</h4><p><code>transformer</code>åº“æ˜¯ Hugging Face å‡ºå“çš„å¼€æºåº“ï¼Œç”¨äºï¼š</p>
<ul>
<li>ä¸‹è½½å’Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ BERT, GPT, BioGPT, T5 ç­‰ï¼‰</li>
<li>å¿«é€Ÿè¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€æ–‡æœ¬ç”Ÿæˆã€é—®ç­”ã€ç¿»è¯‘ã€æ‘˜è¦ç­‰ä»»åŠ¡</li>
<li>æä¾›ç»Ÿä¸€çš„ <strong>Tokenizer</strong>, <strong>Model</strong>, å’Œ <strong>Pipeline</strong> æ¥å£</li>
</ul>
<h5 id="ğŸ—‚ï¸-transformer-æ ¸å¿ƒç»„ä»¶"><a href="#ğŸ—‚ï¸-transformer-æ ¸å¿ƒç»„ä»¶" class="headerlink" title="ğŸ—‚ï¸ transformer æ ¸å¿ƒç»„ä»¶"></a>ğŸ—‚ï¸ <code>transformer</code> æ ¸å¿ƒç»„ä»¶</h5><table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>åŠŸèƒ½ç®€è¿°</th>
</tr>
</thead>
<tbody><tr>
<td><code>AutoTokenizer</code> / <code>XXXTokenizer</code></td>
<td>æŠŠæ–‡æœ¬è½¬æˆ tokens å’Œ ids</td>
</tr>
<tr>
<td><code>AutoModel</code> / <code>XXXModel</code></td>
<td>è¿”å›éšè—çŠ¶æ€ï¼ˆembeddingsï¼‰</td>
</tr>
<tr>
<td><code>AutoModelForCausalLM</code> / <code>XXXForCausalLM</code></td>
<td>ç”¨äºæ–‡æœ¬ç”Ÿæˆ</td>
</tr>
<tr>
<td><code>pipeline</code></td>
<td>å¿«é€Ÿä½¿ç”¨æ¨¡å‹è¿›è¡Œä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æã€QAï¼‰</td>
</tr>
</tbody></table>
<h5 id="ğŸ§ -ä¸åŒæ¨¡å‹ä»»åŠ¡çš„é€‰æ‹©"><a href="#ğŸ§ -ä¸åŒæ¨¡å‹ä»»åŠ¡çš„é€‰æ‹©" class="headerlink" title="ğŸ§  ä¸åŒæ¨¡å‹ä»»åŠ¡çš„é€‰æ‹©"></a>ğŸ§  ä¸åŒæ¨¡å‹ä»»åŠ¡çš„é€‰æ‹©</h5><table>
<thead>
<tr>
<th>ä»»åŠ¡</th>
<th>æ¨¡å‹ç±»</th>
<th>ç¤ºä¾‹æ¨¡å‹å</th>
</tr>
</thead>
<tbody><tr>
<td>æ–‡æœ¬åµŒå…¥</td>
<td><code>AutoModel</code></td>
<td><code>bert-base-uncased</code></td>
</tr>
<tr>
<td>æ–‡æœ¬åˆ†ç±»</td>
<td><code>AutoModelForSequenceClassification</code></td>
<td><code>distilbert-base-uncased-finetuned-sst-2-english</code></td>
</tr>
<tr>
<td>æ–‡æœ¬ç”Ÿæˆ</td>
<td><code>AutoModelForCausalLM</code></td>
<td><code>gpt2</code>, <code>BioGPT</code></td>
</tr>
<tr>
<td>é—®ç­”ç³»ç»Ÿ</td>
<td><code>AutoModelForQuestionAnswering</code></td>
<td><code>distilbert-base-uncased-distilled-squad</code></td>
</tr>
<tr>
<td>ç¿»è¯‘</td>
<td><code>AutoModelForSeq2SeqLM</code></td>
<td><code>t5-small</code>, <code>facebook/mbart-large-50-many-to-many-mmt</code></td>
</tr>
</tbody></table>
<hr>
<h4 id="pipeline-çš„ä½¿ç”¨"><a href="#pipeline-çš„ä½¿ç”¨" class="headerlink" title="pipeline çš„ä½¿ç”¨"></a>pipeline çš„ä½¿ç”¨</h4><hr>
<h4 id="ä¸åŒä»»åŠ¡çš„ç®€å•ç¤ºä¾‹"><a href="#ä¸åŒä»»åŠ¡çš„ç®€å•ç¤ºä¾‹" class="headerlink" title="ä¸åŒä»»åŠ¡çš„ç®€å•ç¤ºä¾‹"></a>ä¸åŒä»»åŠ¡çš„ç®€å•ç¤ºä¾‹</h4><h5 id="ğŸ“˜-å¥å­-x2F-æ–‡æœ¬åµŒå…¥ï¼ˆAutoModelï¼‰"><a href="#ğŸ“˜-å¥å­-x2F-æ–‡æœ¬åµŒå…¥ï¼ˆAutoModelï¼‰" class="headerlink" title="ğŸ“˜ å¥å­/æ–‡æœ¬åµŒå…¥ï¼ˆAutoModelï¼‰"></a>ğŸ“˜ <strong>å¥å­/æ–‡æœ¬åµŒå…¥ï¼ˆ<code>AutoModel</code>ï¼‰</strong></h5><p><code>AutoModel</code> åªè¿”å› <strong>hidden states</strong>ï¼Œä¸åŒ…å«åˆ†ç±»å¤´ï¼ˆä¸è¿›è¡Œé¢„æµ‹ï¼Œ<strong>åªåšç‰¹å¾æå–</strong>ï¼‰ã€‚</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel

<span class="token comment"># åŠ è½½æœ¬åœ°ä¿å­˜çš„ DistilBERT æ¨¡å‹å’Œåˆ†è¯å™¨</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># è¾“å…¥å¥å­</span>
text <span class="token operator">=</span> <span class="token string">"Transformers are powerful models for NLP."</span>

<span class="token comment"># ä½¿ç”¨åˆ†è¯å™¨å°†å¥å­è½¬ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œæ‰§è¡Œå‰å‘ä¼ æ’­</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># å¯¹æ‰€æœ‰ token çš„éšè—çŠ¶æ€åšå¹³å‡ï¼Œå¾—åˆ°å¥å­çº§åˆ«çš„å‘é‡è¡¨ç¤º</span>
sentence_embedding <span class="token operator">=</span> outputs<span class="token punctuation">.</span>last_hidden_state<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°Embeddingçš„å½¢çŠ¶ï¼ˆåº”è¯¥æ˜¯ [1, hidden_size]ï¼Œå¦‚ [1, 768]ï¼‰</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sentence_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>torch.Size([1, 768])</p>
</blockquote>
<hr>
<h5 id="ğŸ§¾-æ–‡æœ¬ç”Ÿæˆï¼ˆAutoModelForCausalLMï¼‰"><a href="#ğŸ§¾-æ–‡æœ¬ç”Ÿæˆï¼ˆAutoModelForCausalLMï¼‰" class="headerlink" title="ğŸ§¾ æ–‡æœ¬ç”Ÿæˆï¼ˆAutoModelForCausalLMï¼‰"></a>ğŸ§¾ <strong>æ–‡æœ¬ç”Ÿæˆï¼ˆ<code>AutoModelForCausalLM</code>ï¼‰</strong></h5><p><code>AutoModelForCausalLM</code> æ˜¯ Hugging Face çš„è‡ªåŠ¨æ¨¡å‹åŠ è½½å™¨çš„ä¸€ç§ï¼Œç”¨äºåŠ è½½ <strong>å› æœè¯­è¨€å»ºæ¨¡ï¼ˆCausal Language Modelingï¼‰</strong> çš„æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç”¨äºã€Œç»™å®šå‰æ–‡ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼ˆtokenï¼‰ã€çš„åœºæ™¯ã€‚</p>
<blockquote>
<p>ğŸ§  â€œCausal LMâ€ æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ</p>
<p><strong>Causal = å› æœæ€§</strong>ï¼šåªèƒ½çœ‹åˆ°â€œè¿‡å»â€çš„è¯ï¼Œä¸èƒ½çœ‹åˆ°æœªæ¥çš„è¯ã€‚</p>
<p>è®­ç»ƒç›®æ ‡ï¼šé¢„æµ‹å½“å‰ token åªä¾èµ–äºå®ƒå·¦è¾¹ï¼ˆå‰é¢çš„ï¼‰tokenã€‚</p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

<span class="token comment"># Load GPT-2 tokenizer and model (causal language model)</span>
model_path <span class="token operator">=</span> <span class="token string">'***/gpt2'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Define prompt for text generation</span>
prompt <span class="token operator">=</span> <span class="token string">"The future of medicine is"</span>

<span class="token comment"># Tokenize input (returns dictionary with input_ids and attention_mask)</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># Generate text using sampling method</span>
output_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
    <span class="token operator">**</span>inputs<span class="token punctuation">,</span>  <span class="token comment"># Unpack tokenized inputs</span>
    max_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># Maximum total tokens (input + generated)</span>
    do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># Enable probabilistic sampling</span>
    top_k<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># Consider top 50 probable tokens at each step</span>
    top_p<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment"># Nucleus sampling: choose from top tokens covering 90% probability mass</span>
    temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment"># Lower = more predictable, higher = more creative</span>
    pad_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>eos_token_id  <span class="token comment"># Use EOS token for padding</span>
<span class="token punctuation">)</span>

<span class="token comment"># Decode generated token IDs to text</span>
generated_text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>generated_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>tensor([[  464,  2003,   286,  9007,   318,   284,  1064,   649, 23533,    11,<br>           475,   340,   468,   257,   890,   835,   284,   467,   878,   326,<br>          4325,    13,   198,   198,   464,   717,  1688,  8668,  4473,   319,<br>           428,  1808,   373,  5952,   287,   262,  3095,    12, 23664,    82,<br>            11,   475,   340,   373,   407,   257,  1688,  1943,    13,   198]])<br>The future of medicine is to find new medicines, but it has a long way to go before that happens.</p>
<p>The first major clinical trial on this question was conducted in the mid-1980s, but it was not a major success.</p>
</blockquote>
<table>
<thead>
<tr>
<th>å‚æ•°å</th>
<th>ç±»å‹</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td><code>**inputs</code></td>
<td>dict</td>
<td>ä¼ å…¥ç»è¿‡åˆ†è¯å™¨ç¼–ç åçš„è¾“å…¥ï¼ˆå¦‚ <code>input_ids</code>ã€<code>attention_mask</code>ï¼‰</td>
</tr>
<tr>
<td><code>max_length</code></td>
<td>int</td>
<td>æœ€å¤šç”Ÿæˆ <code>max_length</code> ä¸ª token çš„æ–‡æœ¬</td>
</tr>
<tr>
<td><code>do_sample</code></td>
<td>bool</td>
<td>æ˜¯å¦å¯ç”¨é‡‡æ ·ç­–ç•¥ï¼ˆTrue è¡¨ç¤ºæ¯ä¸€æ­¥ä¸åªé€‰æœ€å¯èƒ½çš„è¯ï¼Œè€Œæ˜¯æ ¹æ®æ¦‚ç‡åˆ†å¸ƒé‡‡æ ·ï¼‰</td>
</tr>
<tr>
<td><code>top_k</code></td>
<td>int</td>
<td>æ¯ä¸€æ­¥åªä»æ¦‚ç‡æœ€é«˜çš„å‰ K ä¸ªè¯ä¸­è¿›è¡Œé‡‡æ ·ï¼Œé™åˆ¶é‡‡æ ·èŒƒå›´ï¼Œé¿å…å¥‡æ€ªçš„è¯è¢«é€‰ä¸­</td>
</tr>
<tr>
<td><code>top_p</code></td>
<td>float (0-1)</td>
<td>æ ¸é‡‡æ ·ï¼ˆnucleus samplingï¼‰ï¼šåªä»ç´¯è®¡æ¦‚ç‡è¾¾åˆ° p çš„å‰å‡ ä¸ªè¯ä¸­é‡‡æ ·ï¼ŒåŠ¨æ€é€‰æ‹©å€™é€‰è¯æ•°é‡</td>
</tr>
<tr>
<td><code>temperature</code></td>
<td>float (&gt;0)</td>
<td>æ§åˆ¶è¾“å‡ºçš„â€œåˆ›é€ æ€§â€ï¼šè¶Šä½è¶Šä¿å®ˆï¼ˆè¶‹è¿‘ç¡®å®šæ€§ï¼‰ï¼Œè¶Šé«˜è¶Šå‘æ•£ï¼ˆè¶‹è¿‘éšæœºï¼‰</td>
</tr>
<tr>
<td><code>pad_token_id</code></td>
<td>int</td>
<td>å¡«å…… token çš„ IDï¼ˆç”¨äºå¯¹é½é•¿åº¦ï¼‰ï¼Œè¿™é‡Œè®¾ä¸ºæ¨¡å‹çš„ç»ˆæ­¢ç¬¦å·ï¼ˆEOSï¼‰IDï¼Œé¿å…æŠ¥é”™</td>
</tr>
</tbody></table>
<hr>
<h5 id="ğŸ“Š-æ–‡æœ¬åˆ†ç±»ï¼ˆAutoModelForSequenceClassificationï¼‰"><a href="#ğŸ“Š-æ–‡æœ¬åˆ†ç±»ï¼ˆAutoModelForSequenceClassificationï¼‰" class="headerlink" title="ğŸ“Š æ–‡æœ¬åˆ†ç±»ï¼ˆAutoModelForSequenceClassificationï¼‰"></a>ğŸ“Š <strong>æ–‡æœ¬åˆ†ç±»ï¼ˆ<code>AutoModelForSequenceClassification</code>ï¼‰</strong></h5><p><code>AutoModelForSequenceClassification</code> æ˜¯ Hugging Face Transformers åº“ä¸­çš„ä¸€ä¸ªé€šç”¨æ¨¡å‹æ¥å£ï¼Œç”¨äº<strong>åŠ è½½å’Œä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹</strong>ã€‚</p>
<p>å®ƒæ˜¯åœ¨ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼ˆæ¯”å¦‚ BERTã€RoBERTaã€DistilBERT ç­‰ï¼‰åé¢<strong>åŠ äº†ä¸€ä¸ªåˆ†ç±»å¤´</strong>ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ + Softmaxï¼‰ï¼š</p>
<pre class="line-numbers language-none"><code class="language-none">Text â†’ Tokenizer â†’ Transformer Encoder (BERT) â†’ [CLS] â†’ Linear Layer â†’ åˆ†ç±»æ¦‚ç‡<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>æœ€ç»ˆè¾“å‡ºæ˜¯ï¼š</p>
<pre class="line-numbers language-none"><code class="language-none">outputs.logits  # shape = (batch_size, num_labels)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>âœ… é€‚ç”¨ä»»åŠ¡ç±»å‹</p>
<table>
<thead>
<tr>
<th>ä»»åŠ¡ç±»å‹</th>
<th>ç¤ºä¾‹è¾“å…¥</th>
<th>ç¤ºä¾‹è¾“å‡º</th>
</tr>
</thead>
<tbody><tr>
<td>äºŒåˆ†ç±»ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰</td>
<td>â€œI love this product.â€</td>
<td>[Negative, âœ…Positive]</td>
</tr>
<tr>
<td>å¤šåˆ†ç±»ï¼ˆæ„å›¾è¯†åˆ«ï¼‰</td>
<td>â€œBook a flight to Tokyo tomorrow.â€</td>
<td>[weather, âœ…booking, cancel]</td>
</tr>
<tr>
<td>æ–‡æ¡£åˆ†ç±»</td>
<td>ä¸€ç¯‡å®Œæ•´æ–‡ç« </td>
<td>[sport, politics, tech]</td>
</tr>
</tbody></table>
<p>ç¤ºä¾‹ä»£ç </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

<span class="token comment"># ==== 1. åŠ è½½æœ¬åœ°æ¨¡å‹å’Œåˆ†è¯å™¨ ====</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ==== 2. è¾“å…¥æ–‡æœ¬ ====</span>
text <span class="token operator">=</span> <span class="token string">"Clannad is the best anime I have ever seen."</span>  
<span class="token comment"># å°†æ–‡æœ¬ç¼–ç ä¸ºæ¨¡å‹è¾“å…¥ï¼ˆåŒ…å« input_ids å’Œ attention_maskï¼‰</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># ==== 3. å‰å‘ä¼ æ’­å¹¶è®¡ç®—æ¦‚ç‡ ====</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ç¦ç”¨æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜ï¼Œä»…æ¨ç†</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>        <span class="token comment"># è¾“å‡ºåŒ…å« logitsï¼ˆåŸå§‹åˆ†æ•°ï¼‰</span>
    logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits          <span class="token comment"># logits å½¢çŠ¶: (1, 2)ï¼Œè¡¨ç¤ºå¯¹ä¸¤ä¸ªæ ‡ç­¾çš„è¯„åˆ†</span>
    probabilities <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># ä½¿ç”¨ softmax è½¬ä¸ºæ¦‚ç‡åˆ†å¸ƒ</span>

<span class="token comment"># ==== 4. è·å–é¢„æµ‹ç±»åˆ« ====</span>
predicted_class <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probabilities<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># è·å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç´¢å¼•</span>
labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Negative"</span><span class="token punctuation">,</span> <span class="token string">"Positive"</span><span class="token punctuation">]</span>  <span class="token comment"># SST-2 æ•°æ®é›†çš„ä¸¤ä¸ªæ ‡ç­¾</span>

<span class="token comment"># ==== 5. æ‰“å°è¾“å‡ºç»“æœ ====</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== åŸå§‹æ¨¡å‹è¾“å‡º ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Logitsï¼ˆæœªå½’ä¸€åŒ–åˆ†æ•°ï¼‰==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== æ¦‚ç‡åˆ†å¸ƒï¼ˆSoftmax ä¹‹åï¼‰==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>probabilities<span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°æœ€ç»ˆé¢„æµ‹æ ‡ç­¾ä¸æ¦‚ç‡</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\nâœ… é¢„æµ‹æƒ…æ„Ÿç±»åˆ«: </span><span class="token interpolation"><span class="token punctuation">{</span>labels<span class="token punctuation">[</span>predicted_class<span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (</span><span class="token interpolation"><span class="token punctuation">{</span>probabilities<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>predicted_class<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>=== Raw model outputs ===<br>SequenceClassifierOutput(loss=None, logits=tensor([[-4.2006,  4.5068]]), hidden_states=None, attentions=None)</p>
<p>=== Logits (unnormalized scores) ===<br>tensor([[-4.2006,  4.5068]])</p>
<p>=== Probabilities (after softmax) ===<br>tensor([[1.6534e-04, 9.9983e-01]])</p>
<p>âœ… Predicted class: Positive (0.9998)</p>
</blockquote>
<hr>
<h5 id="â“é—®ç­”ç³»ç»Ÿï¼ˆAutoModelForQuestionAnsweringï¼‰"><a href="#â“é—®ç­”ç³»ç»Ÿï¼ˆAutoModelForQuestionAnsweringï¼‰" class="headerlink" title="â“é—®ç­”ç³»ç»Ÿï¼ˆAutoModelForQuestionAnsweringï¼‰"></a>â“<strong>é—®ç­”ç³»ç»Ÿï¼ˆ<code>AutoModelForQuestionAnswering</code>ï¼‰</strong></h5><p><code>AutoModelForQuestionAnswering</code> æ˜¯ Hugging Face æä¾›çš„è‡ªåŠ¨åŠ è½½æ¥å£ï¼Œç”¨äºæ„å»º <strong>æå–å¼é—®ç­”ç³»ç»Ÿ</strong>ã€‚</p>
<blockquote>
<p><strong>æå–å¼é—®ç­”ç³»ç»Ÿ</strong>ï¼šç»™å®šä¸€ä¸ª<strong>é—®é¢˜</strong>å’Œä¸€ä¸ª<strong>ä¸Šä¸‹æ–‡æ®µè½</strong>ï¼Œæ¨¡å‹ä»æ®µè½ä¸­<strong>æå–å‡ºä¸€ä¸ªè¿ç»­çš„ç­”æ¡ˆç‰‡æ®µ</strong>ã€‚</p>
<p><strong>è¾“å…¥ï¼š</strong></p>
<p>ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ï¼šâ€The heart pumps blood through the body using rhythmic contractions.â€</p>
<p>é—®é¢˜ï¼ˆquestionï¼‰ï¼šâ€What does the heart do?â€</p>
<p><strong>æ¨¡å‹è¾“å‡ºï¼š</strong>â€œpumps blood through the bodyâ€</p>
</blockquote>
<p>æ­¤ç±»æ¨¡å‹åŸºäº BERTã€RoBERTa ç­‰ Transformer æ¶æ„ï¼Œæ¨¡å‹å­¦ä¹ ä¸ºæ¯ä¸ª token é¢„æµ‹ä¸¤ä¸ªåˆ†æ•°ï¼š</p>
<ul>
<li><strong>Start score</strong>ï¼šç­”æ¡ˆèµ·å§‹ä½ç½®çš„æ¦‚ç‡</li>
<li><strong>End score</strong>ï¼šç­”æ¡ˆç»“æŸä½ç½®çš„æ¦‚ç‡</li>
</ul>
<p>æœ€ç»ˆé€‰æ‹©ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_index <span class="token operator">=</span> argmax<span class="token punctuation">(</span>start_scores<span class="token punctuation">)</span>
end_index <span class="token operator">=</span> argmax<span class="token punctuation">(</span>end_scores<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>æ‰€ä»¥ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">answer <span class="token operator">=</span> context_tokens<span class="token punctuation">[</span>start_index <span class="token punctuation">:</span> end_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>ç¤ºä¾‹ä»£ç </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForQuestionAnswering

<span class="token comment"># ========== 1. åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨ ==========</span>
model_path <span class="token operator">=</span> <span class="token string">"***/distilbert-base-cased-distilled-squad"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ========== 2. è¾“å…¥é—®é¢˜ä¸ä¸Šä¸‹æ–‡ ==========</span>
question <span class="token operator">=</span> <span class="token string">"What does NLP stand for?"</span>
context <span class="token operator">=</span> <span class="token string">"NLP stands for Natural Language Processing, a subfield of artificial intelligence."</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== åŸå§‹è¾“å…¥ ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ“Œ Question:"</span><span class="token punctuation">,</span> question<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ“„ Context:"</span><span class="token punctuation">,</span> context<span class="token punctuation">)</span>

<span class="token comment"># ç¼–ç è¾“å…¥</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°ç¼–ç åçš„è¾“å…¥</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Tokenizer ç¼–ç ç»“æœ ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ§¾ input_ids:"</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ§  tokens:"</span><span class="token punctuation">,</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ“Š attention_mask:"</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># ========== 3. æ¨¡å‹æ¨ç† ==========</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># ========== 4. æŸ¥çœ‹ logits ==========</span>
start_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>start_logits
end_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>end_logits

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== æ¨¡å‹è¾“å‡ºåˆ†æ•°ï¼ˆlogitsï¼‰ ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸš© start_logits:"</span><span class="token punctuation">,</span> start_logits<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ end_logits:"</span><span class="token punctuation">,</span> end_logits<span class="token punctuation">)</span>

<span class="token comment"># ========== 5. è®¡ç®—èµ·æ­¢ä½ç½® ==========</span>
start_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
end_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>end_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\nğŸ“ é¢„æµ‹çš„èµ·å§‹ä½ç½®: </span><span class="token interpolation"><span class="token punctuation">{</span>start_idx<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"ğŸ“ é¢„æµ‹çš„ç»“æŸä½ç½®: </span><span class="token interpolation"><span class="token punctuation">{</span>end_idx<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># ========== 6. è§£ç ç­”æ¡ˆ ==========</span>
<span class="token keyword">if</span> start_idx <span class="token operator">&gt;</span> end_idx<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"âš ï¸ èµ·å§‹ä½ç½®å¤§äºç»“æŸä½ç½®ï¼Œç­”æ¡ˆæ— æ•ˆã€‚"</span><span class="token punctuation">)</span>
    answer <span class="token operator">=</span> <span class="token string">"[Invalid prediction]"</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>start_idx<span class="token punctuation">:</span>end_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸ” ç­”æ¡ˆç›¸å…³ tokens:"</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span>
    answer <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_string<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>

<span class="token comment"># ========== 7. è¾“å‡ºæœ€ç»ˆç»“æœ ==========</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nâœ… æœ€ç»ˆé¢„æµ‹ç­”æ¡ˆ:"</span><span class="token punctuation">,</span> answer<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>ç¤ºä¾‹è¾“å‡º</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">
=== åŸå§‹è¾“å…¥ ===
ğŸ“Œ Question: What does NLP stand for?
ğŸ“„ Context: NLP stands for Natural Language Processing, a subfield of artificial intelligence.

=== Tokenizer ç¼–ç ç»“æœ ===
ğŸ§¾ input_ids: tensor([[  101,  1327,  1674, 21239,  2101,  2484,  1111,   136,   102, 21239,
          2101,  4061,  1111,  6240,  6828, 18821,  1158,   117,   170,  4841,
          2427,  1104,  8246,  4810,   119,   102]])
ğŸ§  tokens: ['[CLS]', 'What', 'does', 'NL', '##P', 'stand', 'for', '?', '[SEP]', 'NL', '##P', 'stands', 'for', 'Natural', 'Language', 'Process', '##ing', ',', 'a', 'sub', '##field', 'of', 'artificial', 'intelligence', '.', '[SEP]']
ğŸ“Š attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1]])

=== æ¨¡å‹è¾“å‡ºåˆ†æ•°ï¼ˆlogitsï¼‰ ===
ğŸš© start_logits: tensor([[-2.3248e+00, -2.4476e+00, -3.1210e+00, -2.7561e+00, -4.8028e+00,
         -4.4546e+00, -5.1295e+00, -2.0812e+00,  1.0627e-02,  3.7939e+00,
         -1.8733e+00, -1.1664e+00, -1.4235e+00,  1.1914e+01,  2.4047e+00,
          2.3639e+00,  4.6805e-01, -1.6326e+00,  1.9572e+00,  1.0077e+00,
         -2.5621e+00, -3.3284e+00,  3.0263e+00, -1.2865e+00, -2.7076e+00,
          1.0653e-02]])
ğŸ end_logits: tensor([[-0.8734, -2.4869, -3.9640, -4.1681, -3.1094, -4.6843, -4.2300, -2.2853,
          0.8502, -2.0429,  0.0950, -2.6078, -2.2444,  4.0181,  5.2197,  2.5751,
         11.4774,  5.3121, -2.4660, -3.0402,  0.7667, -4.4215, -1.3441,  4.3169,
          4.8004,  0.8503]])

ğŸ“ é¢„æµ‹çš„èµ·å§‹ä½ç½®: 13
ğŸ“ é¢„æµ‹çš„ç»“æŸä½ç½®: 16
ğŸ” ç­”æ¡ˆç›¸å…³ tokens: ['Natural', 'Language', 'Process', '##ing']

âœ… æœ€ç»ˆé¢„æµ‹ç­”æ¡ˆ: Natural Language Processing<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>ğŸ”´ PSï¼š<code>AutoModelForQuestionAnswering</code> ä»…ç”¨äºæ„å»º <strong>æå–å¼é—®ç­”ç³»ç»Ÿ</strong>ï¼Œä¸åŒ…å«å…¶ä»–ç±»å‹çš„é—®ç­”ï¼‰</p>
<blockquote>
<p><strong><u>æ‹“å±•ï¼šé—®ç­”ç³»ç»Ÿçš„è‹¥å¹²ç§èŒƒå¼</u></strong></p>
<table>
<thead>
<tr>
<th align="left">ç±»å‹</th>
<th align="left">æ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡</th>
<th align="left">ç­”æ¡ˆæ¥æº</th>
<th align="left">å…¸å‹æ¨¡å‹</th>
<th align="left">é€‚ç”¨åœºæ™¯</th>
</tr>
</thead>
<tbody><tr>
<td align="left">æŠ½å–å¼QA</td>
<td align="left">æ˜¯</td>
<td align="left">ä¸Šä¸‹æ–‡ç‰‡æ®µ</td>
<td align="left">BERT, RoBERTa</td>
<td align="left">æ–‡æ¡£é˜…è¯»ç†è§£</td>
</tr>
<tr>
<td align="left">ç”Ÿæˆå¼QA</td>
<td align="left">å¯é€‰</td>
<td align="left">æ¨¡å‹ç”Ÿæˆ</td>
<td align="left">T5, GPT</td>
<td align="left">å¼€æ”¾åŸŸé—®ç­”</td>
</tr>
<tr>
<td align="left">å¤šé€‰QA</td>
<td align="left">æ˜¯</td>
<td align="left">ç»™å®šé€‰é¡¹</td>
<td align="left">BERT, XLNet</td>
<td align="left">è€ƒè¯•ç³»ç»Ÿ</td>
</tr>
<tr>
<td align="left">å¼€æ”¾åŸŸQA</td>
<td align="left">å¦</td>
<td align="left">çŸ¥è¯†åº“/æ¨¡å‹</td>
<td align="left">DPR + BERT</td>
<td align="left">æ™ºèƒ½åŠ©æ‰‹</td>
</tr>
<tr>
<td align="left">è§†è§‰QA</td>
<td align="left">æ˜¯ï¼ˆå›¾ç‰‡ï¼‰</td>
<td align="left">å›¾ç‰‡å†…å®¹</td>
<td align="left">ViLBERT, CLIP</td>
<td align="left">å›¾åƒç†è§£</td>
</tr>
<tr>
<td align="left">è¡¨æ ¼QA</td>
<td align="left">æ˜¯ï¼ˆè¡¨æ ¼ï¼‰</td>
<td align="left">è¡¨æ ¼æ•°æ®</td>
<td align="left">TAPAS</td>
<td align="left">ç»“æ„åŒ–æ•°æ®æŸ¥è¯¢</td>
</tr>
</tbody></table>
<p><strong><u>å¯¹æ¯”è¡¨ï¼šæå–å¼é—®ç­” vs Zero-shot é—®ç­”</u></strong></p>
<table>
<thead>
<tr>
<th>ç»´åº¦</th>
<th>æå–å¼é—®ç­”ï¼ˆExtractive QAï¼‰</th>
<th>Zero-shot é—®ç­”ï¼ˆZero-shot QAï¼‰</th>
</tr>
</thead>
<tbody><tr>
<td><strong>å®šä¹‰</strong></td>
<td>ä»<strong>æä¾›çš„ä¸Šä¸‹æ–‡æ®µè½</strong>ä¸­æå–ä¸€ä¸ªè¿ç»­çš„ç­”æ¡ˆ</td>
<td>ä¸ä¾èµ–äºæä¾›ä¸Šä¸‹æ–‡ï¼Œç›´æ¥åŸºäºé¢„è®­ç»ƒçŸ¥è¯†ç”Ÿæˆç­”æ¡ˆ</td>
</tr>
<tr>
<td><strong>ä¾èµ–ä¸Šä¸‹æ–‡</strong></td>
<td>âœ… å¿…é¡»æœ‰ä¸Šä¸‹æ–‡</td>
<td>âŒ å¯æ²¡æœ‰ä¸Šä¸‹æ–‡</td>
</tr>
<tr>
<td><strong>æ¨¡å‹è®­ç»ƒ</strong></td>
<td>éœ€è¦åœ¨é—®ç­”æ•°æ®é›†ï¼ˆå¦‚ SQuADï¼‰ä¸Šè¿›è¡Œ fine-tune</td>
<td>é€šå¸¸åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT-3ã€T5ï¼‰ï¼Œæ— éœ€ç‰¹å®š QA å¾®è°ƒ</td>
</tr>
<tr>
<td><strong>è¾“å‡ºå½¢å¼</strong></td>
<td>é€šå¸¸æ˜¯æ®µè½ä¸­çš„å­å­—ç¬¦ä¸²</td>
<td>æ¨¡å‹ç”Ÿæˆçš„è‡ªç”±å½¢å¼ç­”æ¡ˆ</td>
</tr>
<tr>
<td><strong>æ¨¡å‹æ¥å£</strong></td>
<td><code>AutoModelForQuestionAnswering</code></td>
<td><code>AutoModelForSeq2SeqLM</code> / <code>AutoModelForCausalLM</code></td>
</tr>
<tr>
<td><strong>ç¤ºä¾‹æ¨¡å‹</strong></td>
<td>BERT QA, RoBERTa QA, ALBERT QA</td>
<td>GPT-3, T5, FLAN-T5, BioGPT</td>
</tr>
</tbody></table>
<p><u><strong>å„ç±»é—®ç­”çš„å…·ä½“ä»‹ç»ï¼š</strong></u></p>
<p>1.<strong>æŠ½å–å¼é—®ç­”ï¼ˆExtractive QAï¼‰</strong></p>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šä»ç»™å®šçš„æ–‡æœ¬ä¸­ç›´æ¥æŠ½å–ç­”æ¡ˆç‰‡æ®µï¼ˆspanï¼‰ã€‚</p>
</li>
<li><p><strong>æ¨¡å‹ç¤ºä¾‹</strong>ï¼šBERTã€RoBERTaã€DistilBERTã€‚</p>
</li>
<li><p><strong>è¾“å…¥è¾“å‡º</strong>ï¼š</p>
<ul>
<li>è¾“å…¥ï¼šé—®é¢˜ + ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰</li>
<li>è¾“å‡ºï¼šç­”æ¡ˆåœ¨ä¸Šä¸‹æ–‡ä¸­çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼ˆå­—ç¬¦æˆ–tokenç´¢å¼•ï¼‰</li>
</ul>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
qa_pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"bert-large-uncased-whole-word-masking-finetuned-squad"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> qa_pipeline<span class="token punctuation">(</span>
    question<span class="token operator">=</span><span class="token string">"What is the capital of France?"</span><span class="token punctuation">,</span>
    context<span class="token operator">=</span><span class="token string">"France is a country in Europe. Its capital is Paris."</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºï¼š{'answer': 'Paris', 'score': 0.98, ...}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šé˜…è¯»ç†è§£ã€æ–‡æ¡£æ£€ç´¢ï¼ˆå¦‚SQuADæ•°æ®é›†ï¼‰ã€‚</p>
</li>
</ul>
<hr>
<ol start="2">
<li><strong>ç”Ÿæˆå¼é—®ç­”ï¼ˆGenerative QAï¼‰</strong></li>
</ol>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šæ¨¡å‹æ ¹æ®é—®é¢˜ç”Ÿæˆè‡ªç”±æ–‡æœ¬ç­”æ¡ˆï¼ˆæ— éœ€ä¾èµ–ä¸Šä¸‹æ–‡ä¸­çš„åŸå¥ï¼‰ã€‚</p>
</li>
<li><p><strong>æ¨¡å‹ç¤ºä¾‹</strong>ï¼šT5ã€GPT-3ã€BARTã€‚</p>
</li>
<li><p><strong>è¾“å…¥è¾“å‡º</strong>ï¼š</p>
<ul>
<li>è¾“å…¥ï¼šé—®é¢˜ï¼ˆ+ å¯é€‰çš„ä¸Šä¸‹æ–‡ï¼‰</li>
<li>è¾“å‡ºï¼šç”Ÿæˆçš„ç­”æ¡ˆæ–‡æœ¬</li>
</ul>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text2text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
answer <span class="token operator">=</span> generator<span class="token punctuation">(</span>
    <span class="token string">"question: What is the capital of France? context: France is a country in Europe."</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºï¼š[{'generated_text': 'Paris'}]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šå¼€æ”¾åŸŸé—®ç­”ã€èŠå¤©æœºå™¨äººã€‚</p>
</li>
</ul>
<hr>
<ol start="3">
<li><strong>å¤šé€‰é—®ç­”ï¼ˆMultiple-Choice QAï¼‰</strong></li>
</ol>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©æ­£ç¡®ç­”æ¡ˆã€‚</p>
</li>
<li><p><strong>æ¨¡å‹ç¤ºä¾‹</strong>ï¼šBERTã€XLNetã€‚</p>
</li>
<li><p><strong>è¾“å…¥è¾“å‡º</strong>ï¼š</p>
<ul>
<li>è¾“å…¥ï¼šé—®é¢˜ + ä¸Šä¸‹æ–‡ + å€™é€‰é€‰é¡¹</li>
<li>è¾“å‡ºï¼šé€‰é¡¹æ ‡ç­¾ï¼ˆå¦‚A/B/C/Dï¼‰æˆ–ç½®ä¿¡åº¦åˆ†æ•°</li>
</ul>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMultipleChoice<span class="token punctuation">,</span> AutoTokenizer
model <span class="token operator">=</span> AutoModelForMultipleChoice<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>

<span class="token comment"># é—®é¢˜ä¸é€‰é¡¹</span>
question <span class="token operator">=</span> <span class="token string">"What is the capital of France?"</span>
options <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"London"</span><span class="token punctuation">,</span> <span class="token string">"Berlin"</span><span class="token punctuation">,</span> <span class="token string">"Paris"</span><span class="token punctuation">,</span> <span class="token string">"Madrid"</span><span class="token punctuation">]</span>

<span class="token comment"># å¯¹æ¯ä¸ªé€‰é¡¹ç¼–ç å¹¶è®¡ç®—åˆ†æ•°</span>
inputs <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span> <span class="token keyword">for</span> opt <span class="token keyword">in</span> options<span class="token punctuation">]</span>
outputs <span class="token operator">=</span> <span class="token punctuation">[</span>model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">.</span>logits <span class="token keyword">for</span> <span class="token builtin">input</span> <span class="token keyword">in</span> inputs<span class="token punctuation">]</span>
best_answer <span class="token operator">=</span> options<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>best_answer<span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºï¼šParis</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šè€ƒè¯•ç³»ç»Ÿã€æ ‡å‡†åŒ–æµ‹è¯•ã€‚</p>
</li>
</ul>
<hr>
<ol start="4">
<li><strong>å¼€æ”¾åŸŸé—®ç­”ï¼ˆOpen-Domain QAï¼‰</strong></li>
</ol>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šæ— éœ€æä¾›ä¸Šä¸‹æ–‡ï¼Œç›´æ¥ä»çŸ¥è¯†åº“æˆ–æ¨¡å‹å‚æ•°ä¸­æ£€ç´¢ç­”æ¡ˆã€‚</p>
</li>
<li><p><strong>æŠ€æœ¯ç»„åˆ</strong>ï¼š</p>
<ul>
<li>æ£€ç´¢å™¨ï¼ˆå¦‚DPRï¼‰ + é˜…è¯»å™¨ï¼ˆå¦‚BERTï¼‰</li>
<li>çº¯ç”Ÿæˆå¼æ¨¡å‹ï¼ˆå¦‚GPT-3ï¼‰</li>
</ul>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼ˆæ£€ç´¢+ç”Ÿæˆç»“åˆï¼‰ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ä½¿ç”¨Haystackæ¡†æ¶ï¼ˆåŸºäºæ£€ç´¢çš„QAï¼‰</span>
<span class="token keyword">from</span> haystack <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> haystack<span class="token punctuation">.</span>nodes <span class="token keyword">import</span> BM25Retriever<span class="token punctuation">,</span> FARMReader

retriever <span class="token operator">=</span> BM25Retriever<span class="token punctuation">(</span>document_store<span class="token operator">=</span>my_document_store<span class="token punctuation">)</span>
reader <span class="token operator">=</span> FARMReader<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"deepset/bert-base-cased-squad2"</span><span class="token punctuation">)</span>
pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>retriever<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Retriever"</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Query"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>reader<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Reader"</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Retriever"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>run<span class="token punctuation">(</span>query<span class="token operator">=</span><span class="token string">"What is the capital of France?"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šæ™ºèƒ½åŠ©æ‰‹ï¼ˆå¦‚Alexaã€Siriï¼‰ã€‚</p>
</li>
</ul>
<hr>
<ol start="5">
<li><strong>è§†è§‰é—®ç­”ï¼ˆVisual QA, VQAï¼‰</strong></li>
</ol>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šåŸºäºå›¾åƒå†…å®¹å›ç­”é—®é¢˜ã€‚</p>
</li>
<li><p><strong>æ¨¡å‹ç¤ºä¾‹</strong>ï¼šViLBERTã€CLIPã€BLIPã€‚</p>
</li>
<li><p><strong>è¾“å…¥è¾“å‡º</strong>ï¼š</p>
<ul>
<li>è¾“å…¥ï¼šå›¾ç‰‡ + é—®é¢˜</li>
<li>è¾“å‡ºï¼šæ–‡æœ¬ç­”æ¡ˆ</li>
</ul>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
vqa_pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"visual-question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"dandelin/vilt-b32-finetuned-vqa"</span><span class="token punctuation">)</span>
answer <span class="token operator">=</span> vqa_pipeline<span class="token punctuation">(</span>
    image<span class="token operator">=</span><span class="token string">"paris.jpg"</span><span class="token punctuation">,</span>
    question<span class="token operator">=</span><span class="token string">"What is in the center of the image?"</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºï¼š{'answer': 'Eiffel Tower'}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šå›¾åƒç†è§£ã€ç›²äººè¾…åŠ©å·¥å…·ã€‚</p>
</li>
</ul>
<hr>
<ol start="6">
<li><strong>è¡¨æ ¼é—®ç­”ï¼ˆTable QAï¼‰</strong></li>
</ol>
<ul>
<li><p><strong>ç‰¹ç‚¹</strong>ï¼šä»ç»“æ„åŒ–è¡¨æ ¼ä¸­æå–ç­”æ¡ˆã€‚</p>
</li>
<li><p><strong>æ¨¡å‹ç¤ºä¾‹</strong>ï¼šTAPASã€TaBERTã€‚</p>
</li>
<li><p><strong>ä»£ç ç¤ºä¾‹</strong>ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
table_qa <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"table-question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"google/tapas-base-finetuned-wtq"</span><span class="token punctuation">)</span>

table <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"City"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Paris"</span><span class="token punctuation">,</span> <span class="token string">"London"</span><span class="token punctuation">,</span> <span class="token string">"Berlin"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Country"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"France"</span><span class="token punctuation">,</span> <span class="token string">"UK"</span><span class="token punctuation">,</span> <span class="token string">"Germany"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
answer <span class="token operator">=</span> table_qa<span class="token punctuation">(</span>
    table<span class="token operator">=</span>table<span class="token punctuation">,</span>
    query<span class="token operator">=</span><span class="token string">"Which city is in France?"</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºï¼š{'answer': 'Paris', ...}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šExcel/æ•°æ®åº“æŸ¥è¯¢ã€é‡‘èæŠ¥è¡¨åˆ†æã€‚</p>
</li>
</ul>
</blockquote>
<hr>
<h5 id="ğŸŒ-ç¿»è¯‘ä»»åŠ¡ï¼ˆAutoModelForSeq2SeqLMï¼‰"><a href="#ğŸŒ-ç¿»è¯‘ä»»åŠ¡ï¼ˆAutoModelForSeq2SeqLMï¼‰" class="headerlink" title="ğŸŒ ç¿»è¯‘ä»»åŠ¡ï¼ˆAutoModelForSeq2SeqLMï¼‰"></a>ğŸŒ <strong>ç¿»è¯‘ä»»åŠ¡ï¼ˆ<code>AutoModelForSeq2SeqLM</code>ï¼‰</strong></h5><p><code>AutoModelForSeq2SeqLM</code> æ˜¯ Hugging Face ä¸­ç”¨äº <strong>ç”Ÿæˆå¼ä»»åŠ¡</strong>ï¼ˆå¦‚æ‘˜è¦ã€ç¿»è¯‘ã€é—®ç­”ã€å¯¹è¯ï¼‰çš„æ¨¡å‹æ¥å£ï¼Œé€‚ç”¨äº <strong>ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼ˆEncoder-Decoderï¼‰</strong> çš„æ¨¡å‹æ¶æ„ã€‚</p>
<table>
<thead>
<tr>
<th>ä»»åŠ¡ç±»å‹</th>
<th>ç¤ºä¾‹æ¨¡å‹</th>
<th>è¾“å…¥</th>
<th>è¾“å‡º</th>
</tr>
</thead>
<tbody><tr>
<td><strong>æ–‡æœ¬æ‘˜è¦</strong></td>
<td><code>facebook/bart-large-cnn</code></td>
<td>æ–°é—»æ–‡ç« </td>
<td>æ¦‚æ‹¬å¥å­</td>
</tr>
<tr>
<td><strong>æœºå™¨ç¿»è¯‘</strong></td>
<td><code>Helsinki-NLP/opus-mt-en-zh</code></td>
<td>English</td>
<td>ä¸­æ–‡</td>
</tr>
<tr>
<td><strong>ç”Ÿæˆå¼é—®ç­”</strong></td>
<td><code>t5-base</code>, <code>flan-t5-base</code></td>
<td>é—®é¢˜ + æ–‡æ¡£</td>
<td>è‡ªç”±æ–‡æœ¬ç­”æ¡ˆ</td>
</tr>
<tr>
<td><strong>å¤šä»»åŠ¡å­¦ä¹ </strong></td>
<td><code>google/flan-t5-xl</code></td>
<td>æŒ‡ä»¤å¼ prompt</td>
<td>ä»»æ„ä»»åŠ¡è¾“å‡º</td>
</tr>
</tbody></table>
<p>å¸¸è§çš„ Seq2Seq æ¨¡å‹ï¼ˆå¯ç”¨äº <code>AutoModelForSeq2SeqLM</code>ï¼‰</p>
<table>
<thead>
<tr>
<th>æ¨¡å‹å</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td><code>t5-base</code></td>
<td>Google çš„å¤šä»»åŠ¡ Seq2Seq æ¨¡å‹</td>
</tr>
<tr>
<td><code>flan-t5-base</code></td>
<td>æ›´å¼ºç‰ˆæœ¬çš„ T5ï¼Œç»è¿‡ instruction tuning</td>
</tr>
<tr>
<td><code>facebook/bart-large-cnn</code></td>
<td>BART å¾®è°ƒç”¨äºæ–°é—»æ‘˜è¦</td>
</tr>
<tr>
<td><code>Helsinki-NLP/opus-mt-*</code></td>
<td>å¤šè¯­è¨€æœºå™¨ç¿»è¯‘æ¨¡å‹</td>
</tr>
</tbody></table>
<p>ç¤ºä¾‹ä»£ç ï¼š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

<span class="token comment"># 1. åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹</span>
model_path <span class="token operator">=</span> <span class="token string">'***/Helsinki-NLP:opus-mt-en-zh'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 2. å‡†å¤‡è¾“å…¥æ–‡æœ¬</span>
source_text <span class="token operator">=</span> <span class="token string">"The future of AI is full of possibilities."</span>

<span class="token comment"># 3. å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ç¼–ç ï¼ˆè½¬æ¢ä¸ºæ¨¡å‹å¯æ¥å—çš„æ ¼å¼ï¼‰</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>source_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># 4. ç”Ÿæˆç¿»è¯‘ç»“æœï¼ˆç¦ç”¨æ¢¯åº¦ï¼Œæé«˜æ¨ç†é€Ÿåº¦ï¼‰</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    output_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
        <span class="token operator">**</span>inputs<span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>     <span class="token comment"># æœ€é•¿è¾“å‡ºé•¿åº¦</span>
        num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>       <span class="token comment"># beam search çš„å®½åº¦ï¼Œè¶Šå¤§è¶Šç¨³ä½†é€Ÿåº¦è¶Šæ…¢</span>
        early_stopping<span class="token operator">=</span><span class="token boolean">True</span>  <span class="token comment"># å¦‚æœ beam æå‰æ”¶æ•›å°±åœæ­¢ç”Ÿæˆ</span>
    <span class="token punctuation">)</span>

<span class="token comment"># 5. è§£ç è¾“å‡ºçš„ token IDsï¼Œè½¬æ¢ä¸ºå¯è¯»çš„ç¿»è¯‘ç»“æœ</span>
translated_text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 6. æ‰“å°åŸæ–‡ä¸ç¿»è¯‘ç»“æœ</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nğŸŒ Original:"</span><span class="token punctuation">,</span> source_text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ğŸŒ Translated:"</span><span class="token punctuation">,</span> translated_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>ğŸŒ Original: The future of AI is full of possibilities.<br>ğŸŒ Translated: AIçš„æœªæ¥å……æ»¡äº†å¯èƒ½æ€§ã€‚</p>
</blockquote>
<hr>
<h4 id="Tokens-åŸºç¡€"><a href="#Tokens-åŸºç¡€" class="headerlink" title="Tokens åŸºç¡€"></a>Tokens åŸºç¡€</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

<span class="token comment"># Initialize tokenizer from a fine-tuned DistilBERT model for sentiment analysis</span>
model_Ã¥path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Sample text for tokenization demonstration</span>
text <span class="token operator">=</span> <span class="token string">"Hello, my name is Ricky"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Raw text: </span><span class="token interpolation"><span class="token punctuation">{</span>text<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># Tokenization: text -&gt; subword tokens</span>
tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Tokenized output: </span><span class="token interpolation"><span class="token punctuation">{</span>tokens<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># tokens -&gt; vocabulary IDs</span>
token_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Token IDs: </span><span class="token interpolation"><span class="token punctuation">{</span>token_ids<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># text -&gt; model input format</span>
input_py <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span>  <span class="token comment"># Returns Python dictionary with lists</span>
input_pt <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>  <span class="token comment"># Returns Python dictionary with ready-to-use PyTorch tensors</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Python dictionary format (input_py): </span><span class="token interpolation"><span class="token punctuation">{</span>input_py<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'PyTorch tensor format (input_pt): </span><span class="token interpolation"><span class="token punctuation">{</span>input_pt<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># Best Practice Note:</span>
<span class="token comment"># The PyTorch tensor format (input_pt) is preferred for production because:</span>
<span class="token comment"># 1. Direct compatibility with model.forward() expectations</span>
<span class="token comment"># 2. Automatic GPU acceleration when available (via .cuda() or .to(device))</span>
<span class="token comment"># 3. Built-in support for batch processing</span>
<span class="token comment"># 4. Memory efficiency for large-scale inference</span>
<span class="token comment"># 5. Seamless integration with PyTorch's computation graph</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>æµ‹è¯•ç»“æœ</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Raw text: Hello, my name is Ricky

Tokenized output: ['hello', ',', 'my', 'name', 'is', 'ricky']

Token IDs: [7592, 1010, 2026, 2171, 2003, 11184]

Python dictionary format (input_py): {'input_ids': [101, 7592, 1010, 2026, 2171, 2003, 11184, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}

PyTorch tensor format (input_pt): {'input_ids': tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="Embeddings-åŸºç¡€"><a href="#Embeddings-åŸºç¡€" class="headerlink" title="Embeddings åŸºç¡€"></a>Embeddings åŸºç¡€</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel

<span class="token comment"># Load pre-trained model and tokenizer</span>
model_path <span class="token operator">=</span> <span class="token string">'/home/xixingyu/disk1/PretrainedModels/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Sample text </span>
text <span class="token operator">=</span> <span class="token string">'Hello, my name is Ricky.'</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 1: TOKENIZATION - Converting text to numbers</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Tokenization ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\nRaw text: </span><span class="token interpolation"><span class="token punctuation">{</span>text<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Tokenized Input Structure (PyTorch tensors):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># Let's see what each component means</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nInput IDs (numerical representation of tokens):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nAttention Mask (shows which tokens are real vs padding):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 2: GENERATING EMBEDDINGS</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Generating Embeddings ==="</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Disable gradient calculation for inference</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span> <span class="token comment"># # Forward pass through the model</span>
    
    <span class="token comment"># The model returns a tuple where the first element contains token embeddings</span>
    token_embeddings <span class="token operator">=</span> outputs<span class="token punctuation">.</span>last_hidden_state
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nShape of Token Embeddings:"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Batch Size, Sequence Length, Embedding Dimension] = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"- Batch Size = 1 (we processed one sentence)"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"- Sequence Length = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (number of tokens)"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"- Embedding Dimension = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (size of each vector)"</span></span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 3: CREATING SENTENCE EMBEDDINGS</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Creating Sentence Embeddings ==="</span><span class="token punctuation">)</span>
<span class="token comment"># Simple method: Average all token embeddings (mean pooling)</span>
sentence_embedding <span class="token operator">=</span> token_embeddings<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nShape of Sentence Embedding:"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Batch Size, Embedding Dimension] = </span><span class="token interpolation"><span class="token punctuation">{</span>sentence_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"- Represents the entire sentence as a single vector"</span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># EDUCATIONAL NOTES</span>
<span class="token comment"># =============================================</span>
<span class="token triple-quoted-string string">"""
WHAT ARE EMBEDDINGS?

1. Token Embeddings:
- Each word/subword is converted to a high-dimensional vector
- These vectors capture semantic meaning and context
- Example: "cat" and "kitten" will have similar vectors

2. Sentence Embeddings:
- A single vector representing the entire sentence
- Created by combining token embeddings (here by averaging)
- Can be used for tasks like similarity comparison

WHY THIS MATTERS:
- Computers don't understand words, only numbers
- Embeddings convert language to numerical representations
- Similar meanings â†’ Similar vectors â†’ Better AI understanding
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>æµ‹è¯•ç»“æœ</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">=== Tokenization ===

Raw text: Hello, my name is Ricky.
Tokenized Input Structure (PyTorch tensors):
{'input_ids': tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}

Input IDs (numerical representation of tokens):
tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,  1012,   102]])

Attention Mask (shows which tokens are real vs padding):
tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])

=== Generating Embeddings ===

Shape of Token Embeddings:
[Batch Size, Sequence Length, Embedding Dimension] = torch.Size([1, 9, 768])
- Batch Size = 1 (we processed one sentence)
- Sequence Length = 9 (number of tokens)
- Embedding Dimension = 768 (size of each vector)

=== Creating Sentence Embeddings ===

Shape of Sentence Embedding:
[Batch Size, Embedding Dimension] = torch.Size([1, 768])
- Represents the entire sentence as a single vector<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







<h4 id="æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ï¼ˆå…¥é—¨ç¨‹åºï¼‰"><a href="#æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ï¼ˆå…¥é—¨ç¨‹åºï¼‰" class="headerlink" title="æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ï¼ˆå…¥é—¨ç¨‹åºï¼‰"></a>æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ï¼ˆå…¥é—¨ç¨‹åºï¼‰</h4><p>å¤§æ¨¡å‹è°ƒç”¨ç‰ˆæœ¬çš„ <code>helloworld.py</code> </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification  <span class="token comment"># Hugging Faceçš„Transformeråº“</span>
<span class="token keyword">import</span> torch 

<span class="token comment"># é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„ï¼ˆè¯¥æ¨¡å‹æ˜¯åœ¨SST-2è‹±æ–‡æƒ…æ„Ÿæ•°æ®é›†ä¸Šå¾®è°ƒçš„DistilBERTæ¨¡å‹ï¼Œç”¨äºæƒ…æ„Ÿåˆ†ç±»ï¼‰</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>

<span class="token comment"># ===================== åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ =====================</span>
<span class="token comment"># åŠ è½½ä¸é¢„è®­ç»ƒæ¨¡å‹å¯¹åº”çš„åˆ†è¯å™¨ï¼Œè´Ÿè´£å°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„token IDåºåˆ—ï¼‰</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½é¢„è®­ç»ƒå¥½çš„åºåˆ—åˆ†ç±»æ¨¡å‹</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ===================== å‡†å¤‡è¾“å…¥æ•°æ® =====================</span>
<span class="token comment"># å¾…åˆ†æçš„æ–‡æœ¬</span>
text <span class="token operator">=</span> <span class="token string">"I love China"</span>

<span class="token comment"># ä½¿ç”¨åˆ†è¯å™¨å¤„ç†æ–‡æœ¬ï¼š</span>
<span class="token comment"># - å°†æ–‡æœ¬åˆ†å‰²æˆtoken</span>
<span class="token comment"># - æ·»åŠ ç‰¹æ®Štokenï¼ˆå¦‚[CLS], [SEP]ï¼‰</span>
<span class="token comment"># - å°†tokenè½¬æ¢ä¸ºå¯¹åº”çš„ID</span>
<span class="token comment"># - ç”Ÿæˆæ³¨æ„åŠ›æ©ç ï¼ˆattention maskï¼‰</span>
<span class="token comment"># return_tensors='pt'è¡¨ç¤ºè¿”å›PyTorchå¼ é‡ï¼ˆè€Œä¸æ˜¯NumPyæ•°ç»„ï¼‰</span>
<span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># æŸ¥çœ‹è¾“å…¥çš„ç»“æ„ï¼ˆè°ƒè¯•ç”¨ï¼‰ï¼š</span>
<span class="token comment"># input_ids: tokenå¯¹åº”çš„æ•°å­—ID</span>
<span class="token comment"># attention_mask: æŒ‡ç¤ºå“ªäº›ä½ç½®æ˜¯æœ‰æ•ˆtokenï¼ˆ1è¡¨ç¤ºçœŸå®tokenï¼Œ0è¡¨ç¤ºå¡«å……paddingï¼‰</span>

<span class="token comment"># ===================== æ¨¡å‹æ¨ç† =====================</span>
<span class="token comment"># å°†å¤„ç†å¥½çš„è¾“å…¥ä¼ å…¥æ¨¡å‹</span>
output <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token comment">#**æ“ä½œç¬¦ç”¨äºå°†å­—å…¸è§£åŒ…ä¸ºå…³é”®å­—å‚æ•°</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ===================== è§£ææ¨¡å‹è¾“å‡º =====================</span>
<span class="token comment"># ä»è¾“å‡ºä¸­è·å–logitsï¼ˆæœªç»è¿‡softmaxçš„åŸå§‹è¾“å‡ºåˆ†æ•°ï¼‰</span>
<span class="token comment"># logitså½¢çŠ¶ä¸º[batch_size, num_classes]</span>
<span class="token comment"># å› ä¸ºæˆ‘ä»¬åªè¾“å…¥äº†ä¸€ä¸ªå¥å­ï¼Œæ‰€ä»¥batch_sizeä¸º1</span>
<span class="token comment"># SST-2æ˜¯äºŒåˆ†ç±»ä»»åŠ¡ï¼Œæ‰€ä»¥num_classesä¸º2ï¼ˆç´¢å¼•0:è´Ÿé¢ï¼Œ1:æ­£é¢ï¼‰</span>
logits <span class="token operator">=</span> output<span class="token punctuation">.</span>logits
<span class="token keyword">print</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># è·å–é¢„æµ‹ç±»åˆ«ï¼šæ‰¾åˆ°logitsä¸­æœ€å¤§å€¼çš„ç´¢å¼•</span>
<span class="token comment"># torch.argmaxè¿”å›æœ€å¤§å€¼æ‰€åœ¨çš„ç´¢å¼•</span>
<span class="token comment"># dim=1è¡¨ç¤ºæˆ‘ä»¬åœ¨ç±»åˆ«ç»´åº¦ï¼ˆè€Œä¸æ˜¯æ‰¹æ¬¡ç»´åº¦ï¼‰ä¸Šå¯»æ‰¾æœ€å¤§å€¼</span>
predicted_class_id <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predicted_class_id<span class="token punctuation">)</span>  <span class="token comment"># æ­¤æ—¶è¿˜æ˜¯PyTorchå¼ é‡</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

predicted_class_id <span class="token operator">=</span> predicted_class_id<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># ä½¿ç”¨.item()å°†å¼ é‡è½¬æ¢ä¸ºPythonæ•´æ•°</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predicted_class_id<span class="token punctuation">)</span>  <span class="token comment"># ç°åœ¨æ˜¯æ™®é€šæ•´æ•°ï¼ˆ0æˆ–1ï¼‰</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ===================== ç»“æœæ˜ å°„å’Œè¾“å‡º =====================</span>
<span class="token comment"># å®šä¹‰ç±»åˆ«æ ‡ç­¾ï¼ˆæ³¨æ„SST-2çš„æ ‡å‡†é¡ºåºï¼‰</span>
labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Negative'</span><span class="token punctuation">,</span> <span class="token string">'Positive'</span><span class="token punctuation">]</span>

<span class="token comment"># è·å–é¢„æµ‹ç»“æœå¯¹åº”çš„äººç±»å¯è¯»æ ‡ç­¾</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">[</span>predicted_class_id<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>æµ‹è¯•ç»“æœ</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1045</span><span class="token punctuation">,</span> <span class="token number">2293</span><span class="token punctuation">,</span> <span class="token number">2859</span><span class="token punctuation">,</span>  <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

SequenceClassifierOutput<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> logits<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4.1768</span><span class="token punctuation">,</span>  <span class="token number">4.4845</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attentions<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4.1768</span><span class="token punctuation">,</span>  <span class="token number">4.4845</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token number">1</span>

Positive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







<h2 id="åŒ»ç–—å¤§æ¨¡å‹"><a href="#åŒ»ç–—å¤§æ¨¡å‹" class="headerlink" title="åŒ»ç–—å¤§æ¨¡å‹"></a>åŒ»ç–—å¤§æ¨¡å‹</h2><table>
<thead>
<tr>
<th>æ¨¡å‹</th>
</tr>
</thead>
<tbody><tr>
<td>åä½—</td>
</tr>
<tr>
<td>BioGPT</td>
</tr>
</tbody></table>
<h2 id="å¤§æ¨¡å‹-Leaderboard"><a href="#å¤§æ¨¡å‹-Leaderboard" class="headerlink" title="å¤§æ¨¡å‹ Leaderboard"></a>å¤§æ¨¡å‹ Leaderboard</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://aider.chat/docs/leaderboards/">https://aider.chat/docs/leaderboards/</a></p>
<p><a target="_blank" rel="noopener" href="https://livebench.ai/#/">https://livebench.ai/#/</a></p>
</blockquote>
<h2 id="å¤§æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼"><a href="#å¤§æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼" class="headerlink" title="å¤§æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼"></a>å¤§æ¨¡å‹çš„ä½¿ç”¨æ–¹å¼</h2><h3 id="1-ç½‘é¡µç«¯è°ƒç”¨ï¼ˆæœ€æ–¹ä¾¿çš„æ–¹å¼ï¼‰"><a href="#1-ç½‘é¡µç«¯è°ƒç”¨ï¼ˆæœ€æ–¹ä¾¿çš„æ–¹å¼ï¼‰" class="headerlink" title="1. ç½‘é¡µç«¯è°ƒç”¨ï¼ˆæœ€æ–¹ä¾¿çš„æ–¹å¼ï¼‰"></a>1. ç½‘é¡µç«¯è°ƒç”¨ï¼ˆæœ€æ–¹ä¾¿çš„æ–¹å¼ï¼‰</h3><p>è¿™ç§æ–¹å¼é€‚åˆä¸éœ€è¦æ·±åº¦é›†æˆæˆ–æŠ€æœ¯é—¨æ§›è¾ƒä½çš„åœºæ™¯ï¼Œç”¨æˆ·é€šè¿‡æµè§ˆå™¨ç›´æ¥ä¸å¤§æ¨¡å‹äº¤äº’ã€‚</p>
<p>ğŸ“Œ ä»£è¡¨å¹³å°</p>
<table>
<thead>
<tr>
<th>å¹³å°åç§°</th>
<th>å…¬å¸å</th>
<th>æ¨¡å‹ç±»å‹</th>
<th>å®˜ç½‘é“¾æ¥</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ChatGPT</strong></td>
<td>OpenAI</td>
<td>GPT-4</td>
<td><a target="_blank" rel="noopener" href="https://chat.openai.com/">ğŸ”— chat.openai.com</a></td>
</tr>
<tr>
<td><strong>Claude</strong></td>
<td>Anthropic</td>
<td>Claude 3.5 / Claude 3.7 Sonnet</td>
<td><a target="_blank" rel="noopener" href="https://claude.ai/">ğŸ”— claude.ai</a></td>
</tr>
<tr>
<td><strong>Gemini</strong></td>
<td>Google DeepMind</td>
<td>Gemini 1.5 ç³»åˆ—ï¼ˆå‰ Bardï¼‰</td>
<td><a target="_blank" rel="noopener" href="https://gemini.google.com/">ğŸ”— gemini.google.com</a></td>
</tr>
<tr>
<td><strong>POE</strong></td>
<td>Quora</td>
<td>GPTã€Claudeã€Geminiã€Mistralç­‰</td>
<td><a target="_blank" rel="noopener" href="https://poe.com/">ğŸ”— poe.com</a></td>
</tr>
<tr>
<td><strong>DeepSeek</strong></td>
<td>DeepSeek</td>
<td>DeepSeek-V3ã€DeepSeek-R1</td>
<td><a target="_blank" rel="noopener" href="https://www.deepseek.com/">ğŸ”— www.deepseek.com</a></td>
</tr>
<tr>
<td><strong>é€šä¹‰åƒé—®</strong></td>
<td>é˜¿é‡Œäº‘</td>
<td>Qwen ç³»åˆ—</td>
<td><a target="_blank" rel="noopener" href="https://tongyi.aliyun.com/">ğŸ”— tongyi.aliyun.com</a></td>
</tr>
<tr>
<td><strong>è±†åŒ…</strong></td>
<td>å­—èŠ‚è·³åŠ¨</td>
<td>Skywork / MiniMax</td>
<td><a target="_blank" rel="noopener" href="https://www.doubao.com/">ğŸ”— www.doubao.com</a></td>
</tr>
<tr>
<td><strong>Kimi</strong></td>
<td>æœˆä¹‹æš—</td>
<td>Moonshot ç³»åˆ—</td>
<td>ğŸ”— <a target="_blank" rel="noopener" href="https://kimi.moonshot.cn/">kimi.moonshot.cn</a></td>
</tr>
<tr>
<td><strong>æ™ºè°±æ¸…è¨€</strong></td>
<td>æ™ºè°±AI</td>
<td>ChatGLM ç³»åˆ—</td>
<td><a target="_blank" rel="noopener" href="https://chatglm.cn/">ğŸ”— chatglm.cn</a></td>
</tr>
</tbody></table>
<h3 id="2-APIè°ƒç”¨ï¼ˆé€‚åˆå¼€å‘è€…ï¼‰"><a href="#2-APIè°ƒç”¨ï¼ˆé€‚åˆå¼€å‘è€…ï¼‰" class="headerlink" title="2. APIè°ƒç”¨ï¼ˆé€‚åˆå¼€å‘è€…ï¼‰"></a>2. <strong>APIè°ƒç”¨ï¼ˆé€‚åˆå¼€å‘è€…ï¼‰</strong></h3><h3 id="3-æœ¬åœ°éƒ¨ç½²è°ƒç”¨ï¼ˆæ³¨é‡éšç§å’Œå®‰å…¨ï¼‰"><a href="#3-æœ¬åœ°éƒ¨ç½²è°ƒç”¨ï¼ˆæ³¨é‡éšç§å’Œå®‰å…¨ï¼‰" class="headerlink" title="3. æœ¬åœ°éƒ¨ç½²è°ƒç”¨ï¼ˆæ³¨é‡éšç§å’Œå®‰å…¨ï¼‰"></a>3. æœ¬åœ°éƒ¨ç½²è°ƒç”¨ï¼ˆæ³¨é‡éšç§å’Œå®‰å…¨ï¼‰</h3><h4 id="ollamaç®€ä»‹"><a href="#ollamaç®€ä»‹" class="headerlink" title="ollamaç®€ä»‹"></a>ollamaç®€ä»‹</h4><p>Ollama æ˜¯ä¸€ä¸ªç”¨äºåœ¨æœ¬åœ°è¿è¡Œã€éƒ¨ç½²å’Œç®¡ç†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼€æºå·¥å…·ï¼Œç‰¹åˆ«é€‚åˆå¼€å‘è€…ã€ç ”ç©¶äººå‘˜æˆ–ä»»ä½•æƒ³ç¦»çº¿æˆ–åœ¨ç§æœ‰ç¯å¢ƒä¸­ä½¿ç”¨ AI æ¨¡å‹çš„ç”¨æˆ·ã€‚</p>
<blockquote>
<p>ollamaå®˜æ–¹ç½‘é¡µï¼š<a target="_blank" rel="noopener" href="https://ollama.com/">https://ollama.com/</a></p>
</blockquote>
<h4 id="ollamaå¸¸ç”¨å‘½ä»¤"><a href="#ollamaå¸¸ç”¨å‘½ä»¤" class="headerlink" title="ollamaå¸¸ç”¨å‘½ä»¤"></a>ollamaå¸¸ç”¨å‘½ä»¤</h4><h5 id="æ¨¡å‹ç®¡ç†"><a href="#æ¨¡å‹ç®¡ç†" class="headerlink" title="æ¨¡å‹ç®¡ç†"></a>æ¨¡å‹ç®¡ç†</h5><table>
<thead>
<tr>
<th align="left">å‘½ä»¤</th>
<th align="left">è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama pull &lt;æ¨¡å‹å&gt;</code></td>
<td align="left">ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚ <code>llama3</code>ã€<code>mistral</code>ï¼‰</td>
</tr>
<tr>
<td align="left"><code>ollama list</code></td>
<td align="left">æŸ¥çœ‹å·²å®‰è£…çš„æ¨¡å‹åˆ—è¡¨</td>
</tr>
<tr>
<td align="left"><code>ollama rm &lt;æ¨¡å‹å&gt;</code></td>
<td align="left">åˆ é™¤æœ¬åœ°æ¨¡å‹</td>
</tr>
<tr>
<td align="left"><code>ollama cp &lt;æºæ¨¡å‹&gt; &lt;æ–°æ¨¡å‹å&gt;</code></td>
<td align="left">å¤åˆ¶æ¨¡å‹å‰¯æœ¬</td>
</tr>
<tr>
<td align="left"><code>ollama show --license &lt;æ¨¡å‹å&gt;</code></td>
<td align="left">æŸ¥çœ‹æ¨¡å‹è®¸å¯è¯</td>
</tr>
</tbody></table>
<h5 id="è¿è¡Œä¸äº¤äº’"><a href="#è¿è¡Œä¸äº¤äº’" class="headerlink" title="è¿è¡Œä¸äº¤äº’"></a>è¿è¡Œä¸äº¤äº’</h5><table>
<thead>
<tr>
<th align="left">å‘½ä»¤</th>
<th align="left">è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama run &lt;æ¨¡å‹å&gt;</code></td>
<td align="left">å¯åŠ¨äº¤äº’å¼å¯¹è¯ï¼ˆé»˜è®¤åŠ è½½æ¨¡å‹ï¼‰</td>
</tr>
<tr>
<td align="left"><code>ollama run &lt;æ¨¡å‹å&gt; "ä½ çš„æç¤ºè¯"</code></td>
<td align="left">ç›´æ¥è¾“å…¥æç¤ºè¯å¹¶è·å–è¾“å‡ºï¼ˆéäº¤äº’ï¼‰</td>
</tr>
<tr>
<td align="left"><code>ollama serve</code></td>
<td align="left">å¯åŠ¨æœ¬åœ° API æœåŠ¡ï¼ˆé»˜è®¤ç«¯å£ <code>11434</code>ï¼‰</td>
</tr>
</tbody></table>
<h5 id="ç³»ç»Ÿä¸è°ƒè¯•"><a href="#ç³»ç»Ÿä¸è°ƒè¯•" class="headerlink" title="ç³»ç»Ÿä¸è°ƒè¯•"></a>ç³»ç»Ÿä¸è°ƒè¯•</h5><table>
<thead>
<tr>
<th align="left">å‘½ä»¤</th>
<th align="left">è¯´æ˜</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama help</code></td>
<td align="left">æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤å¸®åŠ©</td>
</tr>
<tr>
<td align="left"><code>ollama version</code></td>
<td align="left">æŸ¥çœ‹ Ollama ç‰ˆæœ¬</td>
</tr>
<tr>
<td align="left"><code>OLLAMA_MODELS=&lt;è·¯å¾„&gt;</code></td>
<td align="left">æŒ‡å®šæ¨¡å‹å­˜å‚¨è·¯å¾„ï¼ˆç¯å¢ƒå˜é‡ï¼‰</td>
</tr>
<tr>
<td align="left"><code>ollama ps</code></td>
<td align="left">æŸ¥çœ‹å½“å‰è¿è¡Œçš„æ¨¡å‹è¿›ç¨‹</td>
</tr>
</tbody></table>
<h4 id="ollamaä¸‹è½½æ¨¡å‹"><a href="#ollamaä¸‹è½½æ¨¡å‹" class="headerlink" title="ollamaä¸‹è½½æ¨¡å‹"></a>ollamaä¸‹è½½æ¨¡å‹</h4><p>ollamaä¸‹è½½deepseekï¼ˆ<a target="_blank" rel="noopener" href="https://ollama.com/library/deepseek-r1">https://ollama.com/library/deepseek-r1</a>ï¼‰</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run deepseek-r1:7b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h4 id="Cherry-Studio"><a href="#Cherry-Studio" class="headerlink" title="Cherry Studio"></a>Cherry Studio</h4><h3 id="4-æ’ä»¶-x2F-Agentç³»ç»Ÿï¼ˆæ‰“é€ æ™ºèƒ½å·¥ä½œæµï¼‰"><a href="#4-æ’ä»¶-x2F-Agentç³»ç»Ÿï¼ˆæ‰“é€ æ™ºèƒ½å·¥ä½œæµï¼‰" class="headerlink" title="4. æ’ä»¶/Agentç³»ç»Ÿï¼ˆæ‰“é€ æ™ºèƒ½å·¥ä½œæµï¼‰"></a>4. æ’ä»¶/Agentç³»ç»Ÿï¼ˆæ‰“é€ æ™ºèƒ½å·¥ä½œæµï¼‰</h3>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Rickyã®æ°´æœæ‘Š</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://ricky2333.github.io/AI-basics/index.html">https://ricky2333.github.io/AI-basics/index.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/about" target="_blank">Rickyã®æ°´æœæ‘Š</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">æ— æ ‡ç­¾</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">èµ</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">ä½ çš„èµè¯†æ˜¯æˆ‘å‰è¿›çš„åŠ¨åŠ›</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">æ”¯ä»˜å®</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">å¾® ä¿¡</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="æ”¯ä»˜å®æ‰“èµäºŒç»´ç ">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="å¾®ä¿¡æ‰“èµäºŒç»´ç ">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;æœ¬ç¯‡
            </div>
            <div class="card">
                <a href="/AI-basics/index.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯">
                        
                        <span class="card-title">Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Rickyã®æ°´æœæ‘Š
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                æœ¬ç¯‡&nbsp;<i class="far fa-dot-circle"></i>
            </div>
            <div class="card">
                <a href="/AI-basics/index.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯">
                        
                        <span class="card-title">Ricky ã® å¤§æ¨¡å‹å­¦ä¹ ä¹‹è·¯</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Rickyã®æ°´æœæ‘Š
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        // if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
        //     newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        // }
        newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'æ¥æº: Rickyã®æ°´æœæ‘Š<br />'
            + 'æ–‡ç« ä½œè€…: Rickyã®æ°´æœæ‘Š<br />'
            + 'æ–‡ç« é“¾æ¥: <a href="' + url + '">' + url + '</a><br />'
            + 'æœ¬æ–‡ç« è‘—ä½œæƒå½’ä½œè€…æ‰€æœ‰ï¼Œä»»ä½•å½¢å¼çš„è½¬è½½éƒ½è¯·æ³¨æ˜å‡ºå¤„ã€‚';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <!-- <div class="toc-widget card" style="background-color: white;"> -->
        <div class="toc-widget card">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="tencent"
                   type="playlist"
                   id="8891306868"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023-2025</span>
            
            <!-- <span id="year">2023</span> -->
            <a href="/about" target="_blank">Rickyã®æ°´æœæ‘Š</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            <!-- |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a> -->
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                class="white-color">311.7k</span>&nbsp;å­—
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;æ¬¡
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;äºº
            </span>
            
            <br>
            
            <span id="sitetime">è½½å…¥è¿è¡Œæ—¶é—´...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2023";
                    var startMonth = "3";
                    var startDate = "24";
                    var startHour = "7";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "æœ¬ç«™å·²è¿è¡Œ " + diffDays + " å¤© " + diffHours +
                            " å°æ—¶ " + diffMinutes + " åˆ†é’Ÿ " + diffSeconds + " ç§’";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "æœ¬ç«™å·²è¿è¡Œ " + diffYears + " å¹´ " + diffDays +
                            " å¤© " + diffHours + " å°æ—¶ " + diffMinutes + " åˆ†é’Ÿ " + diffSeconds + " ç§’";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Ricky2333" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:rickyxlearner@qq.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=775641698" class="tooltipped" target="_blank" data-tooltip="QQè”ç³»æˆ‘: 775641698" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS è®¢é˜…" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="sum-moon-box">
    <a class="btn-floating btn-large waves-effect waves-light" onclick="switchNightMode()" title="åˆ‡æ¢ä¸»é¢˜" >
      <i id="sum-moon-icon" class="fas fa-sun" style="width:48px; height:48px; font-size: 28px;"></i>
    </a>
  </div>
  
  <script>
    function switchNightMode() {
      sessionStorage.setItem('changeTheme', true)
      $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
          $('#dark-mode').length > 0
          ? (document.body.removeAttribute('id'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon'))
          : (document.body.setAttribute('id', 'dark-mode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
  
          setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
              $(this).remove()
            })
          }, 2e3)
        })
    }
  </script>

  <!-- <div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script> -->

    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "ğŸ‰æ”¶æ‘Šå›å®¶å•¦<ï¼ˆ@ï¿£ï¸¶ï¿£@ï¼‰>", clearTimeout(st)) : (document.title = "ğŸ‰æ‘Šä¸»å›æ¥äº† (*ï¿£â–½ï¿£*)ãƒ–", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>

    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?fa6c571338ef69fd41a561901f549e84";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- å†’æ³¡ -->
    
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            document.write(
                '<script type="text/javascript" src="/libs/others/buble.js"><\/script>'
            );
        </script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
