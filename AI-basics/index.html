<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Ricky の 大模型学习之路, Rickyの水果摊">
    <meta name="description" content="Rickyの个人博客">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Ricky の 大模型学习之路 | Rickyの水果摊</title>
    <link rel="icon" type="image/png" href="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <script src="/libs/jquery/jquery.min.js"></script>

    <link rel="stylesheet" type="text/css" href="/css/loading.css">

<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Rickyの水果摊" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/598673.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    
    <div id="loading-box">
      <div class="loading-left-bg"></div>
      <div class="loading-right-bg"></div>
      <div class="spinner-box">
        <div class="configure-border-1">
          <div class="configure-core"></div>
        </div>
        <div class="configure-border-2">
          <div class="configure-core"></div>
        </div>
        <div class="loading-word">加载中...</div>
      </div>
    </div>
    <!-- 页面加载动画 -->
    <script>
      $(document).ready(function () {
        document.body.style.overflow = 'auto';
        document.getElementById('loading-box').classList.add("loaded")
      })
    </script>
  

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Rickyの水果摊</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>博客</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/tags">
          
          <i class="fas fa-tags" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>博客标签夹</span>
        </a>
      </li>
      
      <li>
        <a href="/categories">
          
          <i class="fas fa-bookmark" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>博客分类图</span>
        </a>
      </li>
      
      <li>
        <a href="/archives">
          
          <i class="fas fa-archive" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>创作时光轴</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">

      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/about">
          
          <i class="fas fa-user-circle" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>个人主页</span>
        </a>
      </li>
      
      <li>
        <a href="/resume">
          
          <i class="fas fa-file" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>个人简历</span>
        </a>
      </li>
      
      <li>
        <a href="/self-journey">
          
          <i class="fas fa-train" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>个人旅途</span>
        </a>
      </li>
      
      <li>
        <a href="/self-awareness">
          
          <i class="fas fa-lightbulb" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>自我认知</span>
        </a>
      </li>
      
      <li>
        <a href="/self-growth">
          
          <i class="fas fa-chart-line" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>个人成长</span>
        </a>
      </li>
      
      <li>
        <a href="/anilist">
          
          <i class="fas fa-tv" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>追番列表</span>
        </a>
      </li>
      
      <li>
        <a href="/world-exploration">
          
          <i class="fas fa-globe" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>世界探索</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-language" style="zoom: 0.6;"></i>
      
      <span>外语</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/EngTOEFL">
          
          <span>EN｜TOEFL经验</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicEnglish">
          
          <span>EN｜学术英语</span>
        </a>
      </li>
      
      <li>
        <a href="/EngGrammar">
          
          <span>EN｜英语语法</span>
        </a>
      </li>
      
      <li>
        <a href="/JpBasic">
          
          <span>JP｜五十音图</span>
        </a>
      </li>
      
      <li>
        <a href="/JpVocab">
          
          <span>JP｜基础词汇</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-code" style="zoom: 0.6;"></i>
      
      <span>科研</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/AcademicFoundation">
          
          <span>科研基础技能</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicEnglish">
          
          <span>学术英语</span>
        </a>
      </li>
      
      <li>
        <a href="/AcademicDL">
          
          <span>深度学习</span>
        </a>
      </li>
      
      <li>
        <a href="/Pytorch">
          
          <span>Pytorch</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-keyboard" style="zoom: 0.6;"></i>
      
      <span>AI</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/AI-basics">
          
          <span>AI-大模型</span>
        </a>
      </li>
      
      <li>
        <a href="/">
          
          <span>AI-相关理论</span>
        </a>
      </li>
      
      <li>
        <a href="/AI-tools">
          
          <span>AI-实用工具</span>
        </a>
      </li>
      
      <li>
        <a href="/AI-news">
          
          <span>AI-好文收录</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-keyboard" style="zoom: 0.6;"></i>
      
      <span>OI</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%9F%A5%E8%AF%86%E7%82%B9/">
          
          <span>信息奥赛｜知识点</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E5%8D%95/">
          
          <span>信息奥赛｜题单</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E8%A7%A3/">
          
          <span>信息奥赛｜题解</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E5%A4%8D%E7%9B%98/">
          
          <span>信息奥赛｜复盘</span>
        </a>
      </li>
      
      <li>
        <a href="/tags/%E6%9C%AF%E8%AF%AD/">
          
          <span>信息奥赛｜术语</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F">
          
          <span>信息奥赛｜训练</span>
        </a>
      </li>
      
      <li>
        <a href="/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%BB%8F%E9%AA%8C%E5%B8%96">
          
          <span>信息奥赛｜经验帖</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/Codeforces%E9%A2%98%E8%A7%A3/">
          
          <span>Codeforces题解</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/AtCoder%E9%A2%98%E8%A7%A3/">
          
          <span>AtCoder题解</span>
        </a>
      </li>
      
      <li>
        <a href="/categories/AtCoder%E5%A4%8D%E7%9B%98/">
          
          <span>AtCoder复盘</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">

      
      <i class="fas fa-door-open" style="zoom: 0.6;"></i>
      
      <span>收藏馆</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/music-live">
          
          <span>音乐｜Live现场</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-travel">
          
          <span>风景｜云游世界</span>
        </a>
      </li>
      
      <li>
        <a href="/co-study">
          
          <span>效率｜陪伴学习</span>
        </a>
      </li>
      
      <li>
        <a href="/advice">
          
          <span>提升｜经验分享</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-role-model">
          
          <span>访谈｜榜样前辈</span>
        </a>
      </li>
      
      <li>
        <a href="/archive-sentences">
          
          <span>文学｜金句摘录</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://ricky-typora-notes.oss-cn-hangzhou.aliyuncs.com/avatar_circle_mini.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Rickyの水果摊</div>
        <div class="logo-desc">
            
            Rickyの个人博客
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-tags"></i>
			
			博客
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/tags " style="margin-left:75px">
				  
				   <i class="fa fas fa-tags" style="position: absolute;left:50px" ></i>
			      
		          <span>博客标签夹</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories " style="margin-left:75px">
				  
				   <i class="fa fas fa-bookmark" style="position: absolute;left:50px" ></i>
			      
		          <span>博客分类图</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archives " style="margin-left:75px">
				  
				   <i class="fa fas fa-archive" style="position: absolute;left:50px" ></i>
			      
		          <span>创作时光轴</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-user-circle"></i>
			
			关于
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/about " style="margin-left:75px">
				  
				   <i class="fa fas fa-user-circle" style="position: absolute;left:50px" ></i>
			      
		          <span>个人主页</span>
                  </a>
                </li>
              
                <li>

                  <a href="/resume " style="margin-left:75px">
				  
				   <i class="fa fas fa-file" style="position: absolute;left:50px" ></i>
			      
		          <span>个人简历</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-journey " style="margin-left:75px">
				  
				   <i class="fa fas fa-train" style="position: absolute;left:50px" ></i>
			      
		          <span>个人旅途</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-awareness " style="margin-left:75px">
				  
				   <i class="fa fas fa-lightbulb" style="position: absolute;left:50px" ></i>
			      
		          <span>自我认知</span>
                  </a>
                </li>
              
                <li>

                  <a href="/self-growth " style="margin-left:75px">
				  
				   <i class="fa fas fa-chart-line" style="position: absolute;left:50px" ></i>
			      
		          <span>个人成长</span>
                  </a>
                </li>
              
                <li>

                  <a href="/anilist " style="margin-left:75px">
				  
				   <i class="fa fas fa-tv" style="position: absolute;left:50px" ></i>
			      
		          <span>追番列表</span>
                  </a>
                </li>
              
                <li>

                  <a href="/world-exploration " style="margin-left:75px">
				  
				   <i class="fa fas fa-globe" style="position: absolute;left:50px" ></i>
			      
		          <span>世界探索</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-language"></i>
			
			外语
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/EngTOEFL " style="margin-left:75px">
				  
		          <span>EN｜TOEFL经验</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicEnglish " style="margin-left:75px">
				  
		          <span>EN｜学术英语</span>
                  </a>
                </li>
              
                <li>

                  <a href="/EngGrammar " style="margin-left:75px">
				  
		          <span>EN｜英语语法</span>
                  </a>
                </li>
              
                <li>

                  <a href="/JpBasic " style="margin-left:75px">
				  
		          <span>JP｜五十音图</span>
                  </a>
                </li>
              
                <li>

                  <a href="/JpVocab " style="margin-left:75px">
				  
		          <span>JP｜基础词汇</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-code"></i>
			
			科研
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/AcademicFoundation " style="margin-left:75px">
				  
		          <span>科研基础技能</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicEnglish " style="margin-left:75px">
				  
		          <span>学术英语</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AcademicDL " style="margin-left:75px">
				  
		          <span>深度学习</span>
                  </a>
                </li>
              
                <li>

                  <a href="/Pytorch " style="margin-left:75px">
				  
		          <span>Pytorch</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-keyboard"></i>
			
			AI
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/AI-basics " style="margin-left:75px">
				  
		          <span>AI-大模型</span>
                  </a>
                </li>
              
                <li>

                  <a href="/ " style="margin-left:75px">
				  
		          <span>AI-相关理论</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AI-tools " style="margin-left:75px">
				  
		          <span>AI-实用工具</span>
                  </a>
                </li>
              
                <li>

                  <a href="/AI-news " style="margin-left:75px">
				  
		          <span>AI-好文收录</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-keyboard"></i>
			
			OI
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%9F%A5%E8%AF%86%E7%82%B9/ " style="margin-left:75px">
				  
		          <span>信息奥赛｜知识点</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E5%8D%95/ " style="margin-left:75px">
				  
		          <span>信息奥赛｜题单</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>信息奥赛｜题解</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E5%A4%8D%E7%9B%98/ " style="margin-left:75px">
				  
		          <span>信息奥赛｜复盘</span>
                  </a>
                </li>
              
                <li>

                  <a href="/tags/%E6%9C%AF%E8%AF%AD/ " style="margin-left:75px">
				  
		          <span>信息奥赛｜术语</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F " style="margin-left:75px">
				  
		          <span>信息奥赛｜训练</span>
                  </a>
                </li>
              
                <li>

                  <a href="/%E4%BF%A1%E6%81%AF%E5%A5%A5%E8%B5%9B%E7%BB%8F%E9%AA%8C%E5%B8%96 " style="margin-left:75px">
				  
		          <span>信息奥赛｜经验帖</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/Codeforces%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>Codeforces题解</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/AtCoder%E9%A2%98%E8%A7%A3/ " style="margin-left:75px">
				  
		          <span>AtCoder题解</span>
                  </a>
                </li>
              
                <li>

                  <a href="/categories/AtCoder%E5%A4%8D%E7%9B%98/ " style="margin-left:75px">
				  
		          <span>AtCoder复盘</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-door-open"></i>
			
			收藏馆
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/music-live " style="margin-left:75px">
				  
		          <span>音乐｜Live现场</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-travel " style="margin-left:75px">
				  
		          <span>风景｜云游世界</span>
                  </a>
                </li>
              
                <li>

                  <a href="/co-study " style="margin-left:75px">
				  
		          <span>效率｜陪伴学习</span>
                  </a>
                </li>
              
                <li>

                  <a href="/advice " style="margin-left:75px">
				  
		          <span>提升｜经验分享</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-role-model " style="margin-left:75px">
				  
		          <span>访谈｜榜样前辈</span>
                  </a>
                </li>
              
                <li>

                  <a href="/archive-sentences " style="margin-left:75px">
				  
		          <span>文学｜金句摘录</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Ricky2333" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Ricky2333" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>


    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/18.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Ricky の 大模型学习之路</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
        background-color: rgb(255, 255, 255,0.7);
        border-radius: 10px;
        box-shadow: 0 10px 35px 2px rgba(0, 0, 0, .15), 0 5px 15px rgba(0, 0, 0, .07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        /* color: #42b983; */
        color: #20BDFF;
        font-weight: 700;
        /* text-decoration: underline; */
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
        /* color: #20BDFF; */
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    7.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    33 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Ricky-の-大模型学习之路"><a href="#Ricky-の-大模型学习之路" class="headerlink" title="Ricky の 大模型学习之路"></a>Ricky の 大模型学习之路</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h4 id="Tokens-与-Embeddings"><a href="#Tokens-与-Embeddings" class="headerlink" title="Tokens 与 Embeddings"></a>Tokens 与 Embeddings</h4><p>Tokens 与 Embeddings 的区别</p>
<table>
<thead>
<tr>
<th align="center">Concept</th>
<th align="center">Tokens</th>
<th align="center"><strong>Embeddings</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>What is it?</strong></td>
<td align="center">A <strong>textual unit</strong> (like a word or subword)</td>
<td align="center">A <strong>numerical vector</strong> that represents a token’s meaning</td>
</tr>
<tr>
<td align="center"><strong>Data type</strong></td>
<td align="center">Discrete integers (IDs)</td>
<td align="center">Dense floating-point tensors</td>
</tr>
<tr>
<td align="center"><strong>Example</strong></td>
<td align="center"><code>"insulin"</code> → <code>2345</code> (token ID)</td>
<td align="center"><code>[-0.01, 0.32, ..., 1.25]</code> (vector of 1024 floats)</td>
</tr>
<tr>
<td align="center"><strong>Used for</strong></td>
<td align="center">Input to the model (after tokenization)</td>
<td align="center">Internal representation in the model</td>
</tr>
<tr>
<td align="center"><strong>Reversible?</strong></td>
<td align="center">✅ Can convert back to text via tokenizer</td>
<td align="center">❌ Cannot easily recover original text from embedding</td>
</tr>
</tbody></table>
<p>Text → Tokens → Embeddings 的可视化</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">  ┌──────────────────────────────────────────────┐
  │ <span class="token string">"What condition is characterized by..."</span>      │  → text
  └──────────────────────────────────────────────┘
                        ↓
                   Tokenization
                        ↓
┌────────────┬────────────┬────────────┬────────────┐
│  <span class="token string">"What"</span>    │ <span class="token string">"condition"</span>│    <span class="token string">"is"</span>    │   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>      │  → tokens
└────────────┴────────────┴────────────┴────────────┘
                        ↓
           <span class="token punctuation">[</span><span class="token number">1023</span><span class="token punctuation">,</span> <span class="token number">5678</span><span class="token punctuation">,</span> <span class="token number">2345</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>  → token IDs
                        ↓
              ┌───────────────────────┐
              │    Language Model     │   →   Language Model
              └───────────────────────┘
                        ↓
 ┌────────────────────────────────────────────────┐
 │      last_hidden_state <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>      │ → token embeddings
 └────────────────────────────────────────────────┘
                        ↓
             Mean across tokens <span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
                        ↓
         ┌──────────────────────────────┐
         │ Sentence Embedding <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span> │  → sentence embeddings
         └──────────────────────────────┘<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<h3 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h3><h4 id="微调概念清单"><a href="#微调概念清单" class="headerlink" title="微调概念清单"></a>微调概念清单</h4><ul>
<li>为什么需要微调 ？✅（2025.3.11）</li>
<li>微调的概念 ✅ （2025.3.11）</li>
<li>微调的步骤 ✅ （2025.3.11）</li>
<li>微调的策略分类 ✅ （2025.3.11）</li>
<li>微调的框架</li>
<li>具体的微调框架</li>
<li>微调的挑战 ✅ （2025.3.11）</li>
<li>微调的相关术语</li>
</ul>
<h4 id="为什么需要微调？"><a href="#为什么需要微调？" class="headerlink" title="为什么需要微调？"></a>为什么需要微调？</h4><p>虽然预训练的 LLM（如 GPT-4、LLaMA）已经学到了大量知识，但在具体应用中，可能仍然有以下问题：</p>
<ul>
<li><strong>领域适应性不足</strong>：如医疗、法律、金融等专业领域的语言和表达方式。</li>
<li><strong>任务针对性不强</strong>：如情感分析、摘要生成、代码生成等特定任务。</li>
<li><strong>未掌握特定风格</strong>：比如让 ChatGPT 说话更像某个品牌，或者适应某种语气。</li>
</ul>
<h4 id="微调的概念"><a href="#微调的概念" class="headerlink" title="微调的概念"></a>微调的概念</h4><p>大模型微调是指在预训练大模型的基础上，通过特定任务的数据对大模型进一步训练（修改大模型的部分参数、调整大模型的结构等），以提升大模型在该特定任务上的表现。</p>
<h4 id="微调的步骤"><a href="#微调的步骤" class="headerlink" title="微调的步骤"></a>微调的步骤</h4><ul>
<li>准备微调数据集</li>
<li>准备预训练模型</li>
<li>调整模型结构（调整模型的输出层）</li>
<li>使用微调技术进行训练</li>
<li>验证与测试</li>
</ul>
<h4 id="微调的策略分类"><a href="#微调的策略分类" class="headerlink" title="微调的策略分类"></a>微调的策略分类</h4><ul>
<li><strong>全模型微调（Full Fine-Tuning）</strong><ul>
<li>微调所有参数，适合数据充足的情况。</li>
</ul>
</li>
<li><strong>参数高效微调（PEFT, Parameter Efficient Fine-Tuning）</strong><ul>
<li>只更新模型的一部分参数，而冻结大部分参数，减少计算量。</li>
<li><strong>低秩适应微调（LoRA，Low-Rank Adaptation）</strong><ul>
<li>在预训练模型的权重矩阵上添加低秩矩阵，只训练这些低秩矩阵，从而大幅减少需要训练的参数数量。</li>
</ul>
</li>
<li><strong>适配器微调（Adapter Fine-Tuning）</strong><ul>
<li>在预训练模型中插入小的适配器模块，只训练这些适配器模块，而保持预训练模型的参数不变。适配器模块通常是一个小的神经网络层。</li>
</ul>
</li>
</ul>
</li>
<li><strong>提示微调（Prompt Tuning，P-tuning）</strong><ul>
<li>提示微调是一种新兴的微调方法，通过在输入中添加特定的提示，引导模型生成期望的输出，而不需要大量修改模型参数。</li>
</ul>
</li>
<li><strong>知识蒸馏微调（Knowledge Distillation Fine-Tuning）</strong><ul>
<li>知识蒸馏微调是指使用一个已经训练好的大模型（教师模型）来指导一个小模型（学生模型）的训练。通过这种方式，学生模型可以学习教师模型的知识，从而在特定任务上表现更好。</li>
</ul>
</li>
</ul>
<h4 id="微调的挑战"><a href="#微调的挑战" class="headerlink" title="微调的挑战"></a>微调的挑战</h4><ul>
<li><strong>数据需求</strong>：微调需要大量标注数据，数据不足时效果受限。</li>
<li><strong>计算资源</strong>：大模型微调需要大量计算资源，尤其是全模型微调。</li>
</ul>
<h4 id="微调（Fine-tuning）相关术语总结表"><a href="#微调（Fine-tuning）相关术语总结表" class="headerlink" title="微调（Fine-tuning）相关术语总结表"></a>微调（Fine-tuning）相关术语总结表</h4><table>
<thead>
<tr>
<th align="center"><strong>中文术语</strong></th>
<th align="center"><strong>英文术语</strong></th>
<th><strong>术语解释</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">预训练</td>
<td align="center">Pre-training</td>
<td>在大规模无监督数据集上训练模型，使其学习通用语言特征。</td>
</tr>
<tr>
<td align="center">微调</td>
<td align="center">Fine-tuning</td>
<td>在特定领域或任务数据上进一步训练预训练模型，以提升其性能。</td>
</tr>
<tr>
<td align="center">监督微调</td>
<td align="center">Supervised Fine-tuning</td>
<td>使用带有标签的数据进行微调，让模型学习任务的正确输出。</td>
</tr>
<tr>
<td align="center">低秩适配</td>
<td align="center">LoRA (Low-Rank Adaptation)</td>
<td>一种高效微调方法，通过对权重矩阵添加低秩适配层来减少计算成本。</td>
</tr>
<tr>
<td align="center">参数高效微调</td>
<td align="center">PEFT (Parameter Efficient Fine-tuning)</td>
<td>只调整部分参数（如 LoRA、Adapter），而非整个模型，以减少计算需求。</td>
</tr>
<tr>
<td align="center">适配器</td>
<td align="center">Adapter</td>
<td>在 Transformer 层之间插入的小型网络模块，用于高效微调。</td>
</tr>
<tr>
<td align="center">全参数微调</td>
<td align="center">Full Fine-tuning</td>
<td>调整整个模型的所有参数，通常需要更高的计算资源。</td>
</tr>
<tr>
<td align="center">指令微调</td>
<td align="center">Instruction Fine-tuning</td>
<td>通过提供不同的指令数据，使模型更擅长遵循指令。</td>
</tr>
<tr>
<td align="center">强化学习微调</td>
<td align="center">RLHF (Reinforcement Learning from Human Feedback)</td>
<td>结合人类反馈进行强化学习，使模型的回答更符合人类期望。</td>
</tr>
<tr>
<td align="center">数据集</td>
<td align="center">Dataset</td>
<td>用于微调的文本或任务数据，通常分为训练集、验证集和测试集。</td>
</tr>
<tr>
<td align="center">迁移学习</td>
<td align="center">Transfer Learning</td>
<td>在一个任务上训练的模型权重用于另一个任务，以减少训练成本。</td>
</tr>
<tr>
<td align="center">温度参数</td>
<td align="center">Temperature</td>
<td>控制模型输出的随机性，较高温度增加创造性，较低温度增加确定性。</td>
</tr>
<tr>
<td align="center">Token 限制</td>
<td align="center">Token Limit</td>
<td>LLM 处理的最大 token 数，影响训练和推理过程的上下文长度。</td>
</tr>
<tr>
<td align="center">训练损失</td>
<td align="center">Training Loss</td>
<td>衡量模型在训练集上的误差，常见损失函数有交叉熵损失（Cross-Entropy Loss）。</td>
</tr>
<tr>
<td align="center">验证损失</td>
<td align="center">Validation Loss</td>
<td>衡量模型在验证集上的表现，用于避免过拟合。</td>
</tr>
<tr>
<td align="center">过拟合</td>
<td align="center">Overfitting</td>
<td>模型在训练数据上表现良好，但在新数据上泛化能力较差。</td>
</tr>
<tr>
<td align="center">梯度累积</td>
<td align="center">Gradient Accumulation</td>
<td>通过多次累积小批量梯度来模拟更大的批次，降低显存需求。</td>
</tr>
<tr>
<td align="center">梯度裁剪</td>
<td align="center">Gradient Clipping</td>
<td>防止梯度爆炸的技术，限制梯度的最大值。</td>
</tr>
<tr>
<td align="center">学习率</td>
<td align="center">Learning Rate</td>
<td>控制模型参数更新步伐的超参数，影响收敛速度和稳定性。</td>
</tr>
<tr>
<td align="center">预训练权重</td>
<td align="center">Pretrained Weights</td>
<td>经过大规模数据训练的模型参数，可以在微调时进一步优化。</td>
</tr>
<tr>
<td align="center">AdamW 优化器</td>
<td align="center">AdamW Optimizer</td>
<td>一种改进的 Adam 优化器，广泛用于 LLM 微调。</td>
</tr>
<tr>
<td align="center">训练步数</td>
<td align="center">Training Steps</td>
<td>训练过程中进行参数更新的次数，影响模型的收敛情况。</td>
</tr>
<tr>
<td align="center">Batch Size</td>
<td align="center">批次大小</td>
<td>训练时一次处理的数据样本数量，影响计算开销和收敛速度。</td>
</tr>
<tr>
<td align="center">Prompt 工程</td>
<td align="center">Prompt Engineering</td>
<td>通过设计输入提示词来引导 LLM 生成期望的输出。</td>
</tr>
<tr>
<td align="center">指令数据</td>
<td align="center">Instruction Data</td>
<td>训练模型遵循指令格式的数据，如 “请总结这篇文章”。</td>
</tr>
<tr>
<td align="center">增量微调</td>
<td align="center">Incremental Fine-tuning</td>
<td>在已有的微调模型上进一步训练，而不是从基础模型开始。</td>
</tr>
<tr>
<td align="center">混合精度训练</td>
<td align="center">Mixed Precision Training</td>
<td>结合 FP16 和 FP32 进行训练，以减少显存占用并加速计算。</td>
</tr>
<tr>
<td align="center">零样本学习</td>
<td align="center">Zero-shot Learning</td>
<td>模型在未见过的任务上进行预测，无需额外训练。</td>
</tr>
<tr>
<td align="center">少样本学习</td>
<td align="center">Few-shot Learning</td>
<td>通过少量示例让模型适应新任务，提高泛化能力。</td>
</tr>
<tr>
<td align="center">全精度训练</td>
<td align="center">Full Precision Training</td>
<td>使用 FP32 进行训练，计算精度高但显存占用大。</td>
</tr>
</tbody></table>
<hr>
<h2 id="Hugging-Face-实战"><a href="#Hugging-Face-实战" class="headerlink" title="Hugging Face 实战"></a>Hugging Face 实战</h2><h3 id="平台简介"><a href="#平台简介" class="headerlink" title="平台简介"></a>平台简介</h3><p><strong>Hugging Face</strong> 是一家专注于 <strong>自然语言处理（NLP）</strong> 和 <strong>人工智能模型开源与部署</strong> 的公司。</p>
<p>它提供了：</p>
<ul>
<li>✅ 大量预训练模型（BERT、GPT、T5 等）</li>
<li>✅ 一个统一的 Python 库（<code>transformers</code>）</li>
<li>✅ 训练、微调、部署、分享模型的一整套工具</li>
</ul>
<p>Hugging Face 的 <strong>核心产品</strong>：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>功能说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>🤗 transformers</strong></td>
<td>一个强大易用的 Python 库，支持加载、使用、训练各种预训练 transformer 模型</td>
</tr>
<tr>
<td><strong>🤗 Datasets</strong></td>
<td>提供上千个标准数据集（如 SQuAD、SST-2、CoQA）</td>
</tr>
<tr>
<td><strong>🤗 Hub</strong></td>
<td>一个模型社区平台，你可以上传、下载别人训练好的模型</td>
</tr>
<tr>
<td><strong>🤗 Spaces</strong></td>
<td>免费托管和展示你的 AI 项目（支持 Gradio、Streamlit 等）</td>
</tr>
<tr>
<td><strong>🤗 Auto Classes</strong></td>
<td>提供统一的模型加载接口（如 <code>AutoTokenizer</code>, <code>AutoModel</code>）简化使用流程</td>
</tr>
</tbody></table>
<hr>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><p><strong><u>模型名称结构解析</u></strong></p>
<table>
<thead>
<tr>
<th>部分</th>
<th>示例</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><strong>组织名/作者</strong></td>
<td><code>bert-base-uncased</code>（无组织）<br> <code>facebook/bart-large</code></td>
<td>模型发布者，通常是作者、研究机构、公司等</td>
</tr>
<tr>
<td><strong>模型架构</strong></td>
<td><code>bert</code>, <code>roberta</code>, <code>gpt2</code>, <code>t5</code>, <code>llama</code>, <code>distilbert</code></td>
<td>说明使用的 Transformer 架构类型</td>
</tr>
<tr>
<td><strong>大小</strong></td>
<td><code>base</code>, <code>large</code>, <code>small</code></td>
<td>控制参数量和模型规模</td>
</tr>
<tr>
<td><strong>大小写</strong></td>
<td><code>cased</code> / <code>uncased</code></td>
<td>英文是否区分大小写（如 Apple ≠ apple）</td>
</tr>
<tr>
<td><strong>语言</strong></td>
<td><code>english</code>, <code>chinese</code>, <code>multilingual</code></td>
<td>支持的语言</td>
</tr>
<tr>
<td><strong>训练任务 / 数据集</strong></td>
<td><code>finetuned-sst-2</code>, <code>squad</code>, <code>cnn-dailymail</code></td>
<td>说明是否在特定任务上微调过</td>
</tr>
<tr>
<td><strong>特殊训练方法</strong></td>
<td><code>wwm</code>, <code>whole-word-masking</code>, <code>ext</code>, <code>dapt</code>, <code>adapter</code></td>
<td>特殊技术如全词掩码、扩展训练、适配器等</td>
</tr>
</tbody></table>
<p><strong><u>常见命名实例解析</u></strong></p>
<table>
<thead>
<tr>
<th>模型名</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>bert-base-uncased</code></td>
<td>Google 的基础版 BERT，不区分大小写，未微调</td>
</tr>
<tr>
<td><code>google-bert/bert-large-cased-whole-word-masking</code></td>
<td>更大、区分大小写、使用全词掩码的 BERT</td>
</tr>
<tr>
<td><code>distilbert-base-uncased-finetuned-sst-2-english</code></td>
<td>DistilBERT 模型，SST-2 上训练的英文情感分析模型</td>
</tr>
<tr>
<td><code>facebook/bart-large-cnn</code></td>
<td>Facebook 的 BART 模型，微调在 CNN 新闻摘要任务上</td>
</tr>
<tr>
<td><code>google/flan-t5-xl</code></td>
<td>Google 的 FLAN T5 模型，超大版，适合 zero-shot 多任务</td>
</tr>
<tr>
<td><code>microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</code></td>
<td>微软训练的用于生物医学的 PubMed-BERT，专门处理论文摘要</td>
</tr>
</tbody></table>
<p>当手动下载 Hugging Face 上的一个模型（比如 <code>bert-base-uncased</code>），<strong>最重要的文件</strong>有这几类：</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>作用</th>
<th>是否必须</th>
</tr>
</thead>
<tbody><tr>
<td><code>config.json</code></td>
<td>模型结构配置（层数、隐藏维度、分类头等）</td>
<td>✅</td>
</tr>
<tr>
<td><code>pytorch_model.bin</code></td>
<td>模型的权重（PyTorch 格式）</td>
<td>✅</td>
</tr>
<tr>
<td><code>tokenizer_config.json</code></td>
<td>分词器的配置</td>
<td>✅</td>
</tr>
<tr>
<td><code>vocab.txt</code> 或 <code>merges.txt</code> + <code>vocab.json</code></td>
<td>词表（不同模型格式不同）</td>
<td>✅</td>
</tr>
<tr>
<td><code>special_tokens_map.json</code></td>
<td>特殊 token（如 <code>[CLS]</code>, <code>[SEP]</code>, <code>[MASK]</code>）的定义</td>
<td>⚠️ 推荐</td>
</tr>
<tr>
<td><code>tokenizer.json</code></td>
<td>分词器的 fast version 文件</td>
<td>⚠️ 推荐</td>
</tr>
<tr>
<td><code>README.md</code></td>
<td>模型说明文档</td>
<td>❌ 可选</td>
</tr>
</tbody></table>
<hr>
<h3 id="代码基础"><a href="#代码基础" class="headerlink" title="代码基础"></a>代码基础</h3><h4 id="transformer库"><a href="#transformer库" class="headerlink" title="transformer库"></a>transformer库</h4><p><code>transformer</code>库是 Hugging Face 出品的开源库，用于：</p>
<ul>
<li>下载和使用预训练模型（如 BERT, GPT, BioGPT, T5 等）</li>
<li>快速进行文本分类、文本生成、问答、翻译、摘要等任务</li>
<li>提供统一的 <strong>Tokenizer</strong>, <strong>Model</strong>, 和 <strong>Pipeline</strong> 接口</li>
</ul>
<h5 id="🗂️-transformer-核心组件"><a href="#🗂️-transformer-核心组件" class="headerlink" title="🗂️ transformer 核心组件"></a>🗂️ <code>transformer</code> 核心组件</h5><table>
<thead>
<tr>
<th>模块</th>
<th>功能简述</th>
</tr>
</thead>
<tbody><tr>
<td><code>AutoTokenizer</code> / <code>XXXTokenizer</code></td>
<td>把文本转成 tokens 和 ids</td>
</tr>
<tr>
<td><code>AutoModel</code> / <code>XXXModel</code></td>
<td>返回隐藏状态（embeddings）</td>
</tr>
<tr>
<td><code>AutoModelForCausalLM</code> / <code>XXXForCausalLM</code></td>
<td>用于文本生成</td>
</tr>
<tr>
<td><code>pipeline</code></td>
<td>快速使用模型进行任务（如情感分析、QA）</td>
</tr>
</tbody></table>
<h5 id="🧠-不同模型任务的选择"><a href="#🧠-不同模型任务的选择" class="headerlink" title="🧠 不同模型任务的选择"></a>🧠 不同模型任务的选择</h5><table>
<thead>
<tr>
<th>任务</th>
<th>模型类</th>
<th>示例模型名</th>
</tr>
</thead>
<tbody><tr>
<td>文本嵌入</td>
<td><code>AutoModel</code></td>
<td><code>bert-base-uncased</code></td>
</tr>
<tr>
<td>文本分类</td>
<td><code>AutoModelForSequenceClassification</code></td>
<td><code>distilbert-base-uncased-finetuned-sst-2-english</code></td>
</tr>
<tr>
<td>文本生成</td>
<td><code>AutoModelForCausalLM</code></td>
<td><code>gpt2</code>, <code>BioGPT</code></td>
</tr>
<tr>
<td>问答系统</td>
<td><code>AutoModelForQuestionAnswering</code></td>
<td><code>distilbert-base-uncased-distilled-squad</code></td>
</tr>
<tr>
<td>翻译</td>
<td><code>AutoModelForSeq2SeqLM</code></td>
<td><code>t5-small</code>, <code>facebook/mbart-large-50-many-to-many-mmt</code></td>
</tr>
</tbody></table>
<hr>
<h4 id="pipeline-的使用"><a href="#pipeline-的使用" class="headerlink" title="pipeline 的使用"></a>pipeline 的使用</h4><hr>
<h4 id="不同任务的简单示例"><a href="#不同任务的简单示例" class="headerlink" title="不同任务的简单示例"></a>不同任务的简单示例</h4><h5 id="📘-句子-x2F-文本嵌入（AutoModel）"><a href="#📘-句子-x2F-文本嵌入（AutoModel）" class="headerlink" title="📘 句子/文本嵌入（AutoModel）"></a>📘 <strong>句子/文本嵌入（<code>AutoModel</code>）</strong></h5><p><code>AutoModel</code> 只返回 <strong>hidden states</strong>，不包含分类头（不进行预测，<strong>只做特征提取</strong>）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel

<span class="token comment"># 加载本地保存的 DistilBERT 模型和分词器</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 输入句子</span>
text <span class="token operator">=</span> <span class="token string">"Transformers are powerful models for NLP."</span>

<span class="token comment"># 使用分词器将句子转为模型输入张量</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># 禁用梯度计算，执行前向传播</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># 对所有 token 的隐藏状态做平均，得到句子级别的向量表示</span>
sentence_embedding <span class="token operator">=</span> outputs<span class="token punctuation">.</span>last_hidden_state<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 打印Embedding的形状（应该是 [1, hidden_size]，如 [1, 768]）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sentence_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>torch.Size([1, 768])</p>
</blockquote>
<hr>
<h5 id="🧾-文本生成（AutoModelForCausalLM）"><a href="#🧾-文本生成（AutoModelForCausalLM）" class="headerlink" title="🧾 文本生成（AutoModelForCausalLM）"></a>🧾 <strong>文本生成（<code>AutoModelForCausalLM</code>）</strong></h5><p><code>AutoModelForCausalLM</code> 是 Hugging Face 的自动模型加载器的一种，用于加载 <strong>因果语言建模（Causal Language Modeling）</strong> 的模型。该模型用于「给定前文，预测下一个词（token）」的场景。</p>
<blockquote>
<p>🧠 “Causal LM” 是什么意思？</p>
<p><strong>Causal = 因果性</strong>：只能看到“过去”的词，不能看到未来的词。</p>
<p>训练目标：预测当前 token 只依赖于它左边（前面的）token。</p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

<span class="token comment"># Load GPT-2 tokenizer and model (causal language model)</span>
model_path <span class="token operator">=</span> <span class="token string">'***/gpt2'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Define prompt for text generation</span>
prompt <span class="token operator">=</span> <span class="token string">"The future of medicine is"</span>

<span class="token comment"># Tokenize input (returns dictionary with input_ids and attention_mask)</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># Generate text using sampling method</span>
output_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
    <span class="token operator">**</span>inputs<span class="token punctuation">,</span>  <span class="token comment"># Unpack tokenized inputs</span>
    max_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># Maximum total tokens (input + generated)</span>
    do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># Enable probabilistic sampling</span>
    top_k<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># Consider top 50 probable tokens at each step</span>
    top_p<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment"># Nucleus sampling: choose from top tokens covering 90% probability mass</span>
    temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment"># Lower = more predictable, higher = more creative</span>
    pad_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>eos_token_id  <span class="token comment"># Use EOS token for padding</span>
<span class="token punctuation">)</span>

<span class="token comment"># Decode generated token IDs to text</span>
generated_text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>generated_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>tensor([[  464,  2003,   286,  9007,   318,   284,  1064,   649, 23533,    11,<br>           475,   340,   468,   257,   890,   835,   284,   467,   878,   326,<br>          4325,    13,   198,   198,   464,   717,  1688,  8668,  4473,   319,<br>           428,  1808,   373,  5952,   287,   262,  3095,    12, 23664,    82,<br>            11,   475,   340,   373,   407,   257,  1688,  1943,    13,   198]])<br>The future of medicine is to find new medicines, but it has a long way to go before that happens.</p>
<p>The first major clinical trial on this question was conducted in the mid-1980s, but it was not a major success.</p>
</blockquote>
<table>
<thead>
<tr>
<th>参数名</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>**inputs</code></td>
<td>dict</td>
<td>传入经过分词器编码后的输入（如 <code>input_ids</code>、<code>attention_mask</code>）</td>
</tr>
<tr>
<td><code>max_length</code></td>
<td>int</td>
<td>最多生成 <code>max_length</code> 个 token 的文本</td>
</tr>
<tr>
<td><code>do_sample</code></td>
<td>bool</td>
<td>是否启用采样策略（True 表示每一步不只选最可能的词，而是根据概率分布采样）</td>
</tr>
<tr>
<td><code>top_k</code></td>
<td>int</td>
<td>每一步只从概率最高的前 K 个词中进行采样，限制采样范围，避免奇怪的词被选中</td>
</tr>
<tr>
<td><code>top_p</code></td>
<td>float (0-1)</td>
<td>核采样（nucleus sampling）：只从累计概率达到 p 的前几个词中采样，动态选择候选词数量</td>
</tr>
<tr>
<td><code>temperature</code></td>
<td>float (&gt;0)</td>
<td>控制输出的“创造性”：越低越保守（趋近确定性），越高越发散（趋近随机）</td>
</tr>
<tr>
<td><code>pad_token_id</code></td>
<td>int</td>
<td>填充 token 的 ID（用于对齐长度），这里设为模型的终止符号（EOS）ID，避免报错</td>
</tr>
</tbody></table>
<hr>
<h5 id="📊-文本分类（AutoModelForSequenceClassification）"><a href="#📊-文本分类（AutoModelForSequenceClassification）" class="headerlink" title="📊 文本分类（AutoModelForSequenceClassification）"></a>📊 <strong>文本分类（<code>AutoModelForSequenceClassification</code>）</strong></h5><p><code>AutoModelForSequenceClassification</code> 是 Hugging Face Transformers 库中的一个通用模型接口，用于<strong>加载和使用预训练的文本分类模型</strong>。</p>
<p>它是在一个基础模型（比如 BERT、RoBERTa、DistilBERT 等）后面<strong>加了一个分类头</strong>（通常是一个线性层 + Softmax）：</p>
<pre class="line-numbers language-none"><code class="language-none">Text → Tokenizer → Transformer Encoder (BERT) → [CLS] → Linear Layer → 分类概率<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>最终输出是：</p>
<pre class="line-numbers language-none"><code class="language-none">outputs.logits  # shape = (batch_size, num_labels)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>✅ 适用任务类型</p>
<table>
<thead>
<tr>
<th>任务类型</th>
<th>示例输入</th>
<th>示例输出</th>
</tr>
</thead>
<tbody><tr>
<td>二分类（情感分析）</td>
<td>“I love this product.”</td>
<td>[Negative, ✅Positive]</td>
</tr>
<tr>
<td>多分类（意图识别）</td>
<td>“Book a flight to Tokyo tomorrow.”</td>
<td>[weather, ✅booking, cancel]</td>
</tr>
<tr>
<td>文档分类</td>
<td>一篇完整文章</td>
<td>[sport, politics, tech]</td>
</tr>
</tbody></table>
<p>示例代码</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

<span class="token comment"># ==== 1. 加载本地模型和分词器 ====</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ==== 2. 输入文本 ====</span>
text <span class="token operator">=</span> <span class="token string">"Clannad is the best anime I have ever seen."</span>  
<span class="token comment"># 将文本编码为模型输入（包含 input_ids 和 attention_mask）</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># ==== 3. 前向传播并计算概率 ====</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 禁用梯度，节省内存，仅推理</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>        <span class="token comment"># 输出包含 logits（原始分数）</span>
    logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits          <span class="token comment"># logits 形状: (1, 2)，表示对两个标签的评分</span>
    probabilities <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 使用 softmax 转为概率分布</span>

<span class="token comment"># ==== 4. 获取预测类别 ====</span>
predicted_class <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>probabilities<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 获取最大概率对应的索引</span>
labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Negative"</span><span class="token punctuation">,</span> <span class="token string">"Positive"</span><span class="token punctuation">]</span>  <span class="token comment"># SST-2 数据集的两个标签</span>

<span class="token comment"># ==== 5. 打印输出结果 ====</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== 原始模型输出 ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Logits（未归一化分数）==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== 概率分布（Softmax 之后）==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>probabilities<span class="token punctuation">)</span>

<span class="token comment"># 打印最终预测标签与概率</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n✅ 预测情感类别: </span><span class="token interpolation"><span class="token punctuation">{</span>labels<span class="token punctuation">[</span>predicted_class<span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (</span><span class="token interpolation"><span class="token punctuation">{</span>probabilities<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>predicted_class<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">)"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>=== Raw model outputs ===<br>SequenceClassifierOutput(loss=None, logits=tensor([[-4.2006,  4.5068]]), hidden_states=None, attentions=None)</p>
<p>=== Logits (unnormalized scores) ===<br>tensor([[-4.2006,  4.5068]])</p>
<p>=== Probabilities (after softmax) ===<br>tensor([[1.6534e-04, 9.9983e-01]])</p>
<p>✅ Predicted class: Positive (0.9998)</p>
</blockquote>
<hr>
<h5 id="❓问答系统（AutoModelForQuestionAnswering）"><a href="#❓问答系统（AutoModelForQuestionAnswering）" class="headerlink" title="❓问答系统（AutoModelForQuestionAnswering）"></a>❓<strong>问答系统（<code>AutoModelForQuestionAnswering</code>）</strong></h5><p><code>AutoModelForQuestionAnswering</code> 是 Hugging Face 提供的自动加载接口，用于构建 <strong>提取式问答系统</strong>。</p>
<blockquote>
<p><strong>提取式问答系统</strong>：给定一个<strong>问题</strong>和一个<strong>上下文段落</strong>，模型从段落中<strong>提取出一个连续的答案片段</strong>。</p>
<p><strong>输入：</strong></p>
<p>上下文（context）：”The heart pumps blood through the body using rhythmic contractions.”</p>
<p>问题（question）：”What does the heart do?”</p>
<p><strong>模型输出：</strong>“pumps blood through the body”</p>
</blockquote>
<p>此类模型基于 BERT、RoBERTa 等 Transformer 架构，模型学习为每个 token 预测两个分数：</p>
<ul>
<li><strong>Start score</strong>：答案起始位置的概率</li>
<li><strong>End score</strong>：答案结束位置的概率</li>
</ul>
<p>最终选择：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_index <span class="token operator">=</span> argmax<span class="token punctuation">(</span>start_scores<span class="token punctuation">)</span>
end_index <span class="token operator">=</span> argmax<span class="token punctuation">(</span>end_scores<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>所以：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">answer <span class="token operator">=</span> context_tokens<span class="token punctuation">[</span>start_index <span class="token punctuation">:</span> end_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>示例代码</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForQuestionAnswering

<span class="token comment"># ========== 1. 加载模型与分词器 ==========</span>
model_path <span class="token operator">=</span> <span class="token string">"***/distilbert-base-cased-distilled-squad"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ========== 2. 输入问题与上下文 ==========</span>
question <span class="token operator">=</span> <span class="token string">"What does NLP stand for?"</span>
context <span class="token operator">=</span> <span class="token string">"NLP stands for Natural Language Processing, a subfield of artificial intelligence."</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== 原始输入 ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"📌 Question:"</span><span class="token punctuation">,</span> question<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"📄 Context:"</span><span class="token punctuation">,</span> context<span class="token punctuation">)</span>

<span class="token comment"># 编码输入</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># 打印编码后的输入</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Tokenizer 编码结果 ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🧾 input_ids:"</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🧠 tokens:"</span><span class="token punctuation">,</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"📊 attention_mask:"</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># ========== 3. 模型推理 ==========</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># ========== 4. 查看 logits ==========</span>
start_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>start_logits
end_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>end_logits

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== 模型输出分数（logits） ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🚩 start_logits:"</span><span class="token punctuation">,</span> start_logits<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🏁 end_logits:"</span><span class="token punctuation">,</span> end_logits<span class="token punctuation">)</span>

<span class="token comment"># ========== 5. 计算起止位置 ==========</span>
start_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
end_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>end_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n📍 预测的起始位置: </span><span class="token interpolation"><span class="token punctuation">{</span>start_idx<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"📍 预测的结束位置: </span><span class="token interpolation"><span class="token punctuation">{</span>end_idx<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># ========== 6. 解码答案 ==========</span>
<span class="token keyword">if</span> start_idx <span class="token operator">&gt;</span> end_idx<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"⚠️ 起始位置大于结束位置，答案无效。"</span><span class="token punctuation">)</span>
    answer <span class="token operator">=</span> <span class="token string">"[Invalid prediction]"</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>start_idx<span class="token punctuation">:</span>end_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🔍 答案相关 tokens:"</span><span class="token punctuation">,</span> tokens<span class="token punctuation">)</span>
    answer <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_string<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>

<span class="token comment"># ========== 7. 输出最终结果 ==========</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n✅ 最终预测答案:"</span><span class="token punctuation">,</span> answer<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>示例输出</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">
=== 原始输入 ===
📌 Question: What does NLP stand for?
📄 Context: NLP stands for Natural Language Processing, a subfield of artificial intelligence.

=== Tokenizer 编码结果 ===
🧾 input_ids: tensor([[  101,  1327,  1674, 21239,  2101,  2484,  1111,   136,   102, 21239,
          2101,  4061,  1111,  6240,  6828, 18821,  1158,   117,   170,  4841,
          2427,  1104,  8246,  4810,   119,   102]])
🧠 tokens: ['[CLS]', 'What', 'does', 'NL', '##P', 'stand', 'for', '?', '[SEP]', 'NL', '##P', 'stands', 'for', 'Natural', 'Language', 'Process', '##ing', ',', 'a', 'sub', '##field', 'of', 'artificial', 'intelligence', '.', '[SEP]']
📊 attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1]])

=== 模型输出分数（logits） ===
🚩 start_logits: tensor([[-2.3248e+00, -2.4476e+00, -3.1210e+00, -2.7561e+00, -4.8028e+00,
         -4.4546e+00, -5.1295e+00, -2.0812e+00,  1.0627e-02,  3.7939e+00,
         -1.8733e+00, -1.1664e+00, -1.4235e+00,  1.1914e+01,  2.4047e+00,
          2.3639e+00,  4.6805e-01, -1.6326e+00,  1.9572e+00,  1.0077e+00,
         -2.5621e+00, -3.3284e+00,  3.0263e+00, -1.2865e+00, -2.7076e+00,
          1.0653e-02]])
🏁 end_logits: tensor([[-0.8734, -2.4869, -3.9640, -4.1681, -3.1094, -4.6843, -4.2300, -2.2853,
          0.8502, -2.0429,  0.0950, -2.6078, -2.2444,  4.0181,  5.2197,  2.5751,
         11.4774,  5.3121, -2.4660, -3.0402,  0.7667, -4.4215, -1.3441,  4.3169,
          4.8004,  0.8503]])

📍 预测的起始位置: 13
📍 预测的结束位置: 16
🔍 答案相关 tokens: ['Natural', 'Language', 'Process', '##ing']

✅ 最终预测答案: Natural Language Processing<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>🔴 PS：<code>AutoModelForQuestionAnswering</code> 仅用于构建 <strong>提取式问答系统</strong>，不包含其他类型的问答）</p>
<blockquote>
<p><strong><u>拓展：问答系统的若干种范式</u></strong></p>
<table>
<thead>
<tr>
<th align="left">类型</th>
<th align="left">是否需要上下文</th>
<th align="left">答案来源</th>
<th align="left">典型模型</th>
<th align="left">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left">抽取式QA</td>
<td align="left">是</td>
<td align="left">上下文片段</td>
<td align="left">BERT, RoBERTa</td>
<td align="left">文档阅读理解</td>
</tr>
<tr>
<td align="left">生成式QA</td>
<td align="left">可选</td>
<td align="left">模型生成</td>
<td align="left">T5, GPT</td>
<td align="left">开放域问答</td>
</tr>
<tr>
<td align="left">多选QA</td>
<td align="left">是</td>
<td align="left">给定选项</td>
<td align="left">BERT, XLNet</td>
<td align="left">考试系统</td>
</tr>
<tr>
<td align="left">开放域QA</td>
<td align="left">否</td>
<td align="left">知识库/模型</td>
<td align="left">DPR + BERT</td>
<td align="left">智能助手</td>
</tr>
<tr>
<td align="left">视觉QA</td>
<td align="left">是（图片）</td>
<td align="left">图片内容</td>
<td align="left">ViLBERT, CLIP</td>
<td align="left">图像理解</td>
</tr>
<tr>
<td align="left">表格QA</td>
<td align="left">是（表格）</td>
<td align="left">表格数据</td>
<td align="left">TAPAS</td>
<td align="left">结构化数据查询</td>
</tr>
</tbody></table>
<p><strong><u>对比表：提取式问答 vs Zero-shot 问答</u></strong></p>
<table>
<thead>
<tr>
<th>维度</th>
<th>提取式问答（Extractive QA）</th>
<th>Zero-shot 问答（Zero-shot QA）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>定义</strong></td>
<td>从<strong>提供的上下文段落</strong>中提取一个连续的答案</td>
<td>不依赖于提供上下文，直接基于预训练知识生成答案</td>
</tr>
<tr>
<td><strong>依赖上下文</strong></td>
<td>✅ 必须有上下文</td>
<td>❌ 可没有上下文</td>
</tr>
<tr>
<td><strong>模型训练</strong></td>
<td>需要在问答数据集（如 SQuAD）上进行 fine-tune</td>
<td>通常基于大型语言模型（如 GPT-3、T5），无需特定 QA 微调</td>
</tr>
<tr>
<td><strong>输出形式</strong></td>
<td>通常是段落中的子字符串</td>
<td>模型生成的自由形式答案</td>
</tr>
<tr>
<td><strong>模型接口</strong></td>
<td><code>AutoModelForQuestionAnswering</code></td>
<td><code>AutoModelForSeq2SeqLM</code> / <code>AutoModelForCausalLM</code></td>
</tr>
<tr>
<td><strong>示例模型</strong></td>
<td>BERT QA, RoBERTa QA, ALBERT QA</td>
<td>GPT-3, T5, FLAN-T5, BioGPT</td>
</tr>
</tbody></table>
<p><u><strong>各类问答的具体介绍：</strong></u></p>
<p>1.<strong>抽取式问答（Extractive QA）</strong></p>
<ul>
<li><p><strong>特点</strong>：从给定的文本中直接抽取答案片段（span）。</p>
</li>
<li><p><strong>模型示例</strong>：BERT、RoBERTa、DistilBERT。</p>
</li>
<li><p><strong>输入输出</strong>：</p>
<ul>
<li>输入：问题 + 上下文（context）</li>
<li>输出：答案在上下文中的起始和结束位置（字符或token索引）</li>
</ul>
</li>
<li><p><strong>代码示例</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
qa_pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"bert-large-uncased-whole-word-masking-finetuned-squad"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> qa_pipeline<span class="token punctuation">(</span>
    question<span class="token operator">=</span><span class="token string">"What is the capital of France?"</span><span class="token punctuation">,</span>
    context<span class="token operator">=</span><span class="token string">"France is a country in Europe. Its capital is Paris."</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>  <span class="token comment"># 输出：{'answer': 'Paris', 'score': 0.98, ...}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：阅读理解、文档检索（如SQuAD数据集）。</p>
</li>
</ul>
<hr>
<ol start="2">
<li><strong>生成式问答（Generative QA）</strong></li>
</ol>
<ul>
<li><p><strong>特点</strong>：模型根据问题生成自由文本答案（无需依赖上下文中的原句）。</p>
</li>
<li><p><strong>模型示例</strong>：T5、GPT-3、BART。</p>
</li>
<li><p><strong>输入输出</strong>：</p>
<ul>
<li>输入：问题（+ 可选的上下文）</li>
<li>输出：生成的答案文本</li>
</ul>
</li>
<li><p><strong>代码示例</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"text2text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
answer <span class="token operator">=</span> generator<span class="token punctuation">(</span>
    <span class="token string">"question: What is the capital of France? context: France is a country in Europe."</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># 输出：[{'generated_text': 'Paris'}]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：开放域问答、聊天机器人。</p>
</li>
</ul>
<hr>
<ol start="3">
<li><strong>多选问答（Multiple-Choice QA）</strong></li>
</ol>
<ul>
<li><p><strong>特点</strong>：从给定的选项中选择正确答案。</p>
</li>
<li><p><strong>模型示例</strong>：BERT、XLNet。</p>
</li>
<li><p><strong>输入输出</strong>：</p>
<ul>
<li>输入：问题 + 上下文 + 候选选项</li>
<li>输出：选项标签（如A/B/C/D）或置信度分数</li>
</ul>
</li>
<li><p><strong>代码示例</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMultipleChoice<span class="token punctuation">,</span> AutoTokenizer
model <span class="token operator">=</span> AutoModelForMultipleChoice<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>

<span class="token comment"># 问题与选项</span>
question <span class="token operator">=</span> <span class="token string">"What is the capital of France?"</span>
options <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"London"</span><span class="token punctuation">,</span> <span class="token string">"Berlin"</span><span class="token punctuation">,</span> <span class="token string">"Paris"</span><span class="token punctuation">,</span> <span class="token string">"Madrid"</span><span class="token punctuation">]</span>

<span class="token comment"># 对每个选项编码并计算分数</span>
inputs <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span> <span class="token keyword">for</span> opt <span class="token keyword">in</span> options<span class="token punctuation">]</span>
outputs <span class="token operator">=</span> <span class="token punctuation">[</span>model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">.</span>logits <span class="token keyword">for</span> <span class="token builtin">input</span> <span class="token keyword">in</span> inputs<span class="token punctuation">]</span>
best_answer <span class="token operator">=</span> options<span class="token punctuation">[</span>torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>best_answer<span class="token punctuation">)</span>  <span class="token comment"># 输出：Paris</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：考试系统、标准化测试。</p>
</li>
</ul>
<hr>
<ol start="4">
<li><strong>开放域问答（Open-Domain QA）</strong></li>
</ol>
<ul>
<li><p><strong>特点</strong>：无需提供上下文，直接从知识库或模型参数中检索答案。</p>
</li>
<li><p><strong>技术组合</strong>：</p>
<ul>
<li>检索器（如DPR） + 阅读器（如BERT）</li>
<li>纯生成式模型（如GPT-3）</li>
</ul>
</li>
<li><p><strong>代码示例</strong>（检索+生成结合）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 使用Haystack框架（基于检索的QA）</span>
<span class="token keyword">from</span> haystack <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> haystack<span class="token punctuation">.</span>nodes <span class="token keyword">import</span> BM25Retriever<span class="token punctuation">,</span> FARMReader

retriever <span class="token operator">=</span> BM25Retriever<span class="token punctuation">(</span>document_store<span class="token operator">=</span>my_document_store<span class="token punctuation">)</span>
reader <span class="token operator">=</span> FARMReader<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"deepset/bert-base-cased-squad2"</span><span class="token punctuation">)</span>
pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>retriever<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Retriever"</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Query"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pipeline<span class="token punctuation">.</span>add_node<span class="token punctuation">(</span>component<span class="token operator">=</span>reader<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Reader"</span><span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Retriever"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>run<span class="token punctuation">(</span>query<span class="token operator">=</span><span class="token string">"What is the capital of France?"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：智能助手（如Alexa、Siri）。</p>
</li>
</ul>
<hr>
<ol start="5">
<li><strong>视觉问答（Visual QA, VQA）</strong></li>
</ol>
<ul>
<li><p><strong>特点</strong>：基于图像内容回答问题。</p>
</li>
<li><p><strong>模型示例</strong>：ViLBERT、CLIP、BLIP。</p>
</li>
<li><p><strong>输入输出</strong>：</p>
<ul>
<li>输入：图片 + 问题</li>
<li>输出：文本答案</li>
</ul>
</li>
<li><p><strong>代码示例</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
vqa_pipeline <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"visual-question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"dandelin/vilt-b32-finetuned-vqa"</span><span class="token punctuation">)</span>
answer <span class="token operator">=</span> vqa_pipeline<span class="token punctuation">(</span>
    image<span class="token operator">=</span><span class="token string">"paris.jpg"</span><span class="token punctuation">,</span>
    question<span class="token operator">=</span><span class="token string">"What is in the center of the image?"</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># 输出：{'answer': 'Eiffel Tower'}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：图像理解、盲人辅助工具。</p>
</li>
</ul>
<hr>
<ol start="6">
<li><strong>表格问答（Table QA）</strong></li>
</ol>
<ul>
<li><p><strong>特点</strong>：从结构化表格中提取答案。</p>
</li>
<li><p><strong>模型示例</strong>：TAPAS、TaBERT。</p>
</li>
<li><p><strong>代码示例</strong>：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline
table_qa <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"table-question-answering"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"google/tapas-base-finetuned-wtq"</span><span class="token punctuation">)</span>

table <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"City"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Paris"</span><span class="token punctuation">,</span> <span class="token string">"London"</span><span class="token punctuation">,</span> <span class="token string">"Berlin"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"Country"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"France"</span><span class="token punctuation">,</span> <span class="token string">"UK"</span><span class="token punctuation">,</span> <span class="token string">"Germany"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
answer <span class="token operator">=</span> table_qa<span class="token punctuation">(</span>
    table<span class="token operator">=</span>table<span class="token punctuation">,</span>
    query<span class="token operator">=</span><span class="token string">"Which city is in France?"</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>  <span class="token comment"># 输出：{'answer': 'Paris', ...}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><strong>应用场景</strong>：Excel/数据库查询、金融报表分析。</p>
</li>
</ul>
</blockquote>
<hr>
<h5 id="🌍-翻译任务（AutoModelForSeq2SeqLM）"><a href="#🌍-翻译任务（AutoModelForSeq2SeqLM）" class="headerlink" title="🌍 翻译任务（AutoModelForSeq2SeqLM）"></a>🌍 <strong>翻译任务（<code>AutoModelForSeq2SeqLM</code>）</strong></h5><p><code>AutoModelForSeq2SeqLM</code> 是 Hugging Face 中用于 <strong>生成式任务</strong>（如摘要、翻译、问答、对话）的模型接口，适用于 <strong>编码器-解码器结构（Encoder-Decoder）</strong> 的模型架构。</p>
<table>
<thead>
<tr>
<th>任务类型</th>
<th>示例模型</th>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody><tr>
<td><strong>文本摘要</strong></td>
<td><code>facebook/bart-large-cnn</code></td>
<td>新闻文章</td>
<td>概括句子</td>
</tr>
<tr>
<td><strong>机器翻译</strong></td>
<td><code>Helsinki-NLP/opus-mt-en-zh</code></td>
<td>English</td>
<td>中文</td>
</tr>
<tr>
<td><strong>生成式问答</strong></td>
<td><code>t5-base</code>, <code>flan-t5-base</code></td>
<td>问题 + 文档</td>
<td>自由文本答案</td>
</tr>
<tr>
<td><strong>多任务学习</strong></td>
<td><code>google/flan-t5-xl</code></td>
<td>指令式 prompt</td>
<td>任意任务输出</td>
</tr>
</tbody></table>
<p>常见的 Seq2Seq 模型（可用于 <code>AutoModelForSeq2SeqLM</code>）</p>
<table>
<thead>
<tr>
<th>模型名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>t5-base</code></td>
<td>Google 的多任务 Seq2Seq 模型</td>
</tr>
<tr>
<td><code>flan-t5-base</code></td>
<td>更强版本的 T5，经过 instruction tuning</td>
</tr>
<tr>
<td><code>facebook/bart-large-cnn</code></td>
<td>BART 微调用于新闻摘要</td>
</tr>
<tr>
<td><code>Helsinki-NLP/opus-mt-*</code></td>
<td>多语言机器翻译模型</td>
</tr>
</tbody></table>
<p>示例代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

<span class="token comment"># 1. 加载分词器和模型</span>
model_path <span class="token operator">=</span> <span class="token string">'***/Helsinki-NLP:opus-mt-en-zh'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 2. 准备输入文本</span>
source_text <span class="token operator">=</span> <span class="token string">"The future of AI is full of possibilities."</span>

<span class="token comment"># 3. 对输入文本进行分词编码（转换为模型可接受的格式）</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>source_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token comment"># 4. 生成翻译结果（禁用梯度，提高推理速度）</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    output_ids <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>
        <span class="token operator">**</span>inputs<span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>     <span class="token comment"># 最长输出长度</span>
        num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>       <span class="token comment"># beam search 的宽度，越大越稳但速度越慢</span>
        early_stopping<span class="token operator">=</span><span class="token boolean">True</span>  <span class="token comment"># 如果 beam 提前收敛就停止生成</span>
    <span class="token punctuation">)</span>

<span class="token comment"># 5. 解码输出的 token IDs，转换为可读的翻译结果</span>
translated_text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>output_ids<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 6. 打印原文与翻译结果</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n🌐 Original:"</span><span class="token punctuation">,</span> source_text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"🌍 Translated:"</span><span class="token punctuation">,</span> translated_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>🌐 Original: The future of AI is full of possibilities.<br>🌍 Translated: AI的未来充满了可能性。</p>
</blockquote>
<hr>
<h4 id="Tokens-基础"><a href="#Tokens-基础" class="headerlink" title="Tokens 基础"></a>Tokens 基础</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

<span class="token comment"># Initialize tokenizer from a fine-tuned DistilBERT model for sentiment analysis</span>
model_åpath <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Sample text for tokenization demonstration</span>
text <span class="token operator">=</span> <span class="token string">"Hello, my name is Ricky"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Raw text: </span><span class="token interpolation"><span class="token punctuation">{</span>text<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># Tokenization: text -&gt; subword tokens</span>
tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Tokenized output: </span><span class="token interpolation"><span class="token punctuation">{</span>tokens<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># tokens -&gt; vocabulary IDs</span>
token_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Token IDs: </span><span class="token interpolation"><span class="token punctuation">{</span>token_ids<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># text -&gt; model input format</span>
input_py <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span>  <span class="token comment"># Returns Python dictionary with lists</span>
input_pt <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>  <span class="token comment"># Returns Python dictionary with ready-to-use PyTorch tensors</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Python dictionary format (input_py): </span><span class="token interpolation"><span class="token punctuation">{</span>input_py<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'PyTorch tensor format (input_pt): </span><span class="token interpolation"><span class="token punctuation">{</span>input_pt<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># Best Practice Note:</span>
<span class="token comment"># The PyTorch tensor format (input_pt) is preferred for production because:</span>
<span class="token comment"># 1. Direct compatibility with model.forward() expectations</span>
<span class="token comment"># 2. Automatic GPU acceleration when available (via .cuda() or .to(device))</span>
<span class="token comment"># 3. Built-in support for batch processing</span>
<span class="token comment"># 4. Memory efficiency for large-scale inference</span>
<span class="token comment"># 5. Seamless integration with PyTorch's computation graph</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>测试结果</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Raw text: Hello, my name is Ricky

Tokenized output: ['hello', ',', 'my', 'name', 'is', 'ricky']

Token IDs: [7592, 1010, 2026, 2171, 2003, 11184]

Python dictionary format (input_py): {'input_ids': [101, 7592, 1010, 2026, 2171, 2003, 11184, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}

PyTorch tensor format (input_pt): {'input_ids': tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="Embeddings-基础"><a href="#Embeddings-基础" class="headerlink" title="Embeddings 基础"></a>Embeddings 基础</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel

<span class="token comment"># Load pre-trained model and tokenizer</span>
model_path <span class="token operator">=</span> <span class="token string">'/home/xixingyu/disk1/PretrainedModels/distilbert-base-uncased-finetuned-sst-2-english'</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Sample text </span>
text <span class="token operator">=</span> <span class="token string">'Hello, my name is Ricky.'</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 1: TOKENIZATION - Converting text to numbers</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Tokenization ==="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\nRaw text: </span><span class="token interpolation"><span class="token punctuation">{</span>text<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Tokenized Input Structure (PyTorch tensors):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

<span class="token comment"># Let's see what each component means</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nInput IDs (numerical representation of tokens):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nAttention Mask (shows which tokens are real vs padding):"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">'attention_mask'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 2: GENERATING EMBEDDINGS</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Generating Embeddings ==="</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># Disable gradient calculation for inference</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span> <span class="token comment"># # Forward pass through the model</span>
    
    <span class="token comment"># The model returns a tuple where the first element contains token embeddings</span>
    token_embeddings <span class="token operator">=</span> outputs<span class="token punctuation">.</span>last_hidden_state
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nShape of Token Embeddings:"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Batch Size, Sequence Length, Embedding Dimension] = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"- Batch Size = 1 (we processed one sentence)"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"- Sequence Length = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (number of tokens)"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"- Embedding Dimension = </span><span class="token interpolation"><span class="token punctuation">{</span>token_embeddings<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> (size of each vector)"</span></span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># STEP 3: CREATING SENTENCE EMBEDDINGS</span>
<span class="token comment"># =============================================</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n=== Creating Sentence Embeddings ==="</span><span class="token punctuation">)</span>
<span class="token comment"># Simple method: Average all token embeddings (mean pooling)</span>
sentence_embedding <span class="token operator">=</span> token_embeddings<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nShape of Sentence Embedding:"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Batch Size, Embedding Dimension] = </span><span class="token interpolation"><span class="token punctuation">{</span>sentence_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"- Represents the entire sentence as a single vector"</span><span class="token punctuation">)</span>

<span class="token comment"># =============================================</span>
<span class="token comment"># EDUCATIONAL NOTES</span>
<span class="token comment"># =============================================</span>
<span class="token triple-quoted-string string">"""
WHAT ARE EMBEDDINGS?

1. Token Embeddings:
- Each word/subword is converted to a high-dimensional vector
- These vectors capture semantic meaning and context
- Example: "cat" and "kitten" will have similar vectors

2. Sentence Embeddings:
- A single vector representing the entire sentence
- Created by combining token embeddings (here by averaging)
- Can be used for tasks like similarity comparison

WHY THIS MATTERS:
- Computers don't understand words, only numbers
- Embeddings convert language to numerical representations
- Similar meanings → Similar vectors → Better AI understanding
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>测试结果</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">=== Tokenization ===

Raw text: Hello, my name is Ricky.
Tokenized Input Structure (PyTorch tensors):
{'input_ids': tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}

Input IDs (numerical representation of tokens):
tensor([[  101,  7592,  1010,  2026,  2171,  2003, 11184,  1012,   102]])

Attention Mask (shows which tokens are real vs padding):
tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])

=== Generating Embeddings ===

Shape of Token Embeddings:
[Batch Size, Sequence Length, Embedding Dimension] = torch.Size([1, 9, 768])
- Batch Size = 1 (we processed one sentence)
- Sequence Length = 9 (number of tokens)
- Embedding Dimension = 768 (size of each vector)

=== Creating Sentence Embeddings ===

Shape of Sentence Embedding:
[Batch Size, Embedding Dimension] = torch.Size([1, 768])
- Represents the entire sentence as a single vector<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







<h4 id="文本情感分类（入门程序）"><a href="#文本情感分类（入门程序）" class="headerlink" title="文本情感分类（入门程序）"></a>文本情感分类（入门程序）</h4><p>大模型调用版本的 <code>helloworld.py</code> </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification  <span class="token comment"># Hugging Face的Transformer库</span>
<span class="token keyword">import</span> torch 

<span class="token comment"># 预训练模型的路径（该模型是在SST-2英文情感数据集上微调的DistilBERT模型，用于情感分类）</span>
model_path <span class="token operator">=</span> <span class="token string">'***/distilbert-base-uncased-finetuned-sst-2-english'</span>

<span class="token comment"># ===================== 加载模型和分词器 =====================</span>
<span class="token comment"># 加载与预训练模型对应的分词器，负责将原始文本转换为模型可以理解的token ID序列）</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># 加载预训练好的序列分类模型</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># ===================== 准备输入数据 =====================</span>
<span class="token comment"># 待分析的文本</span>
text <span class="token operator">=</span> <span class="token string">"I love China"</span>

<span class="token comment"># 使用分词器处理文本：</span>
<span class="token comment"># - 将文本分割成token</span>
<span class="token comment"># - 添加特殊token（如[CLS], [SEP]）</span>
<span class="token comment"># - 将token转换为对应的ID</span>
<span class="token comment"># - 生成注意力掩码（attention mask）</span>
<span class="token comment"># return_tensors='pt'表示返回PyTorch张量（而不是NumPy数组）</span>
<span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 查看输入的结构（调试用）：</span>
<span class="token comment"># input_ids: token对应的数字ID</span>
<span class="token comment"># attention_mask: 指示哪些位置是有效token（1表示真实token，0表示填充padding）</span>

<span class="token comment"># ===================== 模型推理 =====================</span>
<span class="token comment"># 将处理好的输入传入模型</span>
output <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token comment">#**操作符用于将字典解包为关键字参数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ===================== 解析模型输出 =====================</span>
<span class="token comment"># 从输出中获取logits（未经过softmax的原始输出分数）</span>
<span class="token comment"># logits形状为[batch_size, num_classes]</span>
<span class="token comment"># 因为我们只输入了一个句子，所以batch_size为1</span>
<span class="token comment"># SST-2是二分类任务，所以num_classes为2（索引0:负面，1:正面）</span>
logits <span class="token operator">=</span> output<span class="token punctuation">.</span>logits
<span class="token keyword">print</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 获取预测类别：找到logits中最大值的索引</span>
<span class="token comment"># torch.argmax返回最大值所在的索引</span>
<span class="token comment"># dim=1表示我们在类别维度（而不是批次维度）上寻找最大值</span>
predicted_class_id <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predicted_class_id<span class="token punctuation">)</span>  <span class="token comment"># 此时还是PyTorch张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

predicted_class_id <span class="token operator">=</span> predicted_class_id<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 使用.item()将张量转换为Python整数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predicted_class_id<span class="token punctuation">)</span>  <span class="token comment"># 现在是普通整数（0或1）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ===================== 结果映射和输出 =====================</span>
<span class="token comment"># 定义类别标签（注意SST-2的标准顺序）</span>
labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Negative'</span><span class="token punctuation">,</span> <span class="token string">'Positive'</span><span class="token punctuation">]</span>

<span class="token comment"># 获取预测结果对应的人类可读标签</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">[</span>predicted_class_id<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>测试结果</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1045</span><span class="token punctuation">,</span> <span class="token number">2293</span><span class="token punctuation">,</span> <span class="token number">2859</span><span class="token punctuation">,</span>  <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

SequenceClassifierOutput<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> logits<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4.1768</span><span class="token punctuation">,</span>  <span class="token number">4.4845</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attentions<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">4.1768</span><span class="token punctuation">,</span>  <span class="token number">4.4845</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token number">1</span>

Positive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







<h2 id="医疗大模型"><a href="#医疗大模型" class="headerlink" title="医疗大模型"></a>医疗大模型</h2><table>
<thead>
<tr>
<th>模型</th>
</tr>
</thead>
<tbody><tr>
<td>华佗</td>
</tr>
<tr>
<td>BioGPT</td>
</tr>
</tbody></table>
<h2 id="大模型-Leaderboard"><a href="#大模型-Leaderboard" class="headerlink" title="大模型 Leaderboard"></a>大模型 Leaderboard</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://aider.chat/docs/leaderboards/">https://aider.chat/docs/leaderboards/</a></p>
<p><a target="_blank" rel="noopener" href="https://livebench.ai/#/">https://livebench.ai/#/</a></p>
</blockquote>
<h2 id="大模型的使用方式"><a href="#大模型的使用方式" class="headerlink" title="大模型的使用方式"></a>大模型的使用方式</h2><h3 id="1-网页端调用（最方便的方式）"><a href="#1-网页端调用（最方便的方式）" class="headerlink" title="1. 网页端调用（最方便的方式）"></a>1. 网页端调用（最方便的方式）</h3><p>这种方式适合不需要深度集成或技术门槛较低的场景，用户通过浏览器直接与大模型交互。</p>
<p>📌 代表平台</p>
<table>
<thead>
<tr>
<th>平台名称</th>
<th>公司名</th>
<th>模型类型</th>
<th>官网链接</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ChatGPT</strong></td>
<td>OpenAI</td>
<td>GPT-4</td>
<td><a target="_blank" rel="noopener" href="https://chat.openai.com/">🔗 chat.openai.com</a></td>
</tr>
<tr>
<td><strong>Claude</strong></td>
<td>Anthropic</td>
<td>Claude 3.5 / Claude 3.7 Sonnet</td>
<td><a target="_blank" rel="noopener" href="https://claude.ai/">🔗 claude.ai</a></td>
</tr>
<tr>
<td><strong>Gemini</strong></td>
<td>Google DeepMind</td>
<td>Gemini 1.5 系列（前 Bard）</td>
<td><a target="_blank" rel="noopener" href="https://gemini.google.com/">🔗 gemini.google.com</a></td>
</tr>
<tr>
<td><strong>POE</strong></td>
<td>Quora</td>
<td>GPT、Claude、Gemini、Mistral等</td>
<td><a target="_blank" rel="noopener" href="https://poe.com/">🔗 poe.com</a></td>
</tr>
<tr>
<td><strong>DeepSeek</strong></td>
<td>DeepSeek</td>
<td>DeepSeek-V3、DeepSeek-R1</td>
<td><a target="_blank" rel="noopener" href="https://www.deepseek.com/">🔗 www.deepseek.com</a></td>
</tr>
<tr>
<td><strong>通义千问</strong></td>
<td>阿里云</td>
<td>Qwen 系列</td>
<td><a target="_blank" rel="noopener" href="https://tongyi.aliyun.com/">🔗 tongyi.aliyun.com</a></td>
</tr>
<tr>
<td><strong>豆包</strong></td>
<td>字节跳动</td>
<td>Skywork / MiniMax</td>
<td><a target="_blank" rel="noopener" href="https://www.doubao.com/">🔗 www.doubao.com</a></td>
</tr>
<tr>
<td><strong>Kimi</strong></td>
<td>月之暗</td>
<td>Moonshot 系列</td>
<td>🔗 <a target="_blank" rel="noopener" href="https://kimi.moonshot.cn/">kimi.moonshot.cn</a></td>
</tr>
<tr>
<td><strong>智谱清言</strong></td>
<td>智谱AI</td>
<td>ChatGLM 系列</td>
<td><a target="_blank" rel="noopener" href="https://chatglm.cn/">🔗 chatglm.cn</a></td>
</tr>
</tbody></table>
<h3 id="2-API调用（适合开发者）"><a href="#2-API调用（适合开发者）" class="headerlink" title="2. API调用（适合开发者）"></a>2. <strong>API调用（适合开发者）</strong></h3><h3 id="3-本地部署调用（注重隐私和安全）"><a href="#3-本地部署调用（注重隐私和安全）" class="headerlink" title="3. 本地部署调用（注重隐私和安全）"></a>3. 本地部署调用（注重隐私和安全）</h3><h4 id="ollama简介"><a href="#ollama简介" class="headerlink" title="ollama简介"></a>ollama简介</h4><p>Ollama 是一个用于在本地运行、部署和管理大型语言模型（LLM）的开源工具，特别适合开发者、研究人员或任何想离线或在私有环境中使用 AI 模型的用户。</p>
<blockquote>
<p>ollama官方网页：<a target="_blank" rel="noopener" href="https://ollama.com/">https://ollama.com/</a></p>
</blockquote>
<h4 id="ollama常用命令"><a href="#ollama常用命令" class="headerlink" title="ollama常用命令"></a>ollama常用命令</h4><h5 id="模型管理"><a href="#模型管理" class="headerlink" title="模型管理"></a>模型管理</h5><table>
<thead>
<tr>
<th align="left">命令</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama pull &lt;模型名&gt;</code></td>
<td align="left">下载模型（如 <code>llama3</code>、<code>mistral</code>）</td>
</tr>
<tr>
<td align="left"><code>ollama list</code></td>
<td align="left">查看已安装的模型列表</td>
</tr>
<tr>
<td align="left"><code>ollama rm &lt;模型名&gt;</code></td>
<td align="left">删除本地模型</td>
</tr>
<tr>
<td align="left"><code>ollama cp &lt;源模型&gt; &lt;新模型名&gt;</code></td>
<td align="left">复制模型副本</td>
</tr>
<tr>
<td align="left"><code>ollama show --license &lt;模型名&gt;</code></td>
<td align="left">查看模型许可证</td>
</tr>
</tbody></table>
<h5 id="运行与交互"><a href="#运行与交互" class="headerlink" title="运行与交互"></a>运行与交互</h5><table>
<thead>
<tr>
<th align="left">命令</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama run &lt;模型名&gt;</code></td>
<td align="left">启动交互式对话（默认加载模型）</td>
</tr>
<tr>
<td align="left"><code>ollama run &lt;模型名&gt; "你的提示词"</code></td>
<td align="left">直接输入提示词并获取输出（非交互）</td>
</tr>
<tr>
<td align="left"><code>ollama serve</code></td>
<td align="left">启动本地 API 服务（默认端口 <code>11434</code>）</td>
</tr>
</tbody></table>
<h5 id="系统与调试"><a href="#系统与调试" class="headerlink" title="系统与调试"></a>系统与调试</h5><table>
<thead>
<tr>
<th align="left">命令</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>ollama help</code></td>
<td align="left">查看所有命令帮助</td>
</tr>
<tr>
<td align="left"><code>ollama version</code></td>
<td align="left">查看 Ollama 版本</td>
</tr>
<tr>
<td align="left"><code>OLLAMA_MODELS=&lt;路径&gt;</code></td>
<td align="left">指定模型存储路径（环境变量）</td>
</tr>
<tr>
<td align="left"><code>ollama ps</code></td>
<td align="left">查看当前运行的模型进程</td>
</tr>
</tbody></table>
<h4 id="ollama下载模型"><a href="#ollama下载模型" class="headerlink" title="ollama下载模型"></a>ollama下载模型</h4><p>ollama下载deepseek（<a target="_blank" rel="noopener" href="https://ollama.com/library/deepseek-r1">https://ollama.com/library/deepseek-r1</a>）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run deepseek-r1:7b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h4 id="Cherry-Studio"><a href="#Cherry-Studio" class="headerlink" title="Cherry Studio"></a>Cherry Studio</h4><h3 id="4-插件-x2F-Agent系统（打造智能工作流）"><a href="#4-插件-x2F-Agent系统（打造智能工作流）" class="headerlink" title="4. 插件/Agent系统（打造智能工作流）"></a>4. 插件/Agent系统（打造智能工作流）</h3>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Rickyの水果摊</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://ricky2333.github.io/AI-basics/index.html">https://ricky2333.github.io/AI-basics/index.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Rickyの水果摊</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/AI-basics/index.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Ricky の 大模型学习之路">
                        
                        <span class="card-title">Ricky の 大模型学习之路</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Rickyの水果摊
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                本篇&nbsp;<i class="far fa-dot-circle"></i>
            </div>
            <div class="card">
                <a href="/AI-basics/index.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Ricky の 大模型学习之路">
                        
                        <span class="card-title">Ricky の 大模型学习之路</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-14
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Rickyの水果摊
                            
                        </span>
                    </div>
                </div>

                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        // if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
        //     newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        // }
        newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Rickyの水果摊<br />'
            + '文章作者: Rickyの水果摊<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <!-- <div class="toc-widget card" style="background-color: white;"> -->
        <div class="toc-widget card">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="tencent"
                   type="playlist"
                   id="8891306868"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023-2025</span>
            
            <!-- <span id="year">2023</span> -->
            <a href="/about" target="_blank">Rickyの水果摊</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            <!-- |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a> -->
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">311.7k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2023";
                    var startMonth = "3";
                    var startDate = "24";
                    var startHour = "7";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Ricky2333" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:rickyxlearner@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=775641698" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 775641698" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 白天和黑夜主题 -->
<div class="sum-moon-box">
    <a class="btn-floating btn-large waves-effect waves-light" onclick="switchNightMode()" title="切换主题" >
      <i id="sum-moon-icon" class="fas fa-sun" style="width:48px; height:48px; font-size: 28px;"></i>
    </a>
  </div>
  
  <script>
    function switchNightMode() {
      sessionStorage.setItem('changeTheme', true)
      $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
          $('#dark-mode').length > 0
          ? (document.body.removeAttribute('id'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon'))
          : (document.body.setAttribute('id', 'dark-mode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
  
          setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
              $(this).remove()
            })
          }, 2e3)
        })
    }
  </script>

  <!-- <div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script> -->

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "🍉收摊回家啦<（@￣︶￣@）>", clearTimeout(st)) : (document.title = "🍉摊主回来了 (*￣▽￣*)ブ", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) </script>

    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?fa6c571338ef69fd41a561901f549e84";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>
    

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 冒泡 -->
    
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            document.write(
                '<script type="text/javascript" src="/libs/others/buble.js"><\/script>'
            );
        </script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
